{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Provenance integration in netcdf/xarray Data-Intensive workflows.\n",
    "\n",
    "\n",
    "#### Authors: Alessandro Spinuso and Andrej Mihajlovski, \n",
    "\n",
    "####  Royal Netherlands Meteorological Institure (KNMI)\n",
    "\n",
    "\n",
    "The following \"Live\" notebook demonstrates a simple workflow implemented with a data-intensive processing library (dispel4py), that has been extended with a configurable and programmable provenance tracking framework , S-PROV.\n",
    "\n",
    "## Management Highligts, S-PROV Towards reproduciblity as a service\n",
    "<ul>\n",
    "<li>\n",
    "The provenance information produced can be tuned and adapted to computational, precision and contextualisation requirements</li>\n",
    "<li>\n",
    "The freamework allows for the traceability of data-reuse across different executions, methods and users</li>\n",
    "<li>The provenance can be stored as files or sent at run-time to a custom external repository</li>\n",
    "<li>The repository can be searched and explored via interactive tools</li> \n",
    "<li>The provenance model is designed around an hybrid data-flow model, which takes into account data-streams and concrete data resourcese. eg. file location, webservices etc.</li>\n",
    "<li>The lineage can be exported from the repository in W3C PROV format. This facilitates the production of interoperabile reports and data-curation tasks. For instance, The provenance related to specific data can be stored in W3C-PROV XML format into strucutred file formats (NetCDF) as well as istitutional and general-purpose citable data-repositories.</li>\n",
    "</ul>\n",
    "\n",
    "## Demonstration outline\n",
    "\n",
    "### 1 - Workflow specification and execution\n",
    "\n",
    "<ol>\n",
    "  <li>Define the <i><b>Classes</b></i> of the <i><b>Workflow Components</b></i></li>\n",
    "  <li>Construct the <i><b>Workflow</b></i> application</li>\n",
    "  <li>Prepare the Input</li>\n",
    "  <li>Visualise and run the workflow without provenance</li>\n",
    "</ol>\n",
    "\n",
    "### 2 - Provenance Types, Profiling and contextualisation\n",
    "\n",
    "<ol>\n",
    "  <li>Define the <i><b>Provenance Type</b></i> to be used within the workflow</li>\n",
    "  <li><i><b>Profile</b></i> the workfow for provenance tracking</li>\n",
    "  <li>Run the workflow with provenance activatied</li>\n",
    "  <li>Export and embed provenance within NetCDF results</li>\n",
    "  <li>Explore the resulting provenance with interactive and static visualsations</li>\n",
    "</ol>\n",
    "\n",
    "### 3 - Data-reuse traceability. \n",
    "<ol>\n",
    "  <li>Change the input and demostrate consistency of provenance for data-ruse across multiple workflow executions</li>\n",
    "  <li>Discuss more complex use cases and configuration options</li>\n",
    "</ol>\n",
    "\n",
    "### 4 - Informal Evaluation\n",
    "\n",
    "SWOT form:\n",
    "\n",
    "https://docs.google.com/presentation/d/10xlRYytR7NB9iC19T29BD-rW77ZAtnjtlukMJDP_MIs/edit?usp=sharing\n",
    "\n",
    "\n",
    "## 1 - Workflow specification and execution\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>The dispel4py framework is utilised for the workflows</li>\n",
    "<li>Xarray for inmemory management of netcdf/opendap data.</li>\n",
    "<li>Matplotlib for visualisation.</li>\n",
    "<li>A W3C PROV specialisation (S-PROV) used as provenance representation.</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xarray\n",
    "#import netCDF4\n",
    "import json\n",
    "\n",
    "from dispel4py.workflow_graph import WorkflowGraph \n",
    "from dispel4py.provenance import *\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "\n",
    "from dispel4py.base import create_iterative_chain, ConsumerPE, IterativePE, SimpleFunctionPE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Simple Workflow, xarray in xarray out. \n",
    "The generic processing elements are defined below. the <i>GenericPE</i> bellongs to the dispel4py framework. It allows data-objects to be passed as inputs and outputs. The <i>Components</i> are linked and visualised via the workflow_graph module.\n",
    "\n",
    "### 1.1 The three Workflow Components:\n",
    "\n",
    "<ol>\n",
    "<li>- Read, xarray is read into memory.</li>\n",
    "<li>- ANALYSIS, xarray is processed/passed to output (dummy, no real changes in the example)</li>\n",
    "<li>- Write, xarray is visualised.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Read(GenericPE):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('xarray')\n",
    "\n",
    "    def _process(self,inputs):\n",
    "        \n",
    "        inputLocation = inputs['input'][0]\n",
    "\n",
    "        ds = xarray.open_dataset(inputLocation)\n",
    "    \n",
    "        self.write( 'xarray' , (ds , inputs['input'][1]) , location=inputLocation )\n",
    "\n",
    "        \n",
    "#The IterativePE automatically assigns input and output ports to the component\n",
    "class Write(IterativePE):\n",
    "    \n",
    "    def __init__(self):\n",
    "        IterativePE.__init__(self)\n",
    "         \n",
    "            \n",
    "    def _process(self,inputs):\n",
    "        self.log('Write_Function')\n",
    "        \n",
    "        outputLocation = inputs[1]\n",
    "        \n",
    "        #specifies location and allocate a new id to the output data consistently into the provenance and file \n",
    "        self.write('storedData', (inputs[0],inputs[1]),location=outputLocation )\n",
    "\n",
    "        #the data is stored with the new id \n",
    "        inputs[0].to_netcdf( outputLocation )\n",
    "        \n",
    "        \n",
    "class Analysis(GenericPE):\n",
    "        \n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('output')\n",
    "        \n",
    "    def _process(self,inputs):\n",
    "        self.log('Workflow_process')\n",
    "        \n",
    "       \n",
    "        nc = inputs['input'][0]\n",
    "         \n",
    "        #Additional metadata can be added to the output for provenance contextualisation\n",
    "        self.write('output', (nc , inputs['input'][1] ), metadata={'mycustom_term':10})\n",
    "\n",
    "\n",
    "        \n",
    "#Collect multiple inputs before producing a result\n",
    "class AnalysisAvg(GenericPE): \n",
    "        \n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('output')\n",
    "        self._add_output('threshold')\n",
    "        self.count=1\n",
    "        \n",
    "    def _process(self,inputs):\n",
    "        #self.log('Workflow_process')\n",
    "        \n",
    "       \n",
    "        nc = inputs['input'][0]\n",
    "         \n",
    "        #Additional metadata can be added to the output for provenance contextualisation\n",
    "        \n",
    "        if (self.count%3==0):\n",
    "            self.log(\"PRINT AVG\" +str(self.count))\n",
    "            self.write('avg', (nc , inputs['input'][1] ), metadata={'count':self.count})\n",
    "            \n",
    "            \n",
    "        if (self.count%5==0):\n",
    "            self.log(\"PRINT thr\" +str(self.count))\n",
    "            self.write('threshold', (nc , inputs['input'][1] ), metadata={'count':self.count})\n",
    "             \n",
    "        self.count+=1\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Construct the Workflow application\n",
    "\n",
    "Instantiates the Components and combines them in a workflow graph which gets eventually visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING NAME: Read\n",
      "SETTING NAME: Analysis\n",
      "SETTING NAME: AnalysisAvg\n",
      "SETTING NAME: Write\n",
      "SETTING NAME: Write\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAFACAYAAACWWDibAAAAAXNSR0IArs4c6QAAQABJREFUeAHt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\ngg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Initialise the graph\n",
    "def createWorkflowGraph():\n",
    "    readX  = Read()\n",
    "    readX.name = 'Collector'\n",
    "\n",
    "    analyse   = Analysis()\n",
    "    analyse.name    = 'ANALYSIS'\n",
    "    analyse.parameters = { 'filter': 10 }\n",
    "\n",
    "    \n",
    "    analyseAc   = AnalysisAvg()\n",
    "    analyseAc.name    = 'ANALYSIS'\n",
    "    analyseAc.parameters = { 'filter': 10 }\n",
    "\n",
    "    writeX = Write()\n",
    "    writeX.name = 'StoreFile'\n",
    "    writey = Write()\n",
    "    writey.name = 'StoreThreshold'\n",
    "    \n",
    "    \n",
    "    graph = WorkflowGraph()    \n",
    "    graph.connect(readX ,'xarray'   , analyseAc     ,'input')\n",
    "    graph.connect(analyseAc    ,'avg'   , writeX , 'input')\n",
    "    graph.connect(analyseAc    ,'threshold'   , writey , 'input')\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "graph = createWorkflowGraph()\n",
    "\n",
    "\n",
    "from dispel4py.visualisation import display\n",
    "display(graph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Specify the Input\n",
    "\n",
    "A simple json representation is used to define initial input data for each named Component of the workflow.\n",
    "Every component can recieve a list of inputs. These will be streamed serially or in parallel, depending from the execution mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = { \n",
    "                \n",
    "                #'Collector': [ { 'input' : [ 'http://opendap.knmi.nl/knmi/thredds/dodsC/CLIPC/cmcc/SWE/SWE_ophidia-0-10-1_CMCC_GlobSnow-SWE-L3B_monClim_19791001-20080701_1979-2008.nc',\n",
    "                #              'data/newA.nc']}]\n",
    "                #Ingest a stream of inputs\n",
    "     'Collector': [ { 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']},{ 'input': [ 'data/newA.nc', 'data/newB.nc']}]     \n",
    "                           \n",
    "    #'Collector': [ { 'input': [ 'data/newB.nc', 'data/newC.nc']}]\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Run the Workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Provenance Types, Profiling and contextualisation\n",
    "\n",
    "### 2.1 Define a Provenance Type\n",
    "\n",
    "The <i>Provenance Type</i> defined below will be used to extend specific workflow components, enabling special provenance tracking properties for <i>NetCDF/xarray</i> formats.\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "<b><i>makeUniqueId:</i></b> \n",
    "Generates and returns a <i>uuid</i>. This can be implemented to adhere to the hosting infrastructure best-practices.</li>\n",
    "<li>\n",
    "<i><b>extractExternalInputDataId:</b></i>\n",
    "This method is used by the provenance type to extract the id of the incoming data. Its use is handy especially when a workflow component ingests files that have been produced by other workflows and that are represented by self-contained and structured data formats.  For instance, in NetCDF where data and metadata can be packaged together according to community standards, this method extracts and returns the id of the external resource, allowing the framework to use it in the current run to represent new dependencies. A customised implementation of this method for a provenance type that deals with domain-specific data formats, ensures the linkage and therefore the consistent continuation of provenance traces across workflow executions. </li>\n",
    "<li><b><i>extractItemMetadata:</i></b>\n",
    "This methods enables the configuration of the provenance for a particular domain, user or infrastructure requirement. It extracts metadata from the data written on a output channel and includes it as a detailed description of the <i>Data</i> entity within the provenance model.</li>\n",
    "<li><b><i>applyFlowResetPolicy (Advanced):</i></b>\n",
    "This method is invoked by each iteration when a decision has to be made on the required lineage pattern. The framework automatically passes information whether the invocation has produced any output or not (<i>on-void-iterations</i>). The method, according to predefined rules, provides indications on either discarding the current input data or to include it into the <i>StateCollection</i> automatically, capturing its contribution to the next invocation through a <i>stateful</i>operations. \n",
    "In our implementation, basic provenance types such as <i>StatefulType</i> and <i>StatelessType</i> are made available and can be used accordingly the specific needs.\n",
    "</li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Collector': [{'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}]}\n",
      "SETTING NAME: SimpleProcessingPE\n",
      "ANALYSIS1: PRINT AVG3\n",
      "ANALYSIS1: PRINT thr5\n",
      "ANALYSIS1: PRINT AVG6\n",
      "StoreFile2: Write_Function\n",
      "StoreFile2: Write_Function\n",
      "StoreThreshold3: Write_Function\n",
      "SimplePE: Processed 1 iteration.\n",
      "\n",
      " RESULT: {'StoreThreshold3': {'storedData': [(<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 0953ef85-3a11-11e7-86f3-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc')]}, 'StoreFile2': {'storedData': [(<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 0953ef85-3a11-11e7-86f3-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc'), (<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 0953ef85-3a11-11e7-86f3-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc')]}}\n"
     ]
    }
   ],
   "source": [
    "global result\n",
    "\n",
    "def runExampleWorkflow():\n",
    "                                                     \n",
    "    print input_data                   \n",
    "\n",
    "    #Launch in simple process\n",
    "    result = simple_process.process_and_return(graph, input_data)\n",
    "    print \"\\n RESULT: \"+str(result)\n",
    "\n",
    "runExampleWorkflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class AccumulationType(ProvenancePE):\n",
    "    def __init__(self):\n",
    "        ProvenancePE.__init__(self)\n",
    "        \n",
    "    \n",
    "    def apply_state_reset_policy(self,event,value,port=None):\n",
    "        self.log(port)\n",
    "        if (event=='write'):\n",
    "            self.resetflow=False\n",
    "            \n",
    "        if (event=='void_iteration') and value==True:\n",
    "             \n",
    "            self.resetflow=False\n",
    "        \n",
    "        if (event=='void_iteration') and value==False:\n",
    "            self.resetflow=True\n",
    "            \n",
    "\n",
    "class netcdfProvType(ProvenancePE):\n",
    "    def __init__(self):\n",
    "        ProvenancePE.__init__(self)\n",
    "        self.ns={\"clipc\":\"http://clipc.eu/ns/#\"}\n",
    "    \n",
    "    def extractExternalInputDataId(self,data, input_port):\n",
    "        #Extract here the id from the data (type specific):\n",
    "\n",
    "        self.log('ANDREJ.extractExternalInputDataId')\n",
    "        #self.log(data)\n",
    "        \n",
    "        try:\n",
    "            #ds = xarray.open_dataset(data['input'][0])\n",
    "            ds = xarray.open_dataset(data[0])\n",
    "            id = ds.attrs['id']\n",
    "            \n",
    "        except Exception, err:\n",
    "            id = str(uuid.uuid1())\n",
    "            self.log(str(err))\n",
    "        #Return\n",
    "        return id\n",
    "    \n",
    "    \n",
    "    def makeUniqueId(self, data, output_port):      \n",
    "        \n",
    "        self.log('ANDREJ.makeUniqueId')\n",
    "        #self.log(kwargs)\n",
    "        \n",
    "        #produce the id\n",
    "        \n",
    "        id=str(uuid.uuid1())\n",
    "            \n",
    "        ''' nc data '''\n",
    "        xa = data[0]\n",
    "        \n",
    "        ''' unique as defined by the community standard '''\n",
    "        xa.attrs['id'] = id\n",
    "        \n",
    "        #Return\n",
    "        return id \n",
    "    \n",
    "\n",
    "    \n",
    "    ''' extracts xarray metadata '''\n",
    "    def extractItemMetadata(self, data, output_port):\n",
    "         \n",
    "        self.log('ANDREJ.extractItemMetadata')\n",
    "        #self.log(data)\n",
    "        \n",
    "        try:            \n",
    "            nc_meta = OrderedDict()\n",
    "            \n",
    "            ''' cycle throug all attributes, dimensions and variables '''\n",
    "            xa = data[0]\n",
    "                        \n",
    "            # dataset meta\n",
    "            nc_meta['Dimensions'] = str( dict(xa.dims)) \n",
    "            nc_meta['Type'] = str(type(xa))\n",
    "            \n",
    "            # global attr\n",
    "            for k , v in xa.attrs.items():\n",
    "                nc_meta['clipc:'+str(k).replace(\".\",\"_\")] = str(v)\n",
    "            # vars attr   \n",
    "            for n , i in xa.data_vars.items():\n",
    "                for k , v in i.attrs.items():\n",
    "                    nc_meta['clipc:'+n+\"_\"+str(k).replace(\".\",\"_\")] = str(v)\n",
    "            \n",
    "            #pprint(nc_meta)\n",
    "        \n",
    "            metadata = [nc_meta]\n",
    "            \n",
    "            return metadata\n",
    "                             \n",
    "        except Exception, err:\n",
    "            self.log(\"Applying default metadata extraction:\"+str(traceback.format_exc()))\n",
    "            self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n",
    "            return super(netcdfProvType, self).extractItemMetadata(data);\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Profile the workfow for provenance tracking\n",
    "\n",
    "Once the Provenance types have been defined, these are used to configure, or profile, a workflow execution to comply with the desired provenance collection requirements.  Below we illustrate the framework method and the details of this approach.\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li><b><i>profile_prov_run</i></b> With this method, the users of the workflow can profile their run for provenance by indicating which types to apply to each component. Users can also chose where to store the metadata, locally to the file system or to a remote service. These operations can be performed in bulks, with different impacts on the overall overhead and on the experienced rapidity of the access of the lineage information. Finally, also general information about the attribution of the run, such as <i>username, run_id, description, workflow_name, workflow_id</i> are captured and included within the provenance traces.\n",
    "</li>\n",
    "<li><b><i>Sel-Rules (Advanced)</i></b>\n",
    "Users can tune the scale of the records produced by indicating in the above method a set of <i>sel-rules</i> for every component.This functionality allows users to specify rules to control the data-driven production of the provenance declaratively. The approach takes advantage of the contextualisation applied by the provenance types, which extract domain and experimental metadata, and evaluates their value against simple <i>sel-rule</i> of this kind:\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sel_rules={\"ANALYSIS\":{\"mycustom_term\":{\"$gt\":0,\"$lt\":10}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining provenance profile\n",
    "\n",
    "A high JSON 'template' describing the provenance profile for a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prov_profile =  {\n",
    "                    'username': \"aspinuso\", \n",
    "                    'description' : \"provdemo basic\",\n",
    "                    'workflowName': \"demo_ecmwf\"      ,\n",
    "                    'workflowId'  : \"workflow process\",\n",
    "                    'save_mode'   : 'service'         ,\n",
    "                    # Defines the use of the ProvenancePE with the Workflow Component\n",
    "                    'componentsType' : {'ANALYSIS':(StateUpdateType,) , 'StoreFile':(netcdfProvType,)},\n",
    "                    'sel_rules': sel_rules\n",
    "                } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repository Endpoints \n",
    "\n",
    "The REPOS_URL is the target provenence repository. \n",
    "Used for VERCE (Seismo), CLIPC (C3S) and Climate4Impact (Climate IS-ENES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store via service\n",
    "ProvenancePE.REPOS_URL='http://127.0.0.1:8082/workflow/insert'\n",
    "\n",
    "#Export data lineage via service (REST GET Call on dataid resource)\n",
    "ProvenancePE.PROV_EXPORT_URL='http://127.0.0.1:8082/workflow/export/data/'\n",
    "\n",
    "\n",
    "#Store to local path\n",
    "ProvenancePE.PROV_PATH='./prov-files/'\n",
    "\n",
    "#Size of the provenance bulk of documents before sending to file, service or sensor\n",
    "ProvenancePE.BULK_SIZE=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Dynamic Profiling\n",
    "\n",
    "The application is then profiled with the desired provenance types and attribution parmeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SETTING NAME: Read\n",
      "SETTING NAME: Analysis\n",
      "SETTING NAME: AnalysisAvg\n",
      "SETTING NAME: Write\n",
      "SETTING NAME: Write\n",
      "{'username': 'aspinuso', 'workflowId': 'workflow process', 'description': 'provdemo basic', 'save_mode': 'service', 'sel_rules': {'ANALYSIS': {'mycustom_term': {'$gt': 0, '$lt': 10}}}, 'workflowName': 'demo_ecmwf', 'componentsType': {'StoreFile': (<class '__main__.netcdfProvType'>,), 'ANALYSIS': (<class 'dispel4py.provenance.StateUpdateType'>,)}}\n",
      "Change grouping implementation \n",
      "Change grouping implementation \n",
      "Injecting provenance to: ANALYSIS Original type: (<class 'dispel4py.core.GenericPE'>,)\n",
      "SETTING NAME: StateUpdateType\n",
      "ANALYSIS {'mycustom_term': {'$gt': 0, '$lt': 10}}\n",
      "Injecting provenance to: ANALYSIS Transoformed: (<class 'dispel4py.provenance.StateUpdateType'>, <class '__main__.AnalysisAvg'>)\n",
      "Change grouping implementation \n",
      "Injecting provenance to: Collector Original type: (<class 'dispel4py.core.GenericPE'>,)\n",
      "SETTING NAME: ProvenancePE\n",
      "Injecting provenance to: Collector Transoformed: (<class 'dispel4py.provenance.ProvenancePE'>, <class '__main__.Read'>)\n",
      "Change grouping implementation \n",
      "Injecting provenance to: StoreFile Original type: (<class 'dispel4py.base.IterativePE'>,)\n",
      "SETTING NAME: netcdfProvType\n",
      "Injecting provenance to: StoreFile Transoformed: (<class '__main__.netcdfProvType'>, <class '__main__.Write'>)\n",
      "Change grouping implementation \n",
      "Injecting provenance to: StoreThreshold Original type: (<class 'dispel4py.base.IterativePE'>,)\n",
      "SETTING NAME: ProvenancePE\n",
      "Injecting provenance to: StoreThreshold Transoformed: (<class 'dispel4py.provenance.ProvenancePE'>, <class '__main__.Write'>)\n",
      "SETTING NAME: NewWorkflowRun\n",
      "SETTING NAME: IterativePE\n",
      "Inputs: {'NewWorkflowRun': [{'input': 'None'}]}\n",
      "SETTING NAME: SimpleProcessingPE\n",
      "NewWorkflowRun8: BUILDING INITIAL DERIVATION\n",
      "NewWorkflowRun8: STORING WORKFLOW RUN METADATA\n",
      "NewWorkflowRun8: SENDING: JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865\n",
      "NewWorkflowRun8: TO SERVICE ________________ID: [{'username': 'aspinuso', 'workflowId': 'workflow process', '_id': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'description': 'provdemo basic', 'modules': ['appinst==2.1.2', 'appnope==0.1.0', 'apptools==4.2.0', 'argh==0.26.2', 'autopep8==1.2', 'avro==1.8.1', 'backports-abc==0.4', 'backports.ssl-match-hostname==3.5.0.1', 'basemap==1.0.7', 'blinker==1.4', 'cachecontrol==0.11.7', 'casuarius==1.1', 'certifi==2015.11.20.1', 'cffi==1.8.3', 'chaco==4.4.1', 'click==6.7', 'cloud==2.4.6', 'configargparse==0.10.0', 'configobj==4.7.2', 'construct==2.5.3', 'cryptography==1.3.4', 'cwlref-runner==1.0', 'cwltool==1.0.20170510165748', 'cython==0.23.4', 'decorator==4.0.4', 'dispel4py==0.0.1', 'distribute==0.6.49', 'enable==4.3.0', 'enaml==0.6.8', 'encore==0.4.0', 'enum34==1.1.6', 'envisage==4.4.0', 'etsproxy==0.1.2', 'examples==7.3', 'flake8==2.3.0', 'flask==0.12.1', 'freetype==2.4.4', 'functools32==3.2.3.post2', 'future==0.14.3', 'gevent==1.1.2', 'globusonline-transfer-api-client==0.10.18', 'gnureadline==6.3.3', 'greenlet==0.4.10', 'grequests==0.3.0', 'gunicorn==19.7.1', 'h2==2.4.1', 'h5py==2.5.0', 'hpack==2.3.0', 'html2text==2016.4.2', 'hyperframe==3.2.0', 'idle==2.7.3', 'idna==2.1', 'ipaddress==1.0.17', 'ipykernel==4.2.1', 'ipython-genutils==0.1.0', 'ipython==4.0.1', 'ipywidgets==4.1.1', 'isodate==0.5.4', 'itsdangerous==0.24', 'jinja2==2.9.6', 'jsonschema==2.5.1', 'jupyter-client==4.1.1', 'jupyter-console==4.0.3', 'jupyter-core==4.0.6', 'jupyter==1.0.0', 'kernmagic==0.2.0', 'libjpeg==7.0', 'libpng==1.2.40', 'lockfile==0.12.2', 'lxml==3.6.4', 'm2crypto==0.25.1', 'markupsafe==1.0', 'matplotlib==1.4.3', 'mccabe==0.3', 'mistune==0.7.4', 'mitmproxy==0.17', 'mpi4py==1.3.1', 'nbconvert==4.1.0', 'nbformat==4.0.1', 'netcdf4==1.2.2', 'networkx==1.11', 'nose==1.3.6', 'notebook==4.0.6', 'noworkflow==0.6.0', 'numpy==1.9.2', 'obspy==0.10.1', 'panda==0.3.1', 'pandas==0.17.1', 'passlib==1.6.5', 'path.py==8.1.2', 'pathtools==0.1.2', 'pep8==1.6.2', 'pexpect==4.0.1', 'pickleshare==0.5', 'pillow==3.2.0', 'pip==9.0.1', 'ply==3.4', 'ptyprocess==0.5', 'py==1.4.26', 'pyasn1==0.1.9', 'pycparser==2.14', 'pydotplus==2.0.2', 'pyface==4.4.0', 'pyflakes==0.8.1', 'pyflex==0.1.3', 'pyglet==1.1.4', 'pygments==1.6', 'pyinstaller==3.2.1', 'pymongo==3.4.0', 'pympler==0.4.2', 'pyopenssl==16.1.0', 'pyparsing==2.1.9', 'pyperclip==1.5.27', 'pytest==2.6.4', 'python-dateutil==2.4.2', 'pythondoc==2.7.3', 'pytz==2015.2', 'pyyaml==3.12', 'pyzmq==15.1.0', 'qtconsole==4.1.1', 'rdflib-jsonld==0.4.0', 'rdflib==4.2.2', 'readline==6.2.1', 'requests-futures==0.9.7', 'requests==2.9.2', 'ruamel.ordereddict==0.4.9', 'ruamel.yaml==0.14.11', 'schema-salad==2.5.20170428142041', 'scipy==0.15.1', 'scriptcwl==0.3.1', 'seaborn==0.7.1', 'setuptools==25.1.4', 'shellescape==3.4.1', 'simplegeneric==0.8.1', 'singledispatch==3.4.0.3', 'six==1.10.0', 'sqlalchemy==0.9.9', 'suds==0.4', 'sympy==0.7.3', 'terminado==0.5', 'tornado==4.3', 'traitlets==4.0.0', 'traits==4.4.0', 'traitsui==4.4.0', 'twisted==16.2.0', 'txmongo==16.1.0', 'typing==3.5.3.0', 'ujson==1.35', 'urwid==1.3.1', 'watchdog==0.8.3', 'werkzeug==0.12.1', 'wxpython==2.9.2.4', 'xarray==0.7.1', 'zope.interface==4.0.5'], 'mapping': '-f', 'source': {'Collector4': {'code': u'    def __computewrapper(self, inputs):\\n\\n        try:\\n            result = None\\n\\n            self.__markIteration()\\n\\n            if self.impcls is not None and isinstance(self, self.impcls):\\n                try:\\n                    if hasattr(self, \\'params\\'):\\n                        self.parameters = self.params\\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\\n                    if result is not None:\\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\\n                except:\\n                    result = self._process(inputs)\\n            else:\\n                result = self._process(inputs)\\n\\n            if result is not None:\\n                return result\\n\\n        except Exception:\\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\\n            # self.endTime = datetime.datetime.utcnow()\\n            self.writeResults(\\'error\\', {\\'error\\': \\'null\\'})\\n\\n    def __getUniqueId(self):\\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\\\\n            \"-\" + str(uuid.uuid1())\\n\\n    def __importInputMetadata(self):\\n        try:\\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\\n        except Exception:\\n            None\\n\\n    def __markIteration(self):\\n        self.startTime = datetime.datetime.utcnow()\\n        self.iterationId = self.name + \\'-\\' + self.makeProcessId()\\n\\n    def __processwrapper(self, data):\\n        try:\\n\\n            self.initParameters()\\n\\n            inputs = self.importInputData(data)\\n            # self.__importInputMetadata()\\n            return self.__computewrapper(inputs)\\n\\n        except:\\n            self.log(traceback.format_exc())\\n\\n    def __init__(self):\\n        GenericPE.__init__(self)\\n        self.parameters = {}\\n        self._add_output(OUTPUT_METADATA)\\n\\n    def _add_input(self, name, grouping=None, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an input for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\\n\\n        :param name: name of the input\\n        :param grouping: the grouping type that this input expects (optional)\\n        :param tuple_type: type of tuples accepted by this input (optional)\\n        \\'\\'\\'\\n        self.inputconnections[name] = {NAME: name}\\n        if grouping:\\n            self.inputconnections[name][GROUPING] = grouping\\n        if tuple_type:\\n            self.inputconnections[name][TYPE] = tuple_type\\n\\n    def _add_output(self, name, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an output for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\\n\\n        :param name: name of the output\\n        :param tuple_type: type of tuples produced by this output (optional)\\n        \\'\\'\\'\\n        self.outputconnections[name] = {NAME: name}\\n        if tuple_type:\\n            self.outputconnections[name][TYPE] = tuple_type\\n\\n    def _postprocess(self):\\n        None\\n\\n    def _preprocess(self):\\n        self.instanceId = self.name + \"-Instance-\" + \\\\\\n            \"-\" + self.makeProcessId()\\n\\n        super(ProvenancePE, self)._preprocess()\\n\\n    def _process(self,inputs):\\n        \\n        inputLocation = inputs[\\'input\\'][0]\\n\\n        ds = xarray.open_dataset(inputLocation)\\n    \\n        self.write( \\'xarray\\' , (ds , inputs[\\'input\\'][1]) , location=inputLocation )\\n\\n    def _updateState(self,name,id):\\n        if name in self.statemap:\\n                self.statemapId.remove(self.statemap[name])\\n        self.statemap[name]=id\\n        self.statemapId.append(id)\\n\\n    def _write(self, name, data, **kwargs):\\n        \\'\\'\\'\\n        This writes the \\'data\\' to the output pipe with name \\'name\\' of this PE.\\n        \\'\\'\\'\\n         \\n        try:\\n            output = self.outputconnections[name]\\n            output[WRITER].write(data)\\n        except KeyError:\\n            raise Exception(\"Can\\'t write data: Unknown output connection\\\\\\n                            \\'%s\\' for PE \\'%s\\'\" % (name, type(self).__name__))\\n\\n    def apply_flow_reset_policy(self,event,value,port=None,data=None):\\n        \\n        if (event==\\'void_iteration\\') and value==True:\\n            self.discardInFlow()\\n        \\n        if (event==\\'void_iteration\\') and value==False:\\n            self.discardInFlow()\\n\\n    def buildDerivation(self, data, port=\"\"):\\n\\t\\t\\n        try:\\n\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          data[\\'id\\'], \\'TriggeredByProcessIterationID\\':\\n                          data[\\'TriggeredByProcessIterationID\\'], \\'prov_cluster\\':\\n                          data[\\'prov_cluster\\'],\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n                          \\n           # if port==\"_d4p_state\": \\n           #     derivation.update({\\'iterationIndex\\':self.iterationIndex})\\n                 \\n\\t\\t    \\n\\n            self.derivationIds.append(derivation)\\n\\n        except Exception:\\n            id=self.extractExternalInputDataId(data,port)\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          id, \\'TriggeredByProcessIterationID\\':\\n                          None, \\'prov_cluster\\':\\n                          None,\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n            self.derivationIds.append(derivation)\\n            self.log(\"BUILDING INITIAL DERIVATION\")\\n\\n    def buildUserMetadata(self, data, **kwargs):\\n        streamlist = list()\\n\\n        streamItem = {}\\n        streammeta = []\\n\\n        streammeta = self.extractItemMetadata(data,kwargs[\\'output_port\\'])\\n        \\n        if not isinstance(streammeta, list):\\n            streammeta = kwargs[\\'metadata\\'] if isinstance(\\n                kwargs[\\'metadata\\'], list) else [kwargs[\\'metadata\\']]\\n        elif isinstance(streammeta, list):\\n            try:\\n                if isinstance(kwargs[\\'metadata\\'], list):\\n                    streammeta = streammeta + kwargs[\\'metadata\\']\\n                if isinstance(kwargs[\\'metadata\\'], dict):\\n                    for y in streammeta:\\n                        y.update(kwargs[\\'metadata\\'])\\n            except:\\n                traceback.print_exc(file=sys.stderr)\\n                None\\n        \\n        if self.sel_rules!=None:\\n            self.provon=self.checkSelectiveRule(streammeta)\\n            \\n        if not self.provon:\\n            return streamItem\\n        #self.log(kwargs)\\n        streamItem.update({\"content\": streammeta,\\n                           \"id\": self.getUniqueId(data,kwargs[\\'output_port\\'],**kwargs),\\n                           \"format\": \"\",\\n                           \"location\": \"\",\\n                           \"annotations\": [],\\n                           \"port\": kwargs[\\'output_port\\']})\\n        # if (self.streamItemsControl!={,:\\n        streamItem.update(kwargs[\\'control\\'])\\n        # if (self.streamItemsLocations!={,:\\n        streamItem.update({\"location\": kwargs[\\'location\\'],\\n                          \"format\": kwargs[\\'format\\']})\\n        #streamItem.update({\"size\": total_size(data)})\\n        streamItem.update({\"size\": 0})\\n        streamlist.append(streamItem)\\n        return streamlist\\n\\n    def checkSelectiveRule(self,streammeta):\\n        self.log(\"Checking Skip-Rules\")\\n        for key in self.sel_rules:\\n                for s in streammeta:\\n                    if key in s: \\n                        self.log(\"A\"+str(self.sel_rules[key]))\\n                        self.log(s[key]) \\n                        self.log(type(s[key]))\\n                        self.log(type(self.sel_rules[key][\\'$lt\\']))\\n                        if \\'$eq\\' in self.sel_rules[key] and s[key]==self.sel_rules[key][\\'$eq\\']:\\n                            return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and \\'$lt\\' in self.sel_rules[key]:\\n                            if (s[key]>self.sel_rules[key][\\'$gt\\'] and s[key]<self.sel_rules[key][\\'$lt\\']):\\n                                self.log(\"GT-LT\") \\n                                return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and s[key]>self.sel_rules[key][\\'$gt\\']:\\n                            self.log(\"GT\") \\n                            return True\\n                        elif \\'$lt\\' in self.sel_rules[key] and s[key]<self.sel_rules[key][\\'$lt\\']:\\n                            self.log(\"LT\") \\n                            return True\\n                        else:\\n                            return self.provon\\n        return self.provon\\n\\n    def dicToKeyVal(self, dict, valueToString=False):\\n        try:\\n            alist = list()\\n            for k, v in dict.iteritems():\\n                adic = {}\\n                adic.update({\"key\": str(k)})\\n                if valueToString:\\n                    adic.update({\"val\": str(v)})\\n                else:\\n\\n                    try:\\n                        v = num(v)\\n                        adic.update({\"val\": v})\\n                    except Exception:\\n                        adic.update({\"val\": str(v)})\\n\\n                alist.append(adic)\\n\\n            return alist\\n        except Exception as err:\\n\\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\\n            sys.stderr.write(\\n                \\'ERROR: \\' +\\n                self.name +\\n                \\' dicToKeyVal output Error: \\' +\\n                str(err))\\n#                self.map.put(\"output\",\"\");\\n            traceback.print_exc(file=sys.stderr)\\n\\n    def discardInFlow(self,discardState=False): \\n        self.log(\\'BEFORE \\'+str(self.derivationIds))\\n        \\n        \\n        if discardState==True:\\n            self.derivationIds=[]\\n        else:\\n            maxit=0\\n            state=None\\n            for x in self.derivationIds: \\n                if x[\\'port\\']==\\'_d4p_state\\' and x[\\'iterationIndex\\']>=maxit:\\n                    state=x\\n                    maxit=x[\\'iterationIndex\\']\\n            \\n            if state!=None:   \\n                self.derivationIds=[state]\\n            else:\\n                self.derivationIds=[]\\n        \\n        \\n        self.log(\"ITENDEX \"+str(self.iterationIndex))    \\n        self.log(\\'AFTER \\'+str(self.derivationIds))\\n\\n    def extractExternalInputDataId(self,data,port):\\n        self.makeUniqueId(data,port)\\n\\n    def extractItemMetadata(self, data, port):\\n\\n        return {}\\n\\n    def extractProvenance(\\n            self,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            control={},\\n            attributes={},\\n            error=\"\",\\n            output_port=\"\",\\n            **kwargs):\\n\\n        self.error = error\\n\\n        if isinstance(metadata, list):\\n            metadata.append(attributes)\\n        else:\\n            metadata.update(attributes)\\n        usermeta = {}\\n\\n        if \\'s-prov:skip\\' in control and bool(control[\\'s-prov:skip\\']):\\n            self.provon = False\\n        else:\\n            self.provon = True\\n            usermeta= self.buildUserMetadata(\\n                data,\\n                location=location,\\n                format=format,\\n                metadata=metadata,\\n                control=control,\\n                attributes=attributes,\\n                error=error,\\n                output_port=output_port,\\n                **kwargs)\\n        \\n         \\n        \\n        self.flushData(data, usermeta, output_port)\\n\\n        return usermeta\\n\\n    def flushData(self, data, metadata, port):\\n        trace = {}\\n        stream = data\\n        try:\\n            if self.provon:\\n                self.endTime = datetime.datetime.utcnow()\\n                trace = self.packageAll(metadata)\\n                stream = self.prepareOutputStream(data, trace, port)\\n              \\n            try:\\n                if port is not None and port != \\'_d4p_state\\' \\\\\\n                        and port != \\'error\\':\\n\\n                    super(ProvenancePE, self).write(port, stream)\\n#stream)\\n\\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n            try:\\n                if self.provon:\\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n\\n                            self.sendProvToSensor(trace[\\'metadata\\'])\\n                            \\n                            \\n                            #super(\\n                            #      ProvenancePE,\\n                            #      self).write(\\n                            #                  OUTPUT_METADATA,\\n                            #                  deepcopy(trace[\\'metadata\\']))\\n                            \\n\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                        self.log(\"SENDING: \"+trace[\\'metadata\\'][\\'_id\\'])\\n                        self.sendProvToService(trace[\\'metadata\\'])\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\\n                         self.writeProvToFile(trace[\\'metadata\\'])\\n                     \\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n\\n            return True\\n\\n        except Exception:\\n            self.log(traceback.format_exc())\\n            if self.provon:\\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\\n\\n    def getDataStreams(self, inputs):\\n        streams = {}\\n        for inp in self.inputconnections:\\n            if inp not in inputs:\\n                continue\\n            values = inputs[inp]\\n            if isinstance(values, list):\\n                data = values[0:]\\n            else:\\n                data = values\\n            streams[\"streams\"].update({inp: data})\\n        return streams\\n\\n    def getInputAt(self, port=\"input\", index=0):\\n        return self.inputs[port][index]\\n\\n    def getOutputTypes(self):\\n        \\'\\'\\'\\n        Returns the output types of this PE, in the form of a dictionary.\\n        This method may be overridden if output types are not static and\\n        depend on input types.\\n\\n        .. note::\\n\\n            This method is only called after the input types have been\\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\\n\\n        :rtype: a dictionary mapping each output name to its type\\n\\n        By default it returns a dictionary of the types defined in the\\n        \\'outputconnections\\' instance variable.\\n\\n        Usage example::\\n\\n            def getOutputTypes(self):\\n                output = { \\'output1\\' : myInputs[\\'input1\\'],\\n                           \\'output2\\' : [ \\'comment\\' ] }\\n\\n        \\'\\'\\'\\n        ret = {}\\n        # print \\'%s: %s\\' % (self.id, self.outputconnections)\\n        for name, output in self.outputconnections.items():\\n            try:\\n                ret[name] = output[TYPE]\\n            except KeyError:\\n                raise Exception(\"%s: No output type defined for \\'%s\\'\"\\n                                % (self.id, name))\\n        return ret\\n\\n    def getProvStateObjectId(self,name):\\n        if name in self.statemap:\\n            return self.statemap[name]\\n        else:\\n            return None\\n\\n    def getUniqueId(self,data,port,**kwargs):\\n        data_id = self.makeUniqueId(data,port)\\n        if \\'name\\' in kwargs:\\n            self._updateState(kwargs[\\'name\\'],data_id)\\n\\n\\n\\n        return data_id\\n\\n    def ignoreState(self):\\n        self.ignore_state=True\\n\\n    def importInputData(self, data):\\n\\n        inputs = {}\\n\\n        try:\\n            if not isinstance(data, collections.Iterable):\\n                return data\\n            else:\\n                for x in data:\\n                    #self.log(data[x])\\n                    self.buildDerivation(data[x], port=x)\\n                    if type(data[x])==dict and \\'_d4p\\' in data[x]:\\n                        inputs[x] = data[x][\\'_d4p\\']\\n                    else:\\n                        inputs[x] = data[x]\\n                return inputs\\n\\n        except Exception:\\n            self.output = \"\"\\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\\n            raise\\n\\n    def initParameters(self):\\n\\n        self.error = \\'\\'\\n        self.w3c_prov = {}\\n        #self.resetflow = True\\n        self.inMetaStreams = None\\n        self.username = None\\n        self.runId = None\\n\\n\\n        try:\\n                # self.iterationId = self.name + \\'-\\' + getUniqueId()\\n            if \"username\" in self.controlParameters:\\n                self.username = self.controlParameters[\"username\"]\\n            if \"runId\" in self.controlParameters:\\n                self.runId = self.controlParameters[\"runId\"]\\n\\n        except:\\n                self.runId = \"\"\\n                pass\\n\\n        self.outputdest = self.controlParameters[\\n            \\'outputdest\\'] if \\'outputdest\\' in self.controlParameters else \\'None\\'\\n        self.rootpath = self.controlParameters[\\n            \\'inputrootpath\\'] \\\\\\n            if \\'inputrootpath\\' in self.controlParameters else \\'None\\'\\n        self.outputid = self.controlParameters[\\n            \\'outputid\\'] \\\\\\n            if \\'outputid\\' in self.controlParameters else \\'None\\'\\n\\n    def makeProcessId(self, **kwargs):\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def makeUniqueId(self,data,port):\\n        #if (\\'data\\' in kwargs):\\n        #    self.log(str(kwargs[\\'data\\']))\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def packageAll (self, contentmeta):\\n        metadata = {}\\n        if self.provon:\\n            try:\\n\\n                # identifies the actual iteration over the instance\\n                metadata.update({\\'iterationId\\': self.iterationId,\\n                # identifies the actual writing process\\'\\n                \\'actedOnBehalfOf\\': self.behalfOf,\\n                \\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId()),\\n                \\'iterationIndex\\': self.iterationIndex,\\n                \\'instanceId\\': self.instanceId,\\n                \\'annotations\\': {}})\\n\\n                if self.feedbackIteration:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_feedback_\\' + str(self.makeProcessId())})\\n                elif not self.resetflow:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_stateful_\\' + str(self.makeProcessId())})\\n\\n                else:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId())})\\n\\n\\n                metadata.update({\\'stateful\\': not self.resetflow,\\n                \\'feedbackIteration\\': self.feedbackIteration,\\n                \\'worker\\': socket.gethostname(),\\n                \\'parameters\\': self.dicToKeyVal(self.parameters),\\n                \\'errors\\': self.error,\\n                \\'pid\\': \\'%s\\' % os.getpid()})\\n\\n\\n                 \\n                if self.ignore_inputs==True:\\n                    derivations = [x for x in self.derivationIds if x[\\'port\\']==\\'_d4p_state\\' and x[\\'DerivedFromDatasetID\\'] in self.statemapId]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    self.ignore_inputs = False\\n                \\n                elif self.ignore_state==True:\\n                    self.log(\"IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    derivations = [x for x in self.derivationIds if (x[\\'iterationIndex\\'] == self.iterationIndex or x[\\'port\\']==\\'_d4p_state\\')]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    #self.ignore_state = False\\n                else:\\n                    #if self.resetflow==True:\\n            \\t    #    self.discardOutFlow()\\n                    self.log(\"NOOOT IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    self.log(\"INSERT DERIV: \"+str(self.derivationIds))\\n                    metadata.update({\\'derivationIds\\': self.derivationIds})\\n                    self.ignore_state = False\\n\\n\\n                metadata.update({\\'name\\': self.name,\\n                \\'runId\\': self.runId,\\n                \\'username\\': self.username,\\n                \\'startTime\\': str(self.startTime),\\n                \\'endTime\\': str(self.endTime),\\n                \\'type\\': \\'lineage\\',\\n\\n                \\'streams\\': contentmeta,\\n                \\'mapping\\': sys.argv[1]})\\n                \\n                if hasattr(self, \\'prov_cluster\\'):\\n                     \\n                    metadata.update({\\'prov_cluster\\': self.prov_cluster})\\n                \\n\\n                if self.creator is not None:\\n                    metadata.update({\\'creator\\': self.creator})\\n            except Exception:\\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\\n                self.log(traceback.format_exc())\\n\\n        output = {\\n            \"metadata\": metadata,\\n            \"error\": self.error,\\n            #\"pid\": \"%s\" %\\n            #os.getpid()\\n             }\\n\\n        if self.ignore_state==True:\\n             self.log(\"DADADADAD :\"+str(output))\\n\\n        return output\\n\\n    def pe_init(self, *args, **kwargs):\\n        #ProvenancePE.__init__(self,*args, **kwargs)\\n\\n        global _d4p_plan_sqn\\n        self._add_input(\\'_d4py_feedback\\', grouping=\\'all\\')\\n        self.statemap={}\\n        self.statemapId=[]\\n        self.impcls = None\\n        self.bulk_prov = []\\n\\n\\n        if \\'pe_class\\' in kwargs and kwargs[\\'pe_class\\'] != GenericPE:\\n            self.impcls = kwargs[\\'pe_class\\']\\n       \\n        if \\'sel_rules\\' in kwargs and self.name in kwargs[\\'sel_rules\\']:\\n            print(self.name+\" \"+str(kwargs[\\'sel_rules\\'][self.name]))\\n            self.sel_rules = kwargs[\\'sel_rules\\'][self.name]\\n        else:\\n            self.sel_rules=None\\n        \\n        if \\'creator\\' not in kwargs:\\n            self.creator = None\\n        else:\\n            self.creator = kwargs[\\'creator\\']\\n\\n        self.error = \\'\\'\\n\\n        if not hasattr(self, \\'parameters\\'):\\n            self.parameters = {}\\n        if not hasattr(self, \\'controlParameters\\'):\\n            self.controlParameters = {}\\n\\n        if \\'controlParameters\\' in kwargs:\\n            self.controlParameters = kwargs[\\'controlParameters\\']\\n\\n        out_md = {}\\n        out_md[NAME] = OUTPUT_METADATA\\n\\n        # self.outputconnections[OUTPUT_DATA] = out1\\n        #print(OUTPUT_METADATA)\\n        self._add_output(OUTPUT_METADATA)\\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\\n        self.taskId = str(uuid.uuid1())\\n\\n        # self.appParameters = None\\n        self.provon = True\\n        \\n\\n        if \\'save_mode\\' not in kwargs:\\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\\n        else:\\n            self.save_mode=SAVE_MODE_FILE = kwargs[\\'save_mode\\']\\n\\n\\n        self.resetflow = False\\n        self.stateUpdateIndex=0\\n        self.ignore_inputs = False\\n        self.ignore_state = False\\n        self.derivationIds = list()\\n        self.iterationIndex = 0\\n        self.behalfOf = self.id \\n        #name + \\'_\\' + str(_d4p_plan_sqn)\\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\\n        self.countstatewrite=0\\n        if not hasattr(self, \\'prov_cluster\\'):\\n                    self.prov_cluster=self.behalfOf\\n\\n    def postprocess(self):\\n\\n        \\n        if len(self.bulk_prov)>0:\\n            \\n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n                params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n                headers = {\\n                       \"Content-type\": \"application/x-www-form-urlencoded\",\\n                       \"Accept\": \"application/json\"}\\n                self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n                self.connection.request(\\n                                    \"POST\",\\n                                    self.provurl.path,\\n                                    params,\\n                                    headers)\\n                response = self.connection.getresponse()\\n                self.log(\"Postprocess: \" +\\n                     str((response.status, response.reason, response.read())))\\n#                    response.read())))\\n                self.connection.close()\\n                self.bulk_prov[:]=[]\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\\n                filep = open(ProvenancePE.PROV_PATH + \"/bulk_\" + self.makeProcessId(), \"wr\")\\n                ujson.dump(self.bulk_prov, filep)\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n                super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n            #self.bulk_prov[:]=[]\\n\\n        self._postprocess()\\n\\n    def prepareOutputStream(self, data, trace,port):\\n        try:\\n            streamtransfer = {}\\n            streamtransfer[\\'_d4p\\'] = data\\n            if self.provon:\\n\\n                try:\\n                    streamtransfer[\\'id\\'] = trace[\\n                        \\'metadata\\'][\"streams\"][0][\"id\"]\\n                    streamtransfer[\\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\\n                    streamtransfer[\\n                        \"prov_cluster\"] = self.prov_cluster\\n                    streamtransfer[\\n                        \"port\"] = port\\n                    if port==\\'_d4p_state\\':\\n                        self.log(\\'\\'\\' Building SELF Derivation \\'\\'\\'+str(trace))\\n                        self._updateState(\\'_d4p_state\\',trace[\\n                        \\'metadata\\'][\"streams\"][0][\\'id\\'])\\n                        self.buildDerivation(streamtransfer,port=\\'_d4p_state\\')\\n                        #if self.resetflow==True:\\n\\t\\t\\t\\t\\t\\t#    self.discardOutFlow()\\n                        #self.resetflow=True\\n                except:\\n                    pass\\n            return streamtransfer\\n\\n        except Exception:\\n            self.error += self.name + \" Writing output Error: %s\" % \\\\\\n                traceback.format_exc()\\n            raise\\n\\n    def preprocess(self):\\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\\n            #self.connection = httplib.HTTPConnection(\\n            #                                         self.provurl.netloc)\\n        self._preprocess()\\n\\n    def process(self, inputs):\\n        self.feedbackIteration = False\\n        self.void_iteration = True\\n        self.iterationIndex += 1\\n         \\n        \\n\\n        if \\'_d4py_feedback\\' in inputs:\\n\\n            \\'state could be used here to track the occurring changes\\'\\n            self.process_feedback(inputs[\\'_d4py_feedback\\'])\\n        else:\\n            self.__processwrapper(inputs)\\n\\n        #if (self.void_iteration==True):\\n        self.apply_flow_reset_policy(\\'void_iteration\\',self.void_iteration)\\n\\n    def process_feedback(self, feedback):\\n        self.feedbackIteration = True\\n        self._process_feedback(feedback)\\n\\n    def removeDerivation(self,**kwargs):\\n        if \\'name\\' in kwargs:\\n            id = self.getProvStateObjectId(kwargs[\\'name\\'])\\n            for j in self.derivationIds:\\n\\n                if j[\\'DerivedFromDatasetID\\']==id:\\n\\n                    del self.derivationIds[self.derivationIds.index(j)]\\n        else:\\n            if \\'port\\' in kwargs:\\n                for j in self.derivationIds:\\n\\n                    if j[\\'port\\']==kwargs[\\'port\\']:\\n\\n                        del self.derivationIds[self.derivationIds.index(j)]\\n\\n    def sendProvToSensor(self, prov):\\n        \\n\\n        self.bulk_prov.append(deepcopy(prov))\\n\\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n\\n             \\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def sendProvToService(self, prov):\\n\\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n\\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n\\n        self.bulk_prov.append(deepcopy(prov))\\n        self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n            headers = {\\n                \"Content-type\": \"application/x-www-form-urlencoded\",\\n                \"Accept\": \"application/json\"}\\n            self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n            self.connection.request(\\n                \"POST\", self.provurl.path, params, headers)\\n            response = self.connection.getresponse()\\n            self.log(\"progress: \" + str((response.status, response.reason,response.read())))\\n            #                             response, response.read())))\\n\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def setInputTypes(self, types):\\n        \\'\\'\\'\\n        Sets the input types of this PE, in the form of a dictionary.\\n        It is meant to be overridden, e.g. if output types depend on input.\\n\\n        .. note::\\n\\n            This method is always called before\\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\\n\\n        :param types: object types for each input stream\\n        :type types: dictionary mapping input name to input type\\n\\n        Usage example::\\n\\n            pe.setInputTypes({\\'input1\\':[\\'t1\\', \\'t2\\', \\'t3\\'], \\\\\\n                              \\'input2\\':[\\'t4\\', \\'t5\\']})\\n        \\'\\'\\'\\n        pass\\n\\n    def update_prov_state(\\n            self,\\n            name,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            ignore_inputs=True,\\n            stateless=False,\\n            **kwargs\\n    ):\\n\\n        self.endTime = datetime.datetime.utcnow()\\n        #self.resetflow = stateless\\n        self.ignore_inputs = ignore_inputs\\n        self.addprov=True\\n        kwargs[\\'name\\']=name\\n        #self.apply_flow_reset_policy(\\'state\\', None)\\n        if self.provon:\\n            if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n                for d in kwargs[\\'dep\\']:\\n                    did=self.getProvStateObjectId(d)\\n                    if did!=None:\\n                        self.buildDerivation({\\'id\\':did,\\'TriggeredByProcessIterationID\\':self.iterationId,\\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n\\n\\n            self.extractProvenance(data,\\n                               location,\\n                               format,\\n                               metadata,\\n                               output_port=\"_d4p_state\",\\n                               **kwargs)\\n\\n\\n\\n        self.ignore_inputs = False\\n\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            self.removeDerivation(port=\\'_d4p_state\\')\\n\\n    def write(self, name, data, **kwargs):\\n        self.void_iteration=False\\n        self.apply_flow_reset_policy(\\'write\\',True,port=name,data=data)\\n        # self.__markIteration()\\n        self.endTime = datetime.datetime.utcnow()\\n\\n        #if \\'state_reset\\' in kwargs:\\n        #    self.resetflow = bool(kwargs[\\'state_reset\\'])\\n        #else:\\n        #    None\\n#            self.resetflow = True\\n        \\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.buildDerivation({\\'id\\':self.getProvStateObjectId(d),\\'TriggeredByProcessIterationID\\':self.iterationId, \\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n                #self.log(self.derivationIds)\\n\\n        if \\'ignore_inputs\\' in kwargs:\\n            #self.log(\"IGNORONG: \"+str(self.ignore_inputs))\\n            self.ignore_inputs=kwargs[\\'ignore_inputs\\']\\n        \\n        #if self.resetflow==True:\\n        #    self.discardOutFlow()\\n        \\n        self.extractProvenance(data, output_port=name, **kwargs)\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.removeDerivation(name=d)\\n\\n    def writeProvToFile(self, prov):\\n        \\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n        \\n         \\n        #self.log(\\'PROCESS: \\'+str(prov))\\n        self.bulk_prov.append(prov)\\n        \\n        \\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            filep = open(\\n                ProvenancePE.PROV_PATH +\\n                \"/bulk_\" +\\n                self.makeProcessId(),\\n                \"wr\")\\n            #self.log(\\'PROCESS: \\'+str(filep))\\n            ujson.dump(self.bulk_prov, filep)\\n            #filep.write(json.dumps(self.bulk_prov))\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def writeResults(self, name, result):\\n\\n        #self.resetflow = True\\n        self.apply_flow_reset_policy(\\'write\\',True,data=data,port=name)\\n        self.void_iteration=False\\n        \\n        \\n\\n        if isinstance(result, dict) and \\'_d4p_prov\\' in result:\\n            meta = result[\\'_d4p_prov\\']\\n            result = (result[\\'_d4p_data\\'])\\n\\n            if \\'error\\' in meta:\\n                self.extractProvenance(result, output_port=name, **meta)\\n            else:\\n\\n                self.extractProvenance(\\n                    result, error=self.error, output_port=name, **meta)\\n\\n        else:\\n            self.extractProvenance(result, error=self.error, output_port=name)\\n\\n', 'type': \"(<class 'dispel4py.provenance.ProvenancePE'>, <class '__main__.Read'>)\"}, 'StoreFile6': {'code': u'    def __computewrapper(self, inputs):\\n\\n        try:\\n            result = None\\n\\n            self.__markIteration()\\n\\n            if self.impcls is not None and isinstance(self, self.impcls):\\n                try:\\n                    if hasattr(self, \\'params\\'):\\n                        self.parameters = self.params\\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\\n                    if result is not None:\\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\\n                except:\\n                    result = self._process(inputs)\\n            else:\\n                result = self._process(inputs)\\n\\n            if result is not None:\\n                return result\\n\\n        except Exception:\\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\\n            # self.endTime = datetime.datetime.utcnow()\\n            self.writeResults(\\'error\\', {\\'error\\': \\'null\\'})\\n\\n    def __getUniqueId(self):\\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\\\\n            \"-\" + str(uuid.uuid1())\\n\\n    def __importInputMetadata(self):\\n        try:\\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\\n        except Exception:\\n            None\\n\\n    def __markIteration(self):\\n        self.startTime = datetime.datetime.utcnow()\\n        self.iterationId = self.name + \\'-\\' + self.makeProcessId()\\n\\n    def __processwrapper(self, data):\\n        try:\\n\\n            self.initParameters()\\n\\n            inputs = self.importInputData(data)\\n            # self.__importInputMetadata()\\n            return self.__computewrapper(inputs)\\n\\n        except:\\n            self.log(traceback.format_exc())\\n\\n    def __init__(self):\\n        ProvenancePE.__init__(self)\\n        self.ns={\"clipc\":\"http://clipc.eu/ns/#\"}\\n\\n    def _add_input(self, name, grouping=None, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an input for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\\n\\n        :param name: name of the input\\n        :param grouping: the grouping type that this input expects (optional)\\n        :param tuple_type: type of tuples accepted by this input (optional)\\n        \\'\\'\\'\\n        self.inputconnections[name] = {NAME: name}\\n        if grouping:\\n            self.inputconnections[name][GROUPING] = grouping\\n        if tuple_type:\\n            self.inputconnections[name][TYPE] = tuple_type\\n\\n    def _add_output(self, name, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an output for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\\n\\n        :param name: name of the output\\n        :param tuple_type: type of tuples produced by this output (optional)\\n        \\'\\'\\'\\n        self.outputconnections[name] = {NAME: name}\\n        if tuple_type:\\n            self.outputconnections[name][TYPE] = tuple_type\\n\\n    def _postprocess(self):\\n        None\\n\\n    def _preprocess(self):\\n        self.instanceId = self.name + \"-Instance-\" + \\\\\\n            \"-\" + self.makeProcessId()\\n\\n        super(ProvenancePE, self)._preprocess()\\n\\n    def _process(self,inputs):\\n        self.log(\\'Write_Function\\')\\n        \\n        outputLocation = inputs[1]\\n        \\n        #specifies location and allocate a new id to the output data consistently into the provenance and file \\n        self.write(\\'storedData\\', (inputs[0],inputs[1]),location=outputLocation )\\n\\n        #the data is stored with the new id \\n        inputs[0].to_netcdf( outputLocation )\\n\\n    def _updateState(self,name,id):\\n        if name in self.statemap:\\n                self.statemapId.remove(self.statemap[name])\\n        self.statemap[name]=id\\n        self.statemapId.append(id)\\n\\n    def _write(self, name, data, **kwargs):\\n        \\'\\'\\'\\n        This writes the \\'data\\' to the output pipe with name \\'name\\' of this PE.\\n        \\'\\'\\'\\n         \\n        try:\\n            output = self.outputconnections[name]\\n            output[WRITER].write(data)\\n        except KeyError:\\n            raise Exception(\"Can\\'t write data: Unknown output connection\\\\\\n                            \\'%s\\' for PE \\'%s\\'\" % (name, type(self).__name__))\\n\\n    def apply_flow_reset_policy(self,event,value,port=None,data=None):\\n        \\n        if (event==\\'void_iteration\\') and value==True:\\n            self.discardInFlow()\\n        \\n        if (event==\\'void_iteration\\') and value==False:\\n            self.discardInFlow()\\n\\n    def buildDerivation(self, data, port=\"\"):\\n\\t\\t\\n        try:\\n\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          data[\\'id\\'], \\'TriggeredByProcessIterationID\\':\\n                          data[\\'TriggeredByProcessIterationID\\'], \\'prov_cluster\\':\\n                          data[\\'prov_cluster\\'],\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n                          \\n           # if port==\"_d4p_state\": \\n           #     derivation.update({\\'iterationIndex\\':self.iterationIndex})\\n                 \\n\\t\\t    \\n\\n            self.derivationIds.append(derivation)\\n\\n        except Exception:\\n            id=self.extractExternalInputDataId(data,port)\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          id, \\'TriggeredByProcessIterationID\\':\\n                          None, \\'prov_cluster\\':\\n                          None,\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n            self.derivationIds.append(derivation)\\n            self.log(\"BUILDING INITIAL DERIVATION\")\\n\\n    def buildUserMetadata(self, data, **kwargs):\\n        streamlist = list()\\n\\n        streamItem = {}\\n        streammeta = []\\n\\n        streammeta = self.extractItemMetadata(data,kwargs[\\'output_port\\'])\\n        \\n        if not isinstance(streammeta, list):\\n            streammeta = kwargs[\\'metadata\\'] if isinstance(\\n                kwargs[\\'metadata\\'], list) else [kwargs[\\'metadata\\']]\\n        elif isinstance(streammeta, list):\\n            try:\\n                if isinstance(kwargs[\\'metadata\\'], list):\\n                    streammeta = streammeta + kwargs[\\'metadata\\']\\n                if isinstance(kwargs[\\'metadata\\'], dict):\\n                    for y in streammeta:\\n                        y.update(kwargs[\\'metadata\\'])\\n            except:\\n                traceback.print_exc(file=sys.stderr)\\n                None\\n        \\n        if self.sel_rules!=None:\\n            self.provon=self.checkSelectiveRule(streammeta)\\n            \\n        if not self.provon:\\n            return streamItem\\n        #self.log(kwargs)\\n        streamItem.update({\"content\": streammeta,\\n                           \"id\": self.getUniqueId(data,kwargs[\\'output_port\\'],**kwargs),\\n                           \"format\": \"\",\\n                           \"location\": \"\",\\n                           \"annotations\": [],\\n                           \"port\": kwargs[\\'output_port\\']})\\n        # if (self.streamItemsControl!={,:\\n        streamItem.update(kwargs[\\'control\\'])\\n        # if (self.streamItemsLocations!={,:\\n        streamItem.update({\"location\": kwargs[\\'location\\'],\\n                          \"format\": kwargs[\\'format\\']})\\n        #streamItem.update({\"size\": total_size(data)})\\n        streamItem.update({\"size\": 0})\\n        streamlist.append(streamItem)\\n        return streamlist\\n\\n    def checkSelectiveRule(self,streammeta):\\n        self.log(\"Checking Skip-Rules\")\\n        for key in self.sel_rules:\\n                for s in streammeta:\\n                    if key in s: \\n                        self.log(\"A\"+str(self.sel_rules[key]))\\n                        self.log(s[key]) \\n                        self.log(type(s[key]))\\n                        self.log(type(self.sel_rules[key][\\'$lt\\']))\\n                        if \\'$eq\\' in self.sel_rules[key] and s[key]==self.sel_rules[key][\\'$eq\\']:\\n                            return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and \\'$lt\\' in self.sel_rules[key]:\\n                            if (s[key]>self.sel_rules[key][\\'$gt\\'] and s[key]<self.sel_rules[key][\\'$lt\\']):\\n                                self.log(\"GT-LT\") \\n                                return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and s[key]>self.sel_rules[key][\\'$gt\\']:\\n                            self.log(\"GT\") \\n                            return True\\n                        elif \\'$lt\\' in self.sel_rules[key] and s[key]<self.sel_rules[key][\\'$lt\\']:\\n                            self.log(\"LT\") \\n                            return True\\n                        else:\\n                            return self.provon\\n        return self.provon\\n\\n    def dicToKeyVal(self, dict, valueToString=False):\\n        try:\\n            alist = list()\\n            for k, v in dict.iteritems():\\n                adic = {}\\n                adic.update({\"key\": str(k)})\\n                if valueToString:\\n                    adic.update({\"val\": str(v)})\\n                else:\\n\\n                    try:\\n                        v = num(v)\\n                        adic.update({\"val\": v})\\n                    except Exception:\\n                        adic.update({\"val\": str(v)})\\n\\n                alist.append(adic)\\n\\n            return alist\\n        except Exception as err:\\n\\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\\n            sys.stderr.write(\\n                \\'ERROR: \\' +\\n                self.name +\\n                \\' dicToKeyVal output Error: \\' +\\n                str(err))\\n#                self.map.put(\"output\",\"\");\\n            traceback.print_exc(file=sys.stderr)\\n\\n    def discardInFlow(self,discardState=False): \\n        self.log(\\'BEFORE \\'+str(self.derivationIds))\\n        \\n        \\n        if discardState==True:\\n            self.derivationIds=[]\\n        else:\\n            maxit=0\\n            state=None\\n            for x in self.derivationIds: \\n                if x[\\'port\\']==\\'_d4p_state\\' and x[\\'iterationIndex\\']>=maxit:\\n                    state=x\\n                    maxit=x[\\'iterationIndex\\']\\n            \\n            if state!=None:   \\n                self.derivationIds=[state]\\n            else:\\n                self.derivationIds=[]\\n        \\n        \\n        self.log(\"ITENDEX \"+str(self.iterationIndex))    \\n        self.log(\\'AFTER \\'+str(self.derivationIds))\\n\\n    def extractExternalInputDataId(self,data, input_port):\\n        #Extract here the id from the data (type specific):\\n\\n        self.log(\\'ANDREJ.extractExternalInputDataId\\')\\n        #self.log(data)\\n        \\n        try:\\n            #ds = xarray.open_dataset(data[\\'input\\'][0])\\n            ds = xarray.open_dataset(data[0])\\n            id = ds.attrs[\\'id\\']\\n            \\n        except Exception, err:\\n            id = str(uuid.uuid1())\\n            self.log(str(err))\\n        #Return\\n        return id\\n\\n    def extractItemMetadata(self, data, output_port):\\n         \\n        self.log(\\'ANDREJ.extractItemMetadata\\')\\n        #self.log(data)\\n        \\n        try:            \\n            nc_meta = OrderedDict()\\n            \\n            \\'\\'\\' cycle throug all attributes, dimensions and variables \\'\\'\\'\\n            xa = data[0]\\n                        \\n            # dataset meta\\n            nc_meta[\\'Dimensions\\'] = str( dict(xa.dims)) \\n            nc_meta[\\'Type\\'] = str(type(xa))\\n            \\n            # global attr\\n            for k , v in xa.attrs.items():\\n                nc_meta[\\'clipc:\\'+str(k).replace(\".\",\"_\")] = str(v)\\n            # vars attr   \\n            for n , i in xa.data_vars.items():\\n                for k , v in i.attrs.items():\\n                    nc_meta[\\'clipc:\\'+n+\"_\"+str(k).replace(\".\",\"_\")] = str(v)\\n            \\n            #pprint(nc_meta)\\n        \\n            metadata = [nc_meta]\\n            \\n            return metadata\\n                             \\n        except Exception, err:\\n            self.log(\"Applying default metadata extraction:\"+str(traceback.format_exc()))\\n            self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\\n            return super(netcdfProvType, self).extractItemMetadata(data);\\n\\n    def extractProvenance(\\n            self,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            control={},\\n            attributes={},\\n            error=\"\",\\n            output_port=\"\",\\n            **kwargs):\\n\\n        self.error = error\\n\\n        if isinstance(metadata, list):\\n            metadata.append(attributes)\\n        else:\\n            metadata.update(attributes)\\n        usermeta = {}\\n\\n        if \\'s-prov:skip\\' in control and bool(control[\\'s-prov:skip\\']):\\n            self.provon = False\\n        else:\\n            self.provon = True\\n            usermeta= self.buildUserMetadata(\\n                data,\\n                location=location,\\n                format=format,\\n                metadata=metadata,\\n                control=control,\\n                attributes=attributes,\\n                error=error,\\n                output_port=output_port,\\n                **kwargs)\\n        \\n         \\n        \\n        self.flushData(data, usermeta, output_port)\\n\\n        return usermeta\\n\\n    def flushData(self, data, metadata, port):\\n        trace = {}\\n        stream = data\\n        try:\\n            if self.provon:\\n                self.endTime = datetime.datetime.utcnow()\\n                trace = self.packageAll(metadata)\\n                stream = self.prepareOutputStream(data, trace, port)\\n              \\n            try:\\n                if port is not None and port != \\'_d4p_state\\' \\\\\\n                        and port != \\'error\\':\\n\\n                    super(ProvenancePE, self).write(port, stream)\\n#stream)\\n\\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n            try:\\n                if self.provon:\\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n\\n                            self.sendProvToSensor(trace[\\'metadata\\'])\\n                            \\n                            \\n                            #super(\\n                            #      ProvenancePE,\\n                            #      self).write(\\n                            #                  OUTPUT_METADATA,\\n                            #                  deepcopy(trace[\\'metadata\\']))\\n                            \\n\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                        self.log(\"SENDING: \"+trace[\\'metadata\\'][\\'_id\\'])\\n                        self.sendProvToService(trace[\\'metadata\\'])\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\\n                         self.writeProvToFile(trace[\\'metadata\\'])\\n                     \\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n\\n            return True\\n\\n        except Exception:\\n            self.log(traceback.format_exc())\\n            if self.provon:\\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\\n\\n    def getDataStreams(self, inputs):\\n        streams = {}\\n        for inp in self.inputconnections:\\n            if inp not in inputs:\\n                continue\\n            values = inputs[inp]\\n            if isinstance(values, list):\\n                data = values[0:]\\n            else:\\n                data = values\\n            streams[\"streams\"].update({inp: data})\\n        return streams\\n\\n    def getInputAt(self, port=\"input\", index=0):\\n        return self.inputs[port][index]\\n\\n    def getOutputTypes(self):\\n        \\'\\'\\'\\n        Returns the output types of this PE, in the form of a dictionary.\\n        This method may be overridden if output types are not static and\\n        depend on input types.\\n\\n        .. note::\\n\\n            This method is only called after the input types have been\\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\\n\\n        :rtype: a dictionary mapping each output name to its type\\n\\n        By default it returns a dictionary of the types defined in the\\n        \\'outputconnections\\' instance variable.\\n\\n        Usage example::\\n\\n            def getOutputTypes(self):\\n                output = { \\'output1\\' : myInputs[\\'input1\\'],\\n                           \\'output2\\' : [ \\'comment\\' ] }\\n\\n        \\'\\'\\'\\n        ret = {}\\n        # print \\'%s: %s\\' % (self.id, self.outputconnections)\\n        for name, output in self.outputconnections.items():\\n            try:\\n                ret[name] = output[TYPE]\\n            except KeyError:\\n                raise Exception(\"%s: No output type defined for \\'%s\\'\"\\n                                % (self.id, name))\\n        return ret\\n\\n    def getProvStateObjectId(self,name):\\n        if name in self.statemap:\\n            return self.statemap[name]\\n        else:\\n            return None\\n\\n    def getUniqueId(self,data,port,**kwargs):\\n        data_id = self.makeUniqueId(data,port)\\n        if \\'name\\' in kwargs:\\n            self._updateState(kwargs[\\'name\\'],data_id)\\n\\n\\n\\n        return data_id\\n\\n    def ignoreState(self):\\n        self.ignore_state=True\\n\\n    def importInputData(self, data):\\n\\n        inputs = {}\\n\\n        try:\\n            if not isinstance(data, collections.Iterable):\\n                return data\\n            else:\\n                for x in data:\\n                    #self.log(data[x])\\n                    self.buildDerivation(data[x], port=x)\\n                    if type(data[x])==dict and \\'_d4p\\' in data[x]:\\n                        inputs[x] = data[x][\\'_d4p\\']\\n                    else:\\n                        inputs[x] = data[x]\\n                return inputs\\n\\n        except Exception:\\n            self.output = \"\"\\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\\n            raise\\n\\n    def initParameters(self):\\n\\n        self.error = \\'\\'\\n        self.w3c_prov = {}\\n        #self.resetflow = True\\n        self.inMetaStreams = None\\n        self.username = None\\n        self.runId = None\\n\\n\\n        try:\\n                # self.iterationId = self.name + \\'-\\' + getUniqueId()\\n            if \"username\" in self.controlParameters:\\n                self.username = self.controlParameters[\"username\"]\\n            if \"runId\" in self.controlParameters:\\n                self.runId = self.controlParameters[\"runId\"]\\n\\n        except:\\n                self.runId = \"\"\\n                pass\\n\\n        self.outputdest = self.controlParameters[\\n            \\'outputdest\\'] if \\'outputdest\\' in self.controlParameters else \\'None\\'\\n        self.rootpath = self.controlParameters[\\n            \\'inputrootpath\\'] \\\\\\n            if \\'inputrootpath\\' in self.controlParameters else \\'None\\'\\n        self.outputid = self.controlParameters[\\n            \\'outputid\\'] \\\\\\n            if \\'outputid\\' in self.controlParameters else \\'None\\'\\n\\n    def makeProcessId(self, **kwargs):\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def makeUniqueId(self, data, output_port):      \\n        \\n        self.log(\\'ANDREJ.makeUniqueId\\')\\n        #self.log(kwargs)\\n        \\n        #produce the id\\n        \\n        id=str(uuid.uuid1())\\n            \\n        \\'\\'\\' nc data \\'\\'\\'\\n        xa = data[0]\\n        \\n        \\'\\'\\' unique as defined by the community standard \\'\\'\\'\\n        xa.attrs[\\'id\\'] = id\\n        \\n        #Return\\n        return id \\n\\n    def packageAll (self, contentmeta):\\n        metadata = {}\\n        if self.provon:\\n            try:\\n\\n                # identifies the actual iteration over the instance\\n                metadata.update({\\'iterationId\\': self.iterationId,\\n                # identifies the actual writing process\\'\\n                \\'actedOnBehalfOf\\': self.behalfOf,\\n                \\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId()),\\n                \\'iterationIndex\\': self.iterationIndex,\\n                \\'instanceId\\': self.instanceId,\\n                \\'annotations\\': {}})\\n\\n                if self.feedbackIteration:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_feedback_\\' + str(self.makeProcessId())})\\n                elif not self.resetflow:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_stateful_\\' + str(self.makeProcessId())})\\n\\n                else:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId())})\\n\\n\\n                metadata.update({\\'stateful\\': not self.resetflow,\\n                \\'feedbackIteration\\': self.feedbackIteration,\\n                \\'worker\\': socket.gethostname(),\\n                \\'parameters\\': self.dicToKeyVal(self.parameters),\\n                \\'errors\\': self.error,\\n                \\'pid\\': \\'%s\\' % os.getpid()})\\n\\n\\n                 \\n                if self.ignore_inputs==True:\\n                    derivations = [x for x in self.derivationIds if x[\\'port\\']==\\'_d4p_state\\' and x[\\'DerivedFromDatasetID\\'] in self.statemapId]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    self.ignore_inputs = False\\n                \\n                elif self.ignore_state==True:\\n                    self.log(\"IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    derivations = [x for x in self.derivationIds if (x[\\'iterationIndex\\'] == self.iterationIndex or x[\\'port\\']==\\'_d4p_state\\')]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    #self.ignore_state = False\\n                else:\\n                    #if self.resetflow==True:\\n            \\t    #    self.discardOutFlow()\\n                    self.log(\"NOOOT IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    self.log(\"INSERT DERIV: \"+str(self.derivationIds))\\n                    metadata.update({\\'derivationIds\\': self.derivationIds})\\n                    self.ignore_state = False\\n\\n\\n                metadata.update({\\'name\\': self.name,\\n                \\'runId\\': self.runId,\\n                \\'username\\': self.username,\\n                \\'startTime\\': str(self.startTime),\\n                \\'endTime\\': str(self.endTime),\\n                \\'type\\': \\'lineage\\',\\n\\n                \\'streams\\': contentmeta,\\n                \\'mapping\\': sys.argv[1]})\\n                \\n                if hasattr(self, \\'prov_cluster\\'):\\n                     \\n                    metadata.update({\\'prov_cluster\\': self.prov_cluster})\\n                \\n\\n                if self.creator is not None:\\n                    metadata.update({\\'creator\\': self.creator})\\n            except Exception:\\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\\n                self.log(traceback.format_exc())\\n\\n        output = {\\n            \"metadata\": metadata,\\n            \"error\": self.error,\\n            #\"pid\": \"%s\" %\\n            #os.getpid()\\n             }\\n\\n        if self.ignore_state==True:\\n             self.log(\"DADADADAD :\"+str(output))\\n\\n        return output\\n\\n    def pe_init(self, *args, **kwargs):\\n        #ProvenancePE.__init__(self,*args, **kwargs)\\n\\n        global _d4p_plan_sqn\\n        self._add_input(\\'_d4py_feedback\\', grouping=\\'all\\')\\n        self.statemap={}\\n        self.statemapId=[]\\n        self.impcls = None\\n        self.bulk_prov = []\\n\\n\\n        if \\'pe_class\\' in kwargs and kwargs[\\'pe_class\\'] != GenericPE:\\n            self.impcls = kwargs[\\'pe_class\\']\\n       \\n        if \\'sel_rules\\' in kwargs and self.name in kwargs[\\'sel_rules\\']:\\n            print(self.name+\" \"+str(kwargs[\\'sel_rules\\'][self.name]))\\n            self.sel_rules = kwargs[\\'sel_rules\\'][self.name]\\n        else:\\n            self.sel_rules=None\\n        \\n        if \\'creator\\' not in kwargs:\\n            self.creator = None\\n        else:\\n            self.creator = kwargs[\\'creator\\']\\n\\n        self.error = \\'\\'\\n\\n        if not hasattr(self, \\'parameters\\'):\\n            self.parameters = {}\\n        if not hasattr(self, \\'controlParameters\\'):\\n            self.controlParameters = {}\\n\\n        if \\'controlParameters\\' in kwargs:\\n            self.controlParameters = kwargs[\\'controlParameters\\']\\n\\n        out_md = {}\\n        out_md[NAME] = OUTPUT_METADATA\\n\\n        # self.outputconnections[OUTPUT_DATA] = out1\\n        #print(OUTPUT_METADATA)\\n        self._add_output(OUTPUT_METADATA)\\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\\n        self.taskId = str(uuid.uuid1())\\n\\n        # self.appParameters = None\\n        self.provon = True\\n        \\n\\n        if \\'save_mode\\' not in kwargs:\\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\\n        else:\\n            self.save_mode=SAVE_MODE_FILE = kwargs[\\'save_mode\\']\\n\\n\\n        self.resetflow = False\\n        self.stateUpdateIndex=0\\n        self.ignore_inputs = False\\n        self.ignore_state = False\\n        self.derivationIds = list()\\n        self.iterationIndex = 0\\n        self.behalfOf = self.id \\n        #name + \\'_\\' + str(_d4p_plan_sqn)\\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\\n        self.countstatewrite=0\\n        if not hasattr(self, \\'prov_cluster\\'):\\n                    self.prov_cluster=self.behalfOf\\n\\n    def postprocess(self):\\n\\n        \\n        if len(self.bulk_prov)>0:\\n            \\n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n                params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n                headers = {\\n                       \"Content-type\": \"application/x-www-form-urlencoded\",\\n                       \"Accept\": \"application/json\"}\\n                self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n                self.connection.request(\\n                                    \"POST\",\\n                                    self.provurl.path,\\n                                    params,\\n                                    headers)\\n                response = self.connection.getresponse()\\n                self.log(\"Postprocess: \" +\\n                     str((response.status, response.reason, response.read())))\\n#                    response.read())))\\n                self.connection.close()\\n                self.bulk_prov[:]=[]\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\\n                filep = open(ProvenancePE.PROV_PATH + \"/bulk_\" + self.makeProcessId(), \"wr\")\\n                ujson.dump(self.bulk_prov, filep)\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n                super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n            #self.bulk_prov[:]=[]\\n\\n        self._postprocess()\\n\\n    def prepareOutputStream(self, data, trace,port):\\n        try:\\n            streamtransfer = {}\\n            streamtransfer[\\'_d4p\\'] = data\\n            if self.provon:\\n\\n                try:\\n                    streamtransfer[\\'id\\'] = trace[\\n                        \\'metadata\\'][\"streams\"][0][\"id\"]\\n                    streamtransfer[\\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\\n                    streamtransfer[\\n                        \"prov_cluster\"] = self.prov_cluster\\n                    streamtransfer[\\n                        \"port\"] = port\\n                    if port==\\'_d4p_state\\':\\n                        self.log(\\'\\'\\' Building SELF Derivation \\'\\'\\'+str(trace))\\n                        self._updateState(\\'_d4p_state\\',trace[\\n                        \\'metadata\\'][\"streams\"][0][\\'id\\'])\\n                        self.buildDerivation(streamtransfer,port=\\'_d4p_state\\')\\n                        #if self.resetflow==True:\\n\\t\\t\\t\\t\\t\\t#    self.discardOutFlow()\\n                        #self.resetflow=True\\n                except:\\n                    pass\\n            return streamtransfer\\n\\n        except Exception:\\n            self.error += self.name + \" Writing output Error: %s\" % \\\\\\n                traceback.format_exc()\\n            raise\\n\\n    def preprocess(self):\\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\\n            #self.connection = httplib.HTTPConnection(\\n            #                                         self.provurl.netloc)\\n        self._preprocess()\\n\\n    def process(self, inputs):\\n        self.feedbackIteration = False\\n        self.void_iteration = True\\n        self.iterationIndex += 1\\n         \\n        \\n\\n        if \\'_d4py_feedback\\' in inputs:\\n\\n            \\'state could be used here to track the occurring changes\\'\\n            self.process_feedback(inputs[\\'_d4py_feedback\\'])\\n        else:\\n            self.__processwrapper(inputs)\\n\\n        #if (self.void_iteration==True):\\n        self.apply_flow_reset_policy(\\'void_iteration\\',self.void_iteration)\\n\\n    def process_feedback(self, feedback):\\n        self.feedbackIteration = True\\n        self._process_feedback(feedback)\\n\\n    def removeDerivation(self,**kwargs):\\n        if \\'name\\' in kwargs:\\n            id = self.getProvStateObjectId(kwargs[\\'name\\'])\\n            for j in self.derivationIds:\\n\\n                if j[\\'DerivedFromDatasetID\\']==id:\\n\\n                    del self.derivationIds[self.derivationIds.index(j)]\\n        else:\\n            if \\'port\\' in kwargs:\\n                for j in self.derivationIds:\\n\\n                    if j[\\'port\\']==kwargs[\\'port\\']:\\n\\n                        del self.derivationIds[self.derivationIds.index(j)]\\n\\n    def sendProvToSensor(self, prov):\\n        \\n\\n        self.bulk_prov.append(deepcopy(prov))\\n\\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n\\n             \\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def sendProvToService(self, prov):\\n\\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n\\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n\\n        self.bulk_prov.append(deepcopy(prov))\\n        self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n            headers = {\\n                \"Content-type\": \"application/x-www-form-urlencoded\",\\n                \"Accept\": \"application/json\"}\\n            self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n            self.connection.request(\\n                \"POST\", self.provurl.path, params, headers)\\n            response = self.connection.getresponse()\\n            self.log(\"progress: \" + str((response.status, response.reason,response.read())))\\n            #                             response, response.read())))\\n\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def setInputTypes(self, types):\\n        \\'\\'\\'\\n        Sets the input types of this PE, in the form of a dictionary.\\n        It is meant to be overridden, e.g. if output types depend on input.\\n\\n        .. note::\\n\\n            This method is always called before\\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\\n\\n        :param types: object types for each input stream\\n        :type types: dictionary mapping input name to input type\\n\\n        Usage example::\\n\\n            pe.setInputTypes({\\'input1\\':[\\'t1\\', \\'t2\\', \\'t3\\'], \\\\\\n                              \\'input2\\':[\\'t4\\', \\'t5\\']})\\n        \\'\\'\\'\\n        pass\\n\\n    def update_prov_state(\\n            self,\\n            name,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            ignore_inputs=True,\\n            stateless=False,\\n            **kwargs\\n    ):\\n\\n        self.endTime = datetime.datetime.utcnow()\\n        #self.resetflow = stateless\\n        self.ignore_inputs = ignore_inputs\\n        self.addprov=True\\n        kwargs[\\'name\\']=name\\n        #self.apply_flow_reset_policy(\\'state\\', None)\\n        if self.provon:\\n            if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n                for d in kwargs[\\'dep\\']:\\n                    did=self.getProvStateObjectId(d)\\n                    if did!=None:\\n                        self.buildDerivation({\\'id\\':did,\\'TriggeredByProcessIterationID\\':self.iterationId,\\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n\\n\\n            self.extractProvenance(data,\\n                               location,\\n                               format,\\n                               metadata,\\n                               output_port=\"_d4p_state\",\\n                               **kwargs)\\n\\n\\n\\n        self.ignore_inputs = False\\n\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            self.removeDerivation(port=\\'_d4p_state\\')\\n\\n    def write(self, name, data, **kwargs):\\n        self.void_iteration=False\\n        self.apply_flow_reset_policy(\\'write\\',True,port=name,data=data)\\n        # self.__markIteration()\\n        self.endTime = datetime.datetime.utcnow()\\n\\n        #if \\'state_reset\\' in kwargs:\\n        #    self.resetflow = bool(kwargs[\\'state_reset\\'])\\n        #else:\\n        #    None\\n#            self.resetflow = True\\n        \\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.buildDerivation({\\'id\\':self.getProvStateObjectId(d),\\'TriggeredByProcessIterationID\\':self.iterationId, \\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n                #self.log(self.derivationIds)\\n\\n        if \\'ignore_inputs\\' in kwargs:\\n            #self.log(\"IGNORONG: \"+str(self.ignore_inputs))\\n            self.ignore_inputs=kwargs[\\'ignore_inputs\\']\\n        \\n        #if self.resetflow==True:\\n        #    self.discardOutFlow()\\n        \\n        self.extractProvenance(data, output_port=name, **kwargs)\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.removeDerivation(name=d)\\n\\n    def writeProvToFile(self, prov):\\n        \\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n        \\n         \\n        #self.log(\\'PROCESS: \\'+str(prov))\\n        self.bulk_prov.append(prov)\\n        \\n        \\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            filep = open(\\n                ProvenancePE.PROV_PATH +\\n                \"/bulk_\" +\\n                self.makeProcessId(),\\n                \"wr\")\\n            #self.log(\\'PROCESS: \\'+str(filep))\\n            ujson.dump(self.bulk_prov, filep)\\n            #filep.write(json.dumps(self.bulk_prov))\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def writeResults(self, name, result):\\n\\n        #self.resetflow = True\\n        self.apply_flow_reset_policy(\\'write\\',True,data=data,port=name)\\n        self.void_iteration=False\\n        \\n        \\n\\n        if isinstance(result, dict) and \\'_d4p_prov\\' in result:\\n            meta = result[\\'_d4p_prov\\']\\n            result = (result[\\'_d4p_data\\'])\\n\\n            if \\'error\\' in meta:\\n                self.extractProvenance(result, output_port=name, **meta)\\n            else:\\n\\n                self.extractProvenance(\\n                    result, error=self.error, output_port=name, **meta)\\n\\n        else:\\n            self.extractProvenance(result, error=self.error, output_port=name)\\n\\n', 'type': \"(<class '__main__.netcdfProvType'>, <class '__main__.Write'>)\"}, 'StoreThreshold7': {'code': u'    def __computewrapper(self, inputs):\\n\\n        try:\\n            result = None\\n\\n            self.__markIteration()\\n\\n            if self.impcls is not None and isinstance(self, self.impcls):\\n                try:\\n                    if hasattr(self, \\'params\\'):\\n                        self.parameters = self.params\\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\\n                    if result is not None:\\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\\n                except:\\n                    result = self._process(inputs)\\n            else:\\n                result = self._process(inputs)\\n\\n            if result is not None:\\n                return result\\n\\n        except Exception:\\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\\n            # self.endTime = datetime.datetime.utcnow()\\n            self.writeResults(\\'error\\', {\\'error\\': \\'null\\'})\\n\\n    def __getUniqueId(self):\\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\\\\n            \"-\" + str(uuid.uuid1())\\n\\n    def __importInputMetadata(self):\\n        try:\\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\\n        except Exception:\\n            None\\n\\n    def __markIteration(self):\\n        self.startTime = datetime.datetime.utcnow()\\n        self.iterationId = self.name + \\'-\\' + self.makeProcessId()\\n\\n    def __processwrapper(self, data):\\n        try:\\n\\n            self.initParameters()\\n\\n            inputs = self.importInputData(data)\\n            # self.__importInputMetadata()\\n            return self.__computewrapper(inputs)\\n\\n        except:\\n            self.log(traceback.format_exc())\\n\\n    def __init__(self):\\n        GenericPE.__init__(self)\\n        self.parameters = {}\\n        self._add_output(OUTPUT_METADATA)\\n\\n    def _add_input(self, name, grouping=None, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an input for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\\n\\n        :param name: name of the input\\n        :param grouping: the grouping type that this input expects (optional)\\n        :param tuple_type: type of tuples accepted by this input (optional)\\n        \\'\\'\\'\\n        self.inputconnections[name] = {NAME: name}\\n        if grouping:\\n            self.inputconnections[name][GROUPING] = grouping\\n        if tuple_type:\\n            self.inputconnections[name][TYPE] = tuple_type\\n\\n    def _add_output(self, name, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an output for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\\n\\n        :param name: name of the output\\n        :param tuple_type: type of tuples produced by this output (optional)\\n        \\'\\'\\'\\n        self.outputconnections[name] = {NAME: name}\\n        if tuple_type:\\n            self.outputconnections[name][TYPE] = tuple_type\\n\\n    def _postprocess(self):\\n        None\\n\\n    def _preprocess(self):\\n        self.instanceId = self.name + \"-Instance-\" + \\\\\\n            \"-\" + self.makeProcessId()\\n\\n        super(ProvenancePE, self)._preprocess()\\n\\n    def _process(self,inputs):\\n        self.log(\\'Write_Function\\')\\n        \\n        outputLocation = inputs[1]\\n        \\n        #specifies location and allocate a new id to the output data consistently into the provenance and file \\n        self.write(\\'storedData\\', (inputs[0],inputs[1]),location=outputLocation )\\n\\n        #the data is stored with the new id \\n        inputs[0].to_netcdf( outputLocation )\\n\\n    def _updateState(self,name,id):\\n        if name in self.statemap:\\n                self.statemapId.remove(self.statemap[name])\\n        self.statemap[name]=id\\n        self.statemapId.append(id)\\n\\n    def _write(self, name, data, **kwargs):\\n        \\'\\'\\'\\n        This writes the \\'data\\' to the output pipe with name \\'name\\' of this PE.\\n        \\'\\'\\'\\n         \\n        try:\\n            output = self.outputconnections[name]\\n            output[WRITER].write(data)\\n        except KeyError:\\n            raise Exception(\"Can\\'t write data: Unknown output connection\\\\\\n                            \\'%s\\' for PE \\'%s\\'\" % (name, type(self).__name__))\\n\\n    def apply_flow_reset_policy(self,event,value,port=None,data=None):\\n        \\n        if (event==\\'void_iteration\\') and value==True:\\n            self.discardInFlow()\\n        \\n        if (event==\\'void_iteration\\') and value==False:\\n            self.discardInFlow()\\n\\n    def buildDerivation(self, data, port=\"\"):\\n\\t\\t\\n        try:\\n\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          data[\\'id\\'], \\'TriggeredByProcessIterationID\\':\\n                          data[\\'TriggeredByProcessIterationID\\'], \\'prov_cluster\\':\\n                          data[\\'prov_cluster\\'],\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n                          \\n           # if port==\"_d4p_state\": \\n           #     derivation.update({\\'iterationIndex\\':self.iterationIndex})\\n                 \\n\\t\\t    \\n\\n            self.derivationIds.append(derivation)\\n\\n        except Exception:\\n            id=self.extractExternalInputDataId(data,port)\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          id, \\'TriggeredByProcessIterationID\\':\\n                          None, \\'prov_cluster\\':\\n                          None,\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n            self.derivationIds.append(derivation)\\n            self.log(\"BUILDING INITIAL DERIVATION\")\\n\\n    def buildUserMetadata(self, data, **kwargs):\\n        streamlist = list()\\n\\n        streamItem = {}\\n        streammeta = []\\n\\n        streammeta = self.extractItemMetadata(data,kwargs[\\'output_port\\'])\\n        \\n        if not isinstance(streammeta, list):\\n            streammeta = kwargs[\\'metadata\\'] if isinstance(\\n                kwargs[\\'metadata\\'], list) else [kwargs[\\'metadata\\']]\\n        elif isinstance(streammeta, list):\\n            try:\\n                if isinstance(kwargs[\\'metadata\\'], list):\\n                    streammeta = streammeta + kwargs[\\'metadata\\']\\n                if isinstance(kwargs[\\'metadata\\'], dict):\\n                    for y in streammeta:\\n                        y.update(kwargs[\\'metadata\\'])\\n            except:\\n                traceback.print_exc(file=sys.stderr)\\n                None\\n        \\n        if self.sel_rules!=None:\\n            self.provon=self.checkSelectiveRule(streammeta)\\n            \\n        if not self.provon:\\n            return streamItem\\n        #self.log(kwargs)\\n        streamItem.update({\"content\": streammeta,\\n                           \"id\": self.getUniqueId(data,kwargs[\\'output_port\\'],**kwargs),\\n                           \"format\": \"\",\\n                           \"location\": \"\",\\n                           \"annotations\": [],\\n                           \"port\": kwargs[\\'output_port\\']})\\n        # if (self.streamItemsControl!={,:\\n        streamItem.update(kwargs[\\'control\\'])\\n        # if (self.streamItemsLocations!={,:\\n        streamItem.update({\"location\": kwargs[\\'location\\'],\\n                          \"format\": kwargs[\\'format\\']})\\n        #streamItem.update({\"size\": total_size(data)})\\n        streamItem.update({\"size\": 0})\\n        streamlist.append(streamItem)\\n        return streamlist\\n\\n    def checkSelectiveRule(self,streammeta):\\n        self.log(\"Checking Skip-Rules\")\\n        for key in self.sel_rules:\\n                for s in streammeta:\\n                    if key in s: \\n                        self.log(\"A\"+str(self.sel_rules[key]))\\n                        self.log(s[key]) \\n                        self.log(type(s[key]))\\n                        self.log(type(self.sel_rules[key][\\'$lt\\']))\\n                        if \\'$eq\\' in self.sel_rules[key] and s[key]==self.sel_rules[key][\\'$eq\\']:\\n                            return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and \\'$lt\\' in self.sel_rules[key]:\\n                            if (s[key]>self.sel_rules[key][\\'$gt\\'] and s[key]<self.sel_rules[key][\\'$lt\\']):\\n                                self.log(\"GT-LT\") \\n                                return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and s[key]>self.sel_rules[key][\\'$gt\\']:\\n                            self.log(\"GT\") \\n                            return True\\n                        elif \\'$lt\\' in self.sel_rules[key] and s[key]<self.sel_rules[key][\\'$lt\\']:\\n                            self.log(\"LT\") \\n                            return True\\n                        else:\\n                            return self.provon\\n        return self.provon\\n\\n    def dicToKeyVal(self, dict, valueToString=False):\\n        try:\\n            alist = list()\\n            for k, v in dict.iteritems():\\n                adic = {}\\n                adic.update({\"key\": str(k)})\\n                if valueToString:\\n                    adic.update({\"val\": str(v)})\\n                else:\\n\\n                    try:\\n                        v = num(v)\\n                        adic.update({\"val\": v})\\n                    except Exception:\\n                        adic.update({\"val\": str(v)})\\n\\n                alist.append(adic)\\n\\n            return alist\\n        except Exception as err:\\n\\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\\n            sys.stderr.write(\\n                \\'ERROR: \\' +\\n                self.name +\\n                \\' dicToKeyVal output Error: \\' +\\n                str(err))\\n#                self.map.put(\"output\",\"\");\\n            traceback.print_exc(file=sys.stderr)\\n\\n    def discardInFlow(self,discardState=False): \\n        self.log(\\'BEFORE \\'+str(self.derivationIds))\\n        \\n        \\n        if discardState==True:\\n            self.derivationIds=[]\\n        else:\\n            maxit=0\\n            state=None\\n            for x in self.derivationIds: \\n                if x[\\'port\\']==\\'_d4p_state\\' and x[\\'iterationIndex\\']>=maxit:\\n                    state=x\\n                    maxit=x[\\'iterationIndex\\']\\n            \\n            if state!=None:   \\n                self.derivationIds=[state]\\n            else:\\n                self.derivationIds=[]\\n        \\n        \\n        self.log(\"ITENDEX \"+str(self.iterationIndex))    \\n        self.log(\\'AFTER \\'+str(self.derivationIds))\\n\\n    def extractExternalInputDataId(self,data,port):\\n        self.makeUniqueId(data,port)\\n\\n    def extractItemMetadata(self, data, port):\\n\\n        return {}\\n\\n    def extractProvenance(\\n            self,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            control={},\\n            attributes={},\\n            error=\"\",\\n            output_port=\"\",\\n            **kwargs):\\n\\n        self.error = error\\n\\n        if isinstance(metadata, list):\\n            metadata.append(attributes)\\n        else:\\n            metadata.update(attributes)\\n        usermeta = {}\\n\\n        if \\'s-prov:skip\\' in control and bool(control[\\'s-prov:skip\\']):\\n            self.provon = False\\n        else:\\n            self.provon = True\\n            usermeta= self.buildUserMetadata(\\n                data,\\n                location=location,\\n                format=format,\\n                metadata=metadata,\\n                control=control,\\n                attributes=attributes,\\n                error=error,\\n                output_port=output_port,\\n                **kwargs)\\n        \\n         \\n        \\n        self.flushData(data, usermeta, output_port)\\n\\n        return usermeta\\n\\n    def flushData(self, data, metadata, port):\\n        trace = {}\\n        stream = data\\n        try:\\n            if self.provon:\\n                self.endTime = datetime.datetime.utcnow()\\n                trace = self.packageAll(metadata)\\n                stream = self.prepareOutputStream(data, trace, port)\\n              \\n            try:\\n                if port is not None and port != \\'_d4p_state\\' \\\\\\n                        and port != \\'error\\':\\n\\n                    super(ProvenancePE, self).write(port, stream)\\n#stream)\\n\\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n            try:\\n                if self.provon:\\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n\\n                            self.sendProvToSensor(trace[\\'metadata\\'])\\n                            \\n                            \\n                            #super(\\n                            #      ProvenancePE,\\n                            #      self).write(\\n                            #                  OUTPUT_METADATA,\\n                            #                  deepcopy(trace[\\'metadata\\']))\\n                            \\n\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                        self.log(\"SENDING: \"+trace[\\'metadata\\'][\\'_id\\'])\\n                        self.sendProvToService(trace[\\'metadata\\'])\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\\n                         self.writeProvToFile(trace[\\'metadata\\'])\\n                     \\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n\\n            return True\\n\\n        except Exception:\\n            self.log(traceback.format_exc())\\n            if self.provon:\\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\\n\\n    def getDataStreams(self, inputs):\\n        streams = {}\\n        for inp in self.inputconnections:\\n            if inp not in inputs:\\n                continue\\n            values = inputs[inp]\\n            if isinstance(values, list):\\n                data = values[0:]\\n            else:\\n                data = values\\n            streams[\"streams\"].update({inp: data})\\n        return streams\\n\\n    def getInputAt(self, port=\"input\", index=0):\\n        return self.inputs[port][index]\\n\\n    def getOutputTypes(self):\\n        \\'\\'\\'\\n        Returns the output types of this PE, in the form of a dictionary.\\n        This method may be overridden if output types are not static and\\n        depend on input types.\\n\\n        .. note::\\n\\n            This method is only called after the input types have been\\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\\n\\n        :rtype: a dictionary mapping each output name to its type\\n\\n        By default it returns a dictionary of the types defined in the\\n        \\'outputconnections\\' instance variable.\\n\\n        Usage example::\\n\\n            def getOutputTypes(self):\\n                output = { \\'output1\\' : myInputs[\\'input1\\'],\\n                           \\'output2\\' : [ \\'comment\\' ] }\\n\\n        \\'\\'\\'\\n        ret = {}\\n        # print \\'%s: %s\\' % (self.id, self.outputconnections)\\n        for name, output in self.outputconnections.items():\\n            try:\\n                ret[name] = output[TYPE]\\n            except KeyError:\\n                raise Exception(\"%s: No output type defined for \\'%s\\'\"\\n                                % (self.id, name))\\n        return ret\\n\\n    def getProvStateObjectId(self,name):\\n        if name in self.statemap:\\n            return self.statemap[name]\\n        else:\\n            return None\\n\\n    def getUniqueId(self,data,port,**kwargs):\\n        data_id = self.makeUniqueId(data,port)\\n        if \\'name\\' in kwargs:\\n            self._updateState(kwargs[\\'name\\'],data_id)\\n\\n\\n\\n        return data_id\\n\\n    def ignoreState(self):\\n        self.ignore_state=True\\n\\n    def importInputData(self, data):\\n\\n        inputs = {}\\n\\n        try:\\n            if not isinstance(data, collections.Iterable):\\n                return data\\n            else:\\n                for x in data:\\n                    #self.log(data[x])\\n                    self.buildDerivation(data[x], port=x)\\n                    if type(data[x])==dict and \\'_d4p\\' in data[x]:\\n                        inputs[x] = data[x][\\'_d4p\\']\\n                    else:\\n                        inputs[x] = data[x]\\n                return inputs\\n\\n        except Exception:\\n            self.output = \"\"\\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\\n            raise\\n\\n    def initParameters(self):\\n\\n        self.error = \\'\\'\\n        self.w3c_prov = {}\\n        #self.resetflow = True\\n        self.inMetaStreams = None\\n        self.username = None\\n        self.runId = None\\n\\n\\n        try:\\n                # self.iterationId = self.name + \\'-\\' + getUniqueId()\\n            if \"username\" in self.controlParameters:\\n                self.username = self.controlParameters[\"username\"]\\n            if \"runId\" in self.controlParameters:\\n                self.runId = self.controlParameters[\"runId\"]\\n\\n        except:\\n                self.runId = \"\"\\n                pass\\n\\n        self.outputdest = self.controlParameters[\\n            \\'outputdest\\'] if \\'outputdest\\' in self.controlParameters else \\'None\\'\\n        self.rootpath = self.controlParameters[\\n            \\'inputrootpath\\'] \\\\\\n            if \\'inputrootpath\\' in self.controlParameters else \\'None\\'\\n        self.outputid = self.controlParameters[\\n            \\'outputid\\'] \\\\\\n            if \\'outputid\\' in self.controlParameters else \\'None\\'\\n\\n    def makeProcessId(self, **kwargs):\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def makeUniqueId(self,data,port):\\n        #if (\\'data\\' in kwargs):\\n        #    self.log(str(kwargs[\\'data\\']))\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def packageAll (self, contentmeta):\\n        metadata = {}\\n        if self.provon:\\n            try:\\n\\n                # identifies the actual iteration over the instance\\n                metadata.update({\\'iterationId\\': self.iterationId,\\n                # identifies the actual writing process\\'\\n                \\'actedOnBehalfOf\\': self.behalfOf,\\n                \\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId()),\\n                \\'iterationIndex\\': self.iterationIndex,\\n                \\'instanceId\\': self.instanceId,\\n                \\'annotations\\': {}})\\n\\n                if self.feedbackIteration:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_feedback_\\' + str(self.makeProcessId())})\\n                elif not self.resetflow:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_stateful_\\' + str(self.makeProcessId())})\\n\\n                else:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId())})\\n\\n\\n                metadata.update({\\'stateful\\': not self.resetflow,\\n                \\'feedbackIteration\\': self.feedbackIteration,\\n                \\'worker\\': socket.gethostname(),\\n                \\'parameters\\': self.dicToKeyVal(self.parameters),\\n                \\'errors\\': self.error,\\n                \\'pid\\': \\'%s\\' % os.getpid()})\\n\\n\\n                 \\n                if self.ignore_inputs==True:\\n                    derivations = [x for x in self.derivationIds if x[\\'port\\']==\\'_d4p_state\\' and x[\\'DerivedFromDatasetID\\'] in self.statemapId]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    self.ignore_inputs = False\\n                \\n                elif self.ignore_state==True:\\n                    self.log(\"IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    derivations = [x for x in self.derivationIds if (x[\\'iterationIndex\\'] == self.iterationIndex or x[\\'port\\']==\\'_d4p_state\\')]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    #self.ignore_state = False\\n                else:\\n                    #if self.resetflow==True:\\n            \\t    #    self.discardOutFlow()\\n                    self.log(\"NOOOT IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    self.log(\"INSERT DERIV: \"+str(self.derivationIds))\\n                    metadata.update({\\'derivationIds\\': self.derivationIds})\\n                    self.ignore_state = False\\n\\n\\n                metadata.update({\\'name\\': self.name,\\n                \\'runId\\': self.runId,\\n                \\'username\\': self.username,\\n                \\'startTime\\': str(self.startTime),\\n                \\'endTime\\': str(self.endTime),\\n                \\'type\\': \\'lineage\\',\\n\\n                \\'streams\\': contentmeta,\\n                \\'mapping\\': sys.argv[1]})\\n                \\n                if hasattr(self, \\'prov_cluster\\'):\\n                     \\n                    metadata.update({\\'prov_cluster\\': self.prov_cluster})\\n                \\n\\n                if self.creator is not None:\\n                    metadata.update({\\'creator\\': self.creator})\\n            except Exception:\\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\\n                self.log(traceback.format_exc())\\n\\n        output = {\\n            \"metadata\": metadata,\\n            \"error\": self.error,\\n            #\"pid\": \"%s\" %\\n            #os.getpid()\\n             }\\n\\n        if self.ignore_state==True:\\n             self.log(\"DADADADAD :\"+str(output))\\n\\n        return output\\n\\n    def pe_init(self, *args, **kwargs):\\n        #ProvenancePE.__init__(self,*args, **kwargs)\\n\\n        global _d4p_plan_sqn\\n        self._add_input(\\'_d4py_feedback\\', grouping=\\'all\\')\\n        self.statemap={}\\n        self.statemapId=[]\\n        self.impcls = None\\n        self.bulk_prov = []\\n\\n\\n        if \\'pe_class\\' in kwargs and kwargs[\\'pe_class\\'] != GenericPE:\\n            self.impcls = kwargs[\\'pe_class\\']\\n       \\n        if \\'sel_rules\\' in kwargs and self.name in kwargs[\\'sel_rules\\']:\\n            print(self.name+\" \"+str(kwargs[\\'sel_rules\\'][self.name]))\\n            self.sel_rules = kwargs[\\'sel_rules\\'][self.name]\\n        else:\\n            self.sel_rules=None\\n        \\n        if \\'creator\\' not in kwargs:\\n            self.creator = None\\n        else:\\n            self.creator = kwargs[\\'creator\\']\\n\\n        self.error = \\'\\'\\n\\n        if not hasattr(self, \\'parameters\\'):\\n            self.parameters = {}\\n        if not hasattr(self, \\'controlParameters\\'):\\n            self.controlParameters = {}\\n\\n        if \\'controlParameters\\' in kwargs:\\n            self.controlParameters = kwargs[\\'controlParameters\\']\\n\\n        out_md = {}\\n        out_md[NAME] = OUTPUT_METADATA\\n\\n        # self.outputconnections[OUTPUT_DATA] = out1\\n        #print(OUTPUT_METADATA)\\n        self._add_output(OUTPUT_METADATA)\\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\\n        self.taskId = str(uuid.uuid1())\\n\\n        # self.appParameters = None\\n        self.provon = True\\n        \\n\\n        if \\'save_mode\\' not in kwargs:\\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\\n        else:\\n            self.save_mode=SAVE_MODE_FILE = kwargs[\\'save_mode\\']\\n\\n\\n        self.resetflow = False\\n        self.stateUpdateIndex=0\\n        self.ignore_inputs = False\\n        self.ignore_state = False\\n        self.derivationIds = list()\\n        self.iterationIndex = 0\\n        self.behalfOf = self.id \\n        #name + \\'_\\' + str(_d4p_plan_sqn)\\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\\n        self.countstatewrite=0\\n        if not hasattr(self, \\'prov_cluster\\'):\\n                    self.prov_cluster=self.behalfOf\\n\\n    def postprocess(self):\\n\\n        \\n        if len(self.bulk_prov)>0:\\n            \\n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n                params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n                headers = {\\n                       \"Content-type\": \"application/x-www-form-urlencoded\",\\n                       \"Accept\": \"application/json\"}\\n                self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n                self.connection.request(\\n                                    \"POST\",\\n                                    self.provurl.path,\\n                                    params,\\n                                    headers)\\n                response = self.connection.getresponse()\\n                self.log(\"Postprocess: \" +\\n                     str((response.status, response.reason, response.read())))\\n#                    response.read())))\\n                self.connection.close()\\n                self.bulk_prov[:]=[]\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\\n                filep = open(ProvenancePE.PROV_PATH + \"/bulk_\" + self.makeProcessId(), \"wr\")\\n                ujson.dump(self.bulk_prov, filep)\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n                super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n            #self.bulk_prov[:]=[]\\n\\n        self._postprocess()\\n\\n    def prepareOutputStream(self, data, trace,port):\\n        try:\\n            streamtransfer = {}\\n            streamtransfer[\\'_d4p\\'] = data\\n            if self.provon:\\n\\n                try:\\n                    streamtransfer[\\'id\\'] = trace[\\n                        \\'metadata\\'][\"streams\"][0][\"id\"]\\n                    streamtransfer[\\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\\n                    streamtransfer[\\n                        \"prov_cluster\"] = self.prov_cluster\\n                    streamtransfer[\\n                        \"port\"] = port\\n                    if port==\\'_d4p_state\\':\\n                        self.log(\\'\\'\\' Building SELF Derivation \\'\\'\\'+str(trace))\\n                        self._updateState(\\'_d4p_state\\',trace[\\n                        \\'metadata\\'][\"streams\"][0][\\'id\\'])\\n                        self.buildDerivation(streamtransfer,port=\\'_d4p_state\\')\\n                        #if self.resetflow==True:\\n\\t\\t\\t\\t\\t\\t#    self.discardOutFlow()\\n                        #self.resetflow=True\\n                except:\\n                    pass\\n            return streamtransfer\\n\\n        except Exception:\\n            self.error += self.name + \" Writing output Error: %s\" % \\\\\\n                traceback.format_exc()\\n            raise\\n\\n    def preprocess(self):\\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\\n            #self.connection = httplib.HTTPConnection(\\n            #                                         self.provurl.netloc)\\n        self._preprocess()\\n\\n    def process(self, inputs):\\n        self.feedbackIteration = False\\n        self.void_iteration = True\\n        self.iterationIndex += 1\\n         \\n        \\n\\n        if \\'_d4py_feedback\\' in inputs:\\n\\n            \\'state could be used here to track the occurring changes\\'\\n            self.process_feedback(inputs[\\'_d4py_feedback\\'])\\n        else:\\n            self.__processwrapper(inputs)\\n\\n        #if (self.void_iteration==True):\\n        self.apply_flow_reset_policy(\\'void_iteration\\',self.void_iteration)\\n\\n    def process_feedback(self, feedback):\\n        self.feedbackIteration = True\\n        self._process_feedback(feedback)\\n\\n    def removeDerivation(self,**kwargs):\\n        if \\'name\\' in kwargs:\\n            id = self.getProvStateObjectId(kwargs[\\'name\\'])\\n            for j in self.derivationIds:\\n\\n                if j[\\'DerivedFromDatasetID\\']==id:\\n\\n                    del self.derivationIds[self.derivationIds.index(j)]\\n        else:\\n            if \\'port\\' in kwargs:\\n                for j in self.derivationIds:\\n\\n                    if j[\\'port\\']==kwargs[\\'port\\']:\\n\\n                        del self.derivationIds[self.derivationIds.index(j)]\\n\\n    def sendProvToSensor(self, prov):\\n        \\n\\n        self.bulk_prov.append(deepcopy(prov))\\n\\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n\\n             \\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def sendProvToService(self, prov):\\n\\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n\\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n\\n        self.bulk_prov.append(deepcopy(prov))\\n        self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n            headers = {\\n                \"Content-type\": \"application/x-www-form-urlencoded\",\\n                \"Accept\": \"application/json\"}\\n            self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n            self.connection.request(\\n                \"POST\", self.provurl.path, params, headers)\\n            response = self.connection.getresponse()\\n            self.log(\"progress: \" + str((response.status, response.reason,response.read())))\\n            #                             response, response.read())))\\n\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def setInputTypes(self, types):\\n        \\'\\'\\'\\n        Sets the input types of this PE, in the form of a dictionary.\\n        It is meant to be overridden, e.g. if output types depend on input.\\n\\n        .. note::\\n\\n            This method is always called before\\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\\n\\n        :param types: object types for each input stream\\n        :type types: dictionary mapping input name to input type\\n\\n        Usage example::\\n\\n            pe.setInputTypes({\\'input1\\':[\\'t1\\', \\'t2\\', \\'t3\\'], \\\\\\n                              \\'input2\\':[\\'t4\\', \\'t5\\']})\\n        \\'\\'\\'\\n        pass\\n\\n    def update_prov_state(\\n            self,\\n            name,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            ignore_inputs=True,\\n            stateless=False,\\n            **kwargs\\n    ):\\n\\n        self.endTime = datetime.datetime.utcnow()\\n        #self.resetflow = stateless\\n        self.ignore_inputs = ignore_inputs\\n        self.addprov=True\\n        kwargs[\\'name\\']=name\\n        #self.apply_flow_reset_policy(\\'state\\', None)\\n        if self.provon:\\n            if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n                for d in kwargs[\\'dep\\']:\\n                    did=self.getProvStateObjectId(d)\\n                    if did!=None:\\n                        self.buildDerivation({\\'id\\':did,\\'TriggeredByProcessIterationID\\':self.iterationId,\\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n\\n\\n            self.extractProvenance(data,\\n                               location,\\n                               format,\\n                               metadata,\\n                               output_port=\"_d4p_state\",\\n                               **kwargs)\\n\\n\\n\\n        self.ignore_inputs = False\\n\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            self.removeDerivation(port=\\'_d4p_state\\')\\n\\n    def write(self, name, data, **kwargs):\\n        self.void_iteration=False\\n        self.apply_flow_reset_policy(\\'write\\',True,port=name,data=data)\\n        # self.__markIteration()\\n        self.endTime = datetime.datetime.utcnow()\\n\\n        #if \\'state_reset\\' in kwargs:\\n        #    self.resetflow = bool(kwargs[\\'state_reset\\'])\\n        #else:\\n        #    None\\n#            self.resetflow = True\\n        \\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.buildDerivation({\\'id\\':self.getProvStateObjectId(d),\\'TriggeredByProcessIterationID\\':self.iterationId, \\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n                #self.log(self.derivationIds)\\n\\n        if \\'ignore_inputs\\' in kwargs:\\n            #self.log(\"IGNORONG: \"+str(self.ignore_inputs))\\n            self.ignore_inputs=kwargs[\\'ignore_inputs\\']\\n        \\n        #if self.resetflow==True:\\n        #    self.discardOutFlow()\\n        \\n        self.extractProvenance(data, output_port=name, **kwargs)\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.removeDerivation(name=d)\\n\\n    def writeProvToFile(self, prov):\\n        \\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n        \\n         \\n        #self.log(\\'PROCESS: \\'+str(prov))\\n        self.bulk_prov.append(prov)\\n        \\n        \\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            filep = open(\\n                ProvenancePE.PROV_PATH +\\n                \"/bulk_\" +\\n                self.makeProcessId(),\\n                \"wr\")\\n            #self.log(\\'PROCESS: \\'+str(filep))\\n            ujson.dump(self.bulk_prov, filep)\\n            #filep.write(json.dumps(self.bulk_prov))\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def writeResults(self, name, result):\\n\\n        #self.resetflow = True\\n        self.apply_flow_reset_policy(\\'write\\',True,data=data,port=name)\\n        self.void_iteration=False\\n        \\n        \\n\\n        if isinstance(result, dict) and \\'_d4p_prov\\' in result:\\n            meta = result[\\'_d4p_prov\\']\\n            result = (result[\\'_d4p_data\\'])\\n\\n            if \\'error\\' in meta:\\n                self.extractProvenance(result, output_port=name, **meta)\\n            else:\\n\\n                self.extractProvenance(\\n                    result, error=self.error, output_port=name, **meta)\\n\\n        else:\\n            self.extractProvenance(result, error=self.error, output_port=name)\\n\\n', 'type': \"(<class 'dispel4py.provenance.ProvenancePE'>, <class '__main__.Write'>)\"}, 'ANALYSIS5': {'code': u'    def __computewrapper(self, inputs):\\n\\n        try:\\n            result = None\\n\\n            self.__markIteration()\\n\\n            if self.impcls is not None and isinstance(self, self.impcls):\\n                try:\\n                    if hasattr(self, \\'params\\'):\\n                        self.parameters = self.params\\n                    result = self._process(inputs[self.impcls.INPUT_NAME])\\n                    if result is not None:\\n                        self.writeResults(self.impcls.OUTPUT_NAME, result)\\n                except:\\n                    result = self._process(inputs)\\n            else:\\n                result = self._process(inputs)\\n\\n            if result is not None:\\n                return result\\n\\n        except Exception:\\n            self.log(\" Compute Error: %s\" % traceback.format_exc())\\n            self.error += \" Compute Error: %s\" % traceback.format_exc()\\n            # self.endTime = datetime.datetime.utcnow()\\n            self.writeResults(\\'error\\', {\\'error\\': \\'null\\'})\\n\\n    def __getUniqueId(self):\\n        return socket.gethostname() + \"-\" + str(os.getpid()) + \\\\\\n            \"-\" + str(uuid.uuid1())\\n\\n    def __importInputMetadata(self):\\n        try:\\n            self.inMetaStreams = self.input[\"metadata\"][\"streams\"]\\n        except Exception:\\n            None\\n\\n    def __markIteration(self):\\n        self.startTime = datetime.datetime.utcnow()\\n        self.iterationId = self.name + \\'-\\' + self.makeProcessId()\\n\\n    def __processwrapper(self, data):\\n        try:\\n\\n            self.initParameters()\\n\\n            inputs = self.importInputData(data)\\n            # self.__importInputMetadata()\\n            return self.__computewrapper(inputs)\\n\\n        except:\\n            self.log(traceback.format_exc())\\n\\n    def __init__(self):\\n        ProvenancePE.__init__(self)\\n\\n    def _add_input(self, name, grouping=None, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an input for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.inputconnections` directly.\\n\\n        :param name: name of the input\\n        :param grouping: the grouping type that this input expects (optional)\\n        :param tuple_type: type of tuples accepted by this input (optional)\\n        \\'\\'\\'\\n        self.inputconnections[name] = {NAME: name}\\n        if grouping:\\n            self.inputconnections[name][GROUPING] = grouping\\n        if tuple_type:\\n            self.inputconnections[name][TYPE] = tuple_type\\n\\n    def _add_output(self, name, tuple_type=None):\\n        \\'\\'\\'\\n        Declares an output for this PE.\\n        This method may be used when initialising a PE instead of modifying\\n        :py:attr:`~dispel4py.core.GenericPE.outputconnections` directly.\\n\\n        :param name: name of the output\\n        :param tuple_type: type of tuples produced by this output (optional)\\n        \\'\\'\\'\\n        self.outputconnections[name] = {NAME: name}\\n        if tuple_type:\\n            self.outputconnections[name][TYPE] = tuple_type\\n\\n    def _postprocess(self):\\n        None\\n\\n    def _preprocess(self):\\n        self.instanceId = self.name + \"-Instance-\" + \\\\\\n            \"-\" + self.makeProcessId()\\n\\n        super(ProvenancePE, self)._preprocess()\\n\\n    def _process(self,inputs):\\n        #self.log(\\'Workflow_process\\')\\n        \\n       \\n        nc = inputs[\\'input\\'][0]\\n         \\n        #Additional metadata can be added to the output for provenance contextualisation\\n        \\n        if (self.count%3==0):\\n            self.log(\"PRINT AVG\" +str(self.count))\\n            self.write(\\'avg\\', (nc , inputs[\\'input\\'][1] ), metadata={\\'count\\':self.count})\\n            \\n            \\n        if (self.count%5==0):\\n            self.log(\"PRINT thr\" +str(self.count))\\n            self.write(\\'threshold\\', (nc , inputs[\\'input\\'][1] ), metadata={\\'count\\':self.count})\\n             \\n        self.count+=1\\n\\n    def _updateState(self,name,id):\\n        if name in self.statemap:\\n                self.statemapId.remove(self.statemap[name])\\n        self.statemap[name]=id\\n        self.statemapId.append(id)\\n\\n    def _write(self, name, data, **kwargs):\\n        \\'\\'\\'\\n        This writes the \\'data\\' to the output pipe with name \\'name\\' of this PE.\\n        \\'\\'\\'\\n         \\n        try:\\n            output = self.outputconnections[name]\\n            output[WRITER].write(data)\\n        except KeyError:\\n            raise Exception(\"Can\\'t write data: Unknown output connection\\\\\\n                            \\'%s\\' for PE \\'%s\\'\" % (name, type(self).__name__))\\n\\n    def apply_flow_reset_policy(self,event,value,port=None,data=None):\\n        self.log(port)\\n        self.ignore_state=False\\n        self.ignore_inputs=False\\n        if (event==\\'write\\' and port == \\'avg\\'):\\n            self.update_prov_state(\\'avg\\',data,ignore_inputs=False)\\n            self.discardInFlow()\\n        if (event==\\'write\\' and port != \\'avg\\'):\\n            self.ignoreState()\\n\\n    def buildDerivation(self, data, port=\"\"):\\n\\t\\t\\n        try:\\n\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          data[\\'id\\'], \\'TriggeredByProcessIterationID\\':\\n                          data[\\'TriggeredByProcessIterationID\\'], \\'prov_cluster\\':\\n                          data[\\'prov_cluster\\'],\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n                          \\n           # if port==\"_d4p_state\": \\n           #     derivation.update({\\'iterationIndex\\':self.iterationIndex})\\n                 \\n\\t\\t    \\n\\n            self.derivationIds.append(derivation)\\n\\n        except Exception:\\n            id=self.extractExternalInputDataId(data,port)\\n            derivation = {\\'port\\': port, \\'DerivedFromDatasetID\\':\\n                          id, \\'TriggeredByProcessIterationID\\':\\n                          None, \\'prov_cluster\\':\\n                          None,\\n                          \\'iterationIndex\\':self.iterationIndex\\n                          }\\n            self.derivationIds.append(derivation)\\n            self.log(\"BUILDING INITIAL DERIVATION\")\\n\\n    def buildUserMetadata(self, data, **kwargs):\\n        streamlist = list()\\n\\n        streamItem = {}\\n        streammeta = []\\n\\n        streammeta = self.extractItemMetadata(data,kwargs[\\'output_port\\'])\\n        \\n        if not isinstance(streammeta, list):\\n            streammeta = kwargs[\\'metadata\\'] if isinstance(\\n                kwargs[\\'metadata\\'], list) else [kwargs[\\'metadata\\']]\\n        elif isinstance(streammeta, list):\\n            try:\\n                if isinstance(kwargs[\\'metadata\\'], list):\\n                    streammeta = streammeta + kwargs[\\'metadata\\']\\n                if isinstance(kwargs[\\'metadata\\'], dict):\\n                    for y in streammeta:\\n                        y.update(kwargs[\\'metadata\\'])\\n            except:\\n                traceback.print_exc(file=sys.stderr)\\n                None\\n        \\n        if self.sel_rules!=None:\\n            self.provon=self.checkSelectiveRule(streammeta)\\n            \\n        if not self.provon:\\n            return streamItem\\n        #self.log(kwargs)\\n        streamItem.update({\"content\": streammeta,\\n                           \"id\": self.getUniqueId(data,kwargs[\\'output_port\\'],**kwargs),\\n                           \"format\": \"\",\\n                           \"location\": \"\",\\n                           \"annotations\": [],\\n                           \"port\": kwargs[\\'output_port\\']})\\n        # if (self.streamItemsControl!={,:\\n        streamItem.update(kwargs[\\'control\\'])\\n        # if (self.streamItemsLocations!={,:\\n        streamItem.update({\"location\": kwargs[\\'location\\'],\\n                          \"format\": kwargs[\\'format\\']})\\n        #streamItem.update({\"size\": total_size(data)})\\n        streamItem.update({\"size\": 0})\\n        streamlist.append(streamItem)\\n        return streamlist\\n\\n    def checkSelectiveRule(self,streammeta):\\n        self.log(\"Checking Skip-Rules\")\\n        for key in self.sel_rules:\\n                for s in streammeta:\\n                    if key in s: \\n                        self.log(\"A\"+str(self.sel_rules[key]))\\n                        self.log(s[key]) \\n                        self.log(type(s[key]))\\n                        self.log(type(self.sel_rules[key][\\'$lt\\']))\\n                        if \\'$eq\\' in self.sel_rules[key] and s[key]==self.sel_rules[key][\\'$eq\\']:\\n                            return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and \\'$lt\\' in self.sel_rules[key]:\\n                            if (s[key]>self.sel_rules[key][\\'$gt\\'] and s[key]<self.sel_rules[key][\\'$lt\\']):\\n                                self.log(\"GT-LT\") \\n                                return True\\n                        elif \\'$gt\\' in self.sel_rules[key] and s[key]>self.sel_rules[key][\\'$gt\\']:\\n                            self.log(\"GT\") \\n                            return True\\n                        elif \\'$lt\\' in self.sel_rules[key] and s[key]<self.sel_rules[key][\\'$lt\\']:\\n                            self.log(\"LT\") \\n                            return True\\n                        else:\\n                            return self.provon\\n        return self.provon\\n\\n    def dicToKeyVal(self, dict, valueToString=False):\\n        try:\\n            alist = list()\\n            for k, v in dict.iteritems():\\n                adic = {}\\n                adic.update({\"key\": str(k)})\\n                if valueToString:\\n                    adic.update({\"val\": str(v)})\\n                else:\\n\\n                    try:\\n                        v = num(v)\\n                        adic.update({\"val\": v})\\n                    except Exception:\\n                        adic.update({\"val\": str(v)})\\n\\n                alist.append(adic)\\n\\n            return alist\\n        except Exception as err:\\n\\n            self.error += self.name + \" dicToKeyVal output Error: \" + str(err)\\n            sys.stderr.write(\\n                \\'ERROR: \\' +\\n                self.name +\\n                \\' dicToKeyVal output Error: \\' +\\n                str(err))\\n#                self.map.put(\"output\",\"\");\\n            traceback.print_exc(file=sys.stderr)\\n\\n    def discardInFlow(self,discardState=False): \\n        self.log(\\'BEFORE \\'+str(self.derivationIds))\\n        \\n        \\n        if discardState==True:\\n            self.derivationIds=[]\\n        else:\\n            maxit=0\\n            state=None\\n            for x in self.derivationIds: \\n                if x[\\'port\\']==\\'_d4p_state\\' and x[\\'iterationIndex\\']>=maxit:\\n                    state=x\\n                    maxit=x[\\'iterationIndex\\']\\n            \\n            if state!=None:   \\n                self.derivationIds=[state]\\n            else:\\n                self.derivationIds=[]\\n        \\n        \\n        self.log(\"ITENDEX \"+str(self.iterationIndex))    \\n        self.log(\\'AFTER \\'+str(self.derivationIds))\\n\\n    def extractExternalInputDataId(self,data,port):\\n        self.makeUniqueId(data,port)\\n\\n    def extractItemMetadata(self, data, port):\\n\\n        return {}\\n\\n    def extractProvenance(\\n            self,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            control={},\\n            attributes={},\\n            error=\"\",\\n            output_port=\"\",\\n            **kwargs):\\n\\n        self.error = error\\n\\n        if isinstance(metadata, list):\\n            metadata.append(attributes)\\n        else:\\n            metadata.update(attributes)\\n        usermeta = {}\\n\\n        if \\'s-prov:skip\\' in control and bool(control[\\'s-prov:skip\\']):\\n            self.provon = False\\n        else:\\n            self.provon = True\\n            usermeta= self.buildUserMetadata(\\n                data,\\n                location=location,\\n                format=format,\\n                metadata=metadata,\\n                control=control,\\n                attributes=attributes,\\n                error=error,\\n                output_port=output_port,\\n                **kwargs)\\n        \\n         \\n        \\n        self.flushData(data, usermeta, output_port)\\n\\n        return usermeta\\n\\n    def flushData(self, data, metadata, port):\\n        trace = {}\\n        stream = data\\n        try:\\n            if self.provon:\\n                self.endTime = datetime.datetime.utcnow()\\n                trace = self.packageAll(metadata)\\n                stream = self.prepareOutputStream(data, trace, port)\\n              \\n            try:\\n                if port is not None and port != \\'_d4p_state\\' \\\\\\n                        and port != \\'error\\':\\n\\n                    super(ProvenancePE, self).write(port, stream)\\n#stream)\\n\\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n            try:\\n                if self.provon:\\n                    if (ProvenancePE.send_prov_to_sensor==True) or (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n\\n                            self.sendProvToSensor(trace[\\'metadata\\'])\\n                            \\n                            \\n                            #super(\\n                            #      ProvenancePE,\\n                            #      self).write(\\n                            #                  OUTPUT_METADATA,\\n                            #                  deepcopy(trace[\\'metadata\\']))\\n                            \\n\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                        self.log(\"SENDING: \"+trace[\\'metadata\\'][\\'_id\\'])\\n                        self.sendProvToService(trace[\\'metadata\\'])\\n                    if self.save_mode==ProvenancePE.SAVE_MODE_FILE:\\n                         self.writeProvToFile(trace[\\'metadata\\'])\\n                     \\n            except:\\n                self.log(traceback.format_exc())\\n                \\'if cant write doesnt matter move on\\'\\n                pass\\n\\n            return True\\n\\n        except Exception:\\n            self.log(traceback.format_exc())\\n            if self.provon:\\n                self.error += \" FlushChunk Error: %s\" % traceback.format_exc()\\n\\n    def getDataStreams(self, inputs):\\n        streams = {}\\n        for inp in self.inputconnections:\\n            if inp not in inputs:\\n                continue\\n            values = inputs[inp]\\n            if isinstance(values, list):\\n                data = values[0:]\\n            else:\\n                data = values\\n            streams[\"streams\"].update({inp: data})\\n        return streams\\n\\n    def getInputAt(self, port=\"input\", index=0):\\n        return self.inputs[port][index]\\n\\n    def getOutputTypes(self):\\n        \\'\\'\\'\\n        Returns the output types of this PE, in the form of a dictionary.\\n        This method may be overridden if output types are not static and\\n        depend on input types.\\n\\n        .. note::\\n\\n            This method is only called after the input types have been\\n            initialised in :py:func:`~dispel4py.core.GenericPE.setInputTypes`.\\n\\n        :rtype: a dictionary mapping each output name to its type\\n\\n        By default it returns a dictionary of the types defined in the\\n        \\'outputconnections\\' instance variable.\\n\\n        Usage example::\\n\\n            def getOutputTypes(self):\\n                output = { \\'output1\\' : myInputs[\\'input1\\'],\\n                           \\'output2\\' : [ \\'comment\\' ] }\\n\\n        \\'\\'\\'\\n        ret = {}\\n        # print \\'%s: %s\\' % (self.id, self.outputconnections)\\n        for name, output in self.outputconnections.items():\\n            try:\\n                ret[name] = output[TYPE]\\n            except KeyError:\\n                raise Exception(\"%s: No output type defined for \\'%s\\'\"\\n                                % (self.id, name))\\n        return ret\\n\\n    def getProvStateObjectId(self,name):\\n        if name in self.statemap:\\n            return self.statemap[name]\\n        else:\\n            return None\\n\\n    def getUniqueId(self,data,port,**kwargs):\\n        data_id = self.makeUniqueId(data,port)\\n        if \\'name\\' in kwargs:\\n            self._updateState(kwargs[\\'name\\'],data_id)\\n\\n\\n\\n        return data_id\\n\\n    def ignoreState(self):\\n        self.ignore_state=True\\n\\n    def importInputData(self, data):\\n\\n        inputs = {}\\n\\n        try:\\n            if not isinstance(data, collections.Iterable):\\n                return data\\n            else:\\n                for x in data:\\n                    #self.log(data[x])\\n                    self.buildDerivation(data[x], port=x)\\n                    if type(data[x])==dict and \\'_d4p\\' in data[x]:\\n                        inputs[x] = data[x][\\'_d4p\\']\\n                    else:\\n                        inputs[x] = data[x]\\n                return inputs\\n\\n        except Exception:\\n            self.output = \"\"\\n            self.error += \"Reading Input Error: %s\" % traceback.format_exc()\\n            raise\\n\\n    def initParameters(self):\\n\\n        self.error = \\'\\'\\n        self.w3c_prov = {}\\n        #self.resetflow = True\\n        self.inMetaStreams = None\\n        self.username = None\\n        self.runId = None\\n\\n\\n        try:\\n                # self.iterationId = self.name + \\'-\\' + getUniqueId()\\n            if \"username\" in self.controlParameters:\\n                self.username = self.controlParameters[\"username\"]\\n            if \"runId\" in self.controlParameters:\\n                self.runId = self.controlParameters[\"runId\"]\\n\\n        except:\\n                self.runId = \"\"\\n                pass\\n\\n        self.outputdest = self.controlParameters[\\n            \\'outputdest\\'] if \\'outputdest\\' in self.controlParameters else \\'None\\'\\n        self.rootpath = self.controlParameters[\\n            \\'inputrootpath\\'] \\\\\\n            if \\'inputrootpath\\' in self.controlParameters else \\'None\\'\\n        self.outputid = self.controlParameters[\\n            \\'outputid\\'] \\\\\\n            if \\'outputid\\' in self.controlParameters else \\'None\\'\\n\\n    def makeProcessId(self, **kwargs):\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def makeUniqueId(self,data,port):\\n        #if (\\'data\\' in kwargs):\\n        #    self.log(str(kwargs[\\'data\\']))\\n        \\n        return socket.gethostname() + \"-\" + \\\\\\n            str(os.getpid()) + \"-\" + str(uuid.uuid1())\\n\\n    def packageAll (self, contentmeta):\\n        metadata = {}\\n        if self.provon:\\n            try:\\n\\n                # identifies the actual iteration over the instance\\n                metadata.update({\\'iterationId\\': self.iterationId,\\n                # identifies the actual writing process\\'\\n                \\'actedOnBehalfOf\\': self.behalfOf,\\n                \\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId()),\\n                \\'iterationIndex\\': self.iterationIndex,\\n                \\'instanceId\\': self.instanceId,\\n                \\'annotations\\': {}})\\n\\n                if self.feedbackIteration:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_feedback_\\' + str(self.makeProcessId())})\\n                elif not self.resetflow:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_stateful_\\' + str(self.makeProcessId())})\\n\\n                else:\\n                    metadata.update(\\n                        {\\'_id\\': self.id + \\'_write_\\' + str(self.makeProcessId())})\\n\\n\\n                metadata.update({\\'stateful\\': not self.resetflow,\\n                \\'feedbackIteration\\': self.feedbackIteration,\\n                \\'worker\\': socket.gethostname(),\\n                \\'parameters\\': self.dicToKeyVal(self.parameters),\\n                \\'errors\\': self.error,\\n                \\'pid\\': \\'%s\\' % os.getpid()})\\n\\n\\n                 \\n                if self.ignore_inputs==True:\\n                    derivations = [x for x in self.derivationIds if x[\\'port\\']==\\'_d4p_state\\' and x[\\'DerivedFromDatasetID\\'] in self.statemapId]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    self.ignore_inputs = False\\n                \\n                elif self.ignore_state==True:\\n                    self.log(\"IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    derivations = [x for x in self.derivationIds if (x[\\'iterationIndex\\'] == self.iterationIndex or x[\\'port\\']==\\'_d4p_state\\')]\\n                    metadata.update({\\'derivationIds\\': derivations})\\n                    #self.ignore_state = False\\n                else:\\n                    #if self.resetflow==True:\\n            \\t    #    self.discardOutFlow()\\n                    self.log(\"NOOOT IGNOOOORING STTEEEE: \"+metadata[\\'_id\\'])\\n                    self.log(\"INSERT DERIV: \"+str(self.derivationIds))\\n                    metadata.update({\\'derivationIds\\': self.derivationIds})\\n                    self.ignore_state = False\\n\\n\\n                metadata.update({\\'name\\': self.name,\\n                \\'runId\\': self.runId,\\n                \\'username\\': self.username,\\n                \\'startTime\\': str(self.startTime),\\n                \\'endTime\\': str(self.endTime),\\n                \\'type\\': \\'lineage\\',\\n\\n                \\'streams\\': contentmeta,\\n                \\'mapping\\': sys.argv[1]})\\n                \\n                if hasattr(self, \\'prov_cluster\\'):\\n                     \\n                    metadata.update({\\'prov_cluster\\': self.prov_cluster})\\n                \\n\\n                if self.creator is not None:\\n                    metadata.update({\\'creator\\': self.creator})\\n            except Exception:\\n                self.error += \" Packaging Error: %s\" % traceback.format_exc()\\n                self.log(traceback.format_exc())\\n\\n        output = {\\n            \"metadata\": metadata,\\n            \"error\": self.error,\\n            #\"pid\": \"%s\" %\\n            #os.getpid()\\n             }\\n\\n        if self.ignore_state==True:\\n             self.log(\"DADADADAD :\"+str(output))\\n\\n        return output\\n\\n    def pe_init(self, *args, **kwargs):\\n        #ProvenancePE.__init__(self,*args, **kwargs)\\n\\n        global _d4p_plan_sqn\\n        self._add_input(\\'_d4py_feedback\\', grouping=\\'all\\')\\n        self.statemap={}\\n        self.statemapId=[]\\n        self.impcls = None\\n        self.bulk_prov = []\\n\\n\\n        if \\'pe_class\\' in kwargs and kwargs[\\'pe_class\\'] != GenericPE:\\n            self.impcls = kwargs[\\'pe_class\\']\\n       \\n        if \\'sel_rules\\' in kwargs and self.name in kwargs[\\'sel_rules\\']:\\n            print(self.name+\" \"+str(kwargs[\\'sel_rules\\'][self.name]))\\n            self.sel_rules = kwargs[\\'sel_rules\\'][self.name]\\n        else:\\n            self.sel_rules=None\\n        \\n        if \\'creator\\' not in kwargs:\\n            self.creator = None\\n        else:\\n            self.creator = kwargs[\\'creator\\']\\n\\n        self.error = \\'\\'\\n\\n        if not hasattr(self, \\'parameters\\'):\\n            self.parameters = {}\\n        if not hasattr(self, \\'controlParameters\\'):\\n            self.controlParameters = {}\\n\\n        if \\'controlParameters\\' in kwargs:\\n            self.controlParameters = kwargs[\\'controlParameters\\']\\n\\n        out_md = {}\\n        out_md[NAME] = OUTPUT_METADATA\\n\\n        # self.outputconnections[OUTPUT_DATA] = out1\\n        #print(OUTPUT_METADATA)\\n        self._add_output(OUTPUT_METADATA)\\n        ##self.outputconnections[OUTPUT_METADATA] = out_md\\n        self.taskId = str(uuid.uuid1())\\n\\n        # self.appParameters = None\\n        self.provon = True\\n        \\n\\n        if \\'save_mode\\' not in kwargs:\\n            self.save_mode=ProvenancePE.SAVE_MODE_FILE\\n        else:\\n            self.save_mode=SAVE_MODE_FILE = kwargs[\\'save_mode\\']\\n\\n\\n        self.resetflow = False\\n        self.stateUpdateIndex=0\\n        self.ignore_inputs = False\\n        self.ignore_state = False\\n        self.derivationIds = list()\\n        self.iterationIndex = 0\\n        self.behalfOf = self.id \\n        #name + \\'_\\' + str(_d4p_plan_sqn)\\n        _d4p_plan_sqn = _d4p_plan_sqn + 1\\n        self.countstatewrite=0\\n        if not hasattr(self, \\'prov_cluster\\'):\\n                    self.prov_cluster=self.behalfOf\\n\\n    def postprocess(self):\\n\\n        \\n        if len(self.bulk_prov)>0:\\n            \\n            if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n                #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n                params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n                headers = {\\n                       \"Content-type\": \"application/x-www-form-urlencoded\",\\n                       \"Accept\": \"application/json\"}\\n                self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n                self.connection.request(\\n                                    \"POST\",\\n                                    self.provurl.path,\\n                                    params,\\n                                    headers)\\n                response = self.connection.getresponse()\\n                self.log(\"Postprocess: \" +\\n                     str((response.status, response.reason, response.read())))\\n#                    response.read())))\\n                self.connection.close()\\n                self.bulk_prov[:]=[]\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_FILE):\\n                filep = open(ProvenancePE.PROV_PATH + \"/bulk_\" + self.makeProcessId(), \"wr\")\\n                ujson.dump(self.bulk_prov, filep)\\n            elif (self.save_mode==ProvenancePE.SAVE_MODE_SENSOR):\\n                super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n            #self.bulk_prov[:]=[]\\n\\n        self._postprocess()\\n\\n    def prepareOutputStream(self, data, trace,port):\\n        try:\\n            streamtransfer = {}\\n            streamtransfer[\\'_d4p\\'] = data\\n            if self.provon:\\n\\n                try:\\n                    streamtransfer[\\'id\\'] = trace[\\n                        \\'metadata\\'][\"streams\"][0][\"id\"]\\n                    streamtransfer[\\n                        \"TriggeredByProcessIterationID\"] = self.iterationId\\n                    streamtransfer[\\n                        \"prov_cluster\"] = self.prov_cluster\\n                    streamtransfer[\\n                        \"port\"] = port\\n                    if port==\\'_d4p_state\\':\\n                        self.log(\\'\\'\\' Building SELF Derivation \\'\\'\\'+str(trace))\\n                        self._updateState(\\'_d4p_state\\',trace[\\n                        \\'metadata\\'][\"streams\"][0][\\'id\\'])\\n                        self.buildDerivation(streamtransfer,port=\\'_d4p_state\\')\\n                        #if self.resetflow==True:\\n\\t\\t\\t\\t\\t\\t#    self.discardOutFlow()\\n                        #self.resetflow=True\\n                except:\\n                    pass\\n            return streamtransfer\\n\\n        except Exception:\\n            self.error += self.name + \" Writing output Error: %s\" % \\\\\\n                traceback.format_exc()\\n            raise\\n\\n    def preprocess(self):\\n        if self.save_mode==ProvenancePE.SAVE_MODE_SERVICE:\\n            self.provurl = urlparse(ProvenancePE.REPOS_URL)\\n            #self.connection = httplib.HTTPConnection(\\n            #                                         self.provurl.netloc)\\n        self._preprocess()\\n\\n    def process(self, inputs):\\n        self.feedbackIteration = False\\n        self.void_iteration = True\\n        self.iterationIndex += 1\\n         \\n        \\n\\n        if \\'_d4py_feedback\\' in inputs:\\n\\n            \\'state could be used here to track the occurring changes\\'\\n            self.process_feedback(inputs[\\'_d4py_feedback\\'])\\n        else:\\n            self.__processwrapper(inputs)\\n\\n        #if (self.void_iteration==True):\\n        self.apply_flow_reset_policy(\\'void_iteration\\',self.void_iteration)\\n\\n    def process_feedback(self, feedback):\\n        self.feedbackIteration = True\\n        self._process_feedback(feedback)\\n\\n    def removeDerivation(self,**kwargs):\\n        if \\'name\\' in kwargs:\\n            id = self.getProvStateObjectId(kwargs[\\'name\\'])\\n            for j in self.derivationIds:\\n\\n                if j[\\'DerivedFromDatasetID\\']==id:\\n\\n                    del self.derivationIds[self.derivationIds.index(j)]\\n        else:\\n            if \\'port\\' in kwargs:\\n                for j in self.derivationIds:\\n\\n                    if j[\\'port\\']==kwargs[\\'port\\']:\\n\\n                        del self.derivationIds[self.derivationIds.index(j)]\\n\\n    def sendProvToSensor(self, prov):\\n        \\n\\n        self.bulk_prov.append(deepcopy(prov))\\n\\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            super(\\n                                  ProvenancePE,\\n                                  self).write(\\n                                              OUTPUT_METADATA,\\n                                              {\\'prov_cluster\\':self.prov_cluster,\\'provenance\\':deepcopy(self.bulk_prov)})\\n\\n             \\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def sendProvToService(self, prov):\\n\\n        #self.log(\"TO SERVICE ________________ID: \"+str(self.provurl.netloc))\\n\\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n\\n        self.bulk_prov.append(deepcopy(prov))\\n        self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n        if len(self.bulk_prov) > ProvenancePE.BULK_SIZE:\\n            #self.log(\"TO SERVICE ________________ID: \"+str(self.bulk_prov))\\n            params = urllib.urlencode({\\'prov\\': ujson.dumps(self.bulk_prov)})\\n            headers = {\\n                \"Content-type\": \"application/x-www-form-urlencoded\",\\n                \"Accept\": \"application/json\"}\\n            self.connection = httplib.HTTPConnection(\\n                                                     self.provurl.netloc)\\n            self.connection.request(\\n                \"POST\", self.provurl.path, params, headers)\\n            response = self.connection.getresponse()\\n            self.log(\"progress: \" + str((response.status, response.reason,response.read())))\\n            #                             response, response.read())))\\n\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def setInputTypes(self, types):\\n        \\'\\'\\'\\n        Sets the input types of this PE, in the form of a dictionary.\\n        It is meant to be overridden, e.g. if output types depend on input.\\n\\n        .. note::\\n\\n            This method is always called before\\n            :py:func:`~dispel4py.core.GenericPE.getOutputTypes`.\\n\\n        :param types: object types for each input stream\\n        :type types: dictionary mapping input name to input type\\n\\n        Usage example::\\n\\n            pe.setInputTypes({\\'input1\\':[\\'t1\\', \\'t2\\', \\'t3\\'], \\\\\\n                              \\'input2\\':[\\'t4\\', \\'t5\\']})\\n        \\'\\'\\'\\n        pass\\n\\n    def update_prov_state(\\n            self,\\n            name,\\n            data,\\n            location=\"\",\\n            format=\"\",\\n            metadata={},\\n            ignore_inputs=True,\\n            stateless=False,\\n            **kwargs\\n    ):\\n\\n        self.endTime = datetime.datetime.utcnow()\\n        #self.resetflow = stateless\\n        self.ignore_inputs = ignore_inputs\\n        self.addprov=True\\n        kwargs[\\'name\\']=name\\n        #self.apply_flow_reset_policy(\\'state\\', None)\\n        if self.provon:\\n            if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n                for d in kwargs[\\'dep\\']:\\n                    did=self.getProvStateObjectId(d)\\n                    if did!=None:\\n                        self.buildDerivation({\\'id\\':did,\\'TriggeredByProcessIterationID\\':self.iterationId,\\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n\\n\\n            self.extractProvenance(data,\\n                               location,\\n                               format,\\n                               metadata,\\n                               output_port=\"_d4p_state\",\\n                               **kwargs)\\n\\n\\n\\n        self.ignore_inputs = False\\n\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            self.removeDerivation(port=\\'_d4p_state\\')\\n\\n    def write(self, name, data, **kwargs):\\n        self.void_iteration=False\\n        self.apply_flow_reset_policy(\\'write\\',True,port=name,data=data)\\n        # self.__markIteration()\\n        self.endTime = datetime.datetime.utcnow()\\n\\n        #if \\'state_reset\\' in kwargs:\\n        #    self.resetflow = bool(kwargs[\\'state_reset\\'])\\n        #else:\\n        #    None\\n#            self.resetflow = True\\n        \\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.buildDerivation({\\'id\\':self.getProvStateObjectId(d),\\'TriggeredByProcessIterationID\\':self.iterationId, \\'prov_cluster\\':self.prov_cluster}, port=\"_d4p_state\")\\n                #self.log(self.derivationIds)\\n\\n        if \\'ignore_inputs\\' in kwargs:\\n            #self.log(\"IGNORONG: \"+str(self.ignore_inputs))\\n            self.ignore_inputs=kwargs[\\'ignore_inputs\\']\\n        \\n        #if self.resetflow==True:\\n        #    self.discardOutFlow()\\n        \\n        self.extractProvenance(data, output_port=name, **kwargs)\\n\\n        if \\'dep\\' in kwargs and kwargs[\\'dep\\']!=None:\\n            for d in kwargs[\\'dep\\']:\\n                self.removeDerivation(name=d)\\n\\n    def writeProvToFile(self, prov):\\n        \\n        if isinstance(prov, list) and \"data\" in prov[0]:\\n            prov = prov[0][\"data\"]\\n        \\n         \\n        #self.log(\\'PROCESS: \\'+str(prov))\\n        self.bulk_prov.append(prov)\\n        \\n        \\n        if len(self.bulk_prov) == ProvenancePE.BULK_SIZE:\\n            filep = open(\\n                ProvenancePE.PROV_PATH +\\n                \"/bulk_\" +\\n                self.makeProcessId(),\\n                \"wr\")\\n            #self.log(\\'PROCESS: \\'+str(filep))\\n            ujson.dump(self.bulk_prov, filep)\\n            #filep.write(json.dumps(self.bulk_prov))\\n            self.bulk_prov[:]=[]\\n\\n        return None\\n\\n    def writeResults(self, name, result):\\n\\n        #self.resetflow = True\\n        self.apply_flow_reset_policy(\\'write\\',True,data=data,port=name)\\n        self.void_iteration=False\\n        \\n        \\n\\n        if isinstance(result, dict) and \\'_d4p_prov\\' in result:\\n            meta = result[\\'_d4p_prov\\']\\n            result = (result[\\'_d4p_data\\'])\\n\\n            if \\'error\\' in meta:\\n                self.extractProvenance(result, output_port=name, **meta)\\n            else:\\n\\n                self.extractProvenance(\\n                    result, error=self.error, output_port=name, **meta)\\n\\n        else:\\n            self.extractProvenance(result, error=self.error, output_port=name)\\n\\n', 'type': \"(<class 'dispel4py.provenance.StateUpdateType'>, <class '__main__.AnalysisAvg'>)\"}}, 'system_id': None, 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'startTime': '2017-06-21 21:42:20.024771', 'input': [], 'ns': {'clipc': 'http://clipc.eu/ns/#'}, 'type': 'workflow_run', 'workflowName': 'demo_ecmwf'}]\n",
      "NewWorkflowRun8: BEFORE [{'iterationIndex': 1, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "NewWorkflowRun8: ITENDEX 1\n",
      "NewWorkflowRun8: AFTER []\n",
      "NewWorkflowRun8: Postprocess: (200, 'OK', '{\"inserts\": [\"JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865\"], \"success\": true}')\n",
      "SimplePE: Processed 1 iteration.\n",
      "Outputs: {}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARcAAAFACAYAAACWWDibAAAAAXNSR0IArs4c6QAAQABJREFUeAHt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\nIGGfhoAhUFYEjLmUFU6rzBAwBAIC/w+bWyCTv6ZvgAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def createGraphWithProv():\n",
    "    \n",
    "    graph=createWorkflowGraph()\n",
    "    #Location of the remote repository for runtime updates of the lineage traces. Shared among ProvenanceRecorder subtypes\n",
    "\n",
    "    # Ranomdly generated unique identifier for the current run\n",
    "    rid='JUP_SIMPLE_'+getUniqueId()\n",
    "\n",
    "    \n",
    "    # Finally, provenance enhanced graph is prepared:\n",
    "    print prov_profile\n",
    "\n",
    "     \n",
    "    #Initialise provenance storage to service:\n",
    "    profile_prov_run(graph, \n",
    "                     provImpClass=(ProvenancePE,),\n",
    "                     username=prov_profile['username'],\n",
    "                     runId=rid,\n",
    "                     description=prov_profile['description'],\n",
    "                     workflowName=prov_profile['workflowName'],\n",
    "                     workflowId=prov_profile['workflowId'],\n",
    "                     save_mode=prov_profile['save_mode'],\n",
    "                     componentsType=prov_profile['componentsType'],\n",
    "                     sel_rules=prov_profile['sel_rules']\n",
    "                    )\n",
    "                   \n",
    "\n",
    "    #clustersRecorders={'record0':ProvenanceRecorderToFileBulk,'record1':ProvenanceRecorderToFileBulk,'record2':ProvenanceRecorderToFileBulk,'record6':ProvenanceRecorderToFileBulk,'record3':ProvenanceRecorderToFileBulk,'record4':ProvenanceRecorderToFileBulk,'record5':ProvenanceRecorderToFileBulk}\n",
    "    #Initialise provenance storage end associate a Provenance type with specific components:\n",
    "    #profile_prov_run(graph,provImpClass=ProvenancePE,componentsType={'Source':(ProvenanceStock,)},username='aspinuso',runId=rid,w3c_prov=False,description=\"provState\",workflowName=\"test_rdwd\",workflowId=\"xx\",save_mode='service')\n",
    "\n",
    "    #\n",
    "    return graph\n",
    "\n",
    "\n",
    "graph=createGraphWithProv()\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Run the workflow with provenance activatied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Collector': [{'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}, {'input': ['data/newA.nc', 'data/newB.nc']}]}\n",
      "SETTING NAME: SimpleProcessingPE\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80c4b06e-56ca-11e7-af4e-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 1, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80c4b06e-56ca-11e7-af4e-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.146995', '_id': 'Collector4_stateful_orfeus-as-46133-80c4b06e-56ca-11e7-af4e-f45c89acf865', 'name': 'Collector', 'iterationIndex': 1, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.184438'}]\n",
      "Collector4: BEFORE [{'iterationIndex': 1, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 1\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80c8c514-56ca-11e7-9608-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 2, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80c8c514-56ca-11e7-9608-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.146995', '_id': 'Collector4_stateful_orfeus-as-46133-80c4b06e-56ca-11e7-af4e-f45c89acf865', 'name': 'Collector', 'iterationIndex': 1, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.184438'}, {'derivationIds': [{'iterationIndex': 2, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.185653', '_id': 'Collector4_stateful_orfeus-as-46133-80c8c514-56ca-11e7-9608-f45c89acf865', 'name': 'Collector', 'iterationIndex': 2, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.211118'}]\n",
      "Collector4: progress: (200, 'OK', '{\"inserts\": [\"Collector4_stateful_orfeus-as-46133-80c4b06e-56ca-11e7-af4e-f45c89acf865\", \"Collector4_stateful_orfeus-as-46133-80c8c514-56ca-11e7-9608-f45c89acf865\"], \"success\": true}')\n",
      "Collector4: BEFORE [{'iterationIndex': 2, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 2\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80cf1099-56ca-11e7-a861-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 3, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80cf1099-56ca-11e7-a861-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.222711', '_id': 'Collector4_stateful_orfeus-as-46133-80cf1099-56ca-11e7-a861-f45c89acf865', 'name': 'Collector', 'iterationIndex': 3, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.252515'}]\n",
      "Collector4: BEFORE [{'iterationIndex': 3, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 3\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80d4f1a3-56ca-11e7-8a90-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 4, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80d4f1a3-56ca-11e7-8a90-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.222711', '_id': 'Collector4_stateful_orfeus-as-46133-80cf1099-56ca-11e7-a861-f45c89acf865', 'name': 'Collector', 'iterationIndex': 3, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.252515'}, {'derivationIds': [{'iterationIndex': 4, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80cf3cdc-56ca-11e7-97fe-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.253694', '_id': 'Collector4_stateful_orfeus-as-46133-80d4f1a3-56ca-11e7-8a90-f45c89acf865', 'name': 'Collector', 'iterationIndex': 4, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80d4ee5c-56ca-11e7-b89a-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.291072'}]\n",
      "Collector4: progress: (200, 'OK', '{\"inserts\": [\"Collector4_stateful_orfeus-as-46133-80cf1099-56ca-11e7-a861-f45c89acf865\", \"Collector4_stateful_orfeus-as-46133-80d4f1a3-56ca-11e7-8a90-f45c89acf865\"], \"success\": true}')\n",
      "Collector4: BEFORE [{'iterationIndex': 4, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 4\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80dbe145-56ca-11e7-bf84-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 5, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80dbe145-56ca-11e7-bf84-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 5, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.303185', '_id': 'Collector4_stateful_orfeus-as-46133-80dbe145-56ca-11e7-bf84-f45c89acf865', 'name': 'Collector', 'iterationIndex': 5, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.336503'}]\n",
      "Collector4: BEFORE [{'iterationIndex': 5, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 5\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80e0ecca-56ca-11e7-80b0-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 6, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80e0ecca-56ca-11e7-80b0-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 5, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.303185', '_id': 'Collector4_stateful_orfeus-as-46133-80dbe145-56ca-11e7-bf84-f45c89acf865', 'name': 'Collector', 'iterationIndex': 5, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.336503'}, {'derivationIds': [{'iterationIndex': 6, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80dbf935-56ca-11e7-9996-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.337168', '_id': 'Collector4_stateful_orfeus-as-46133-80e0ecca-56ca-11e7-80b0-f45c89acf865', 'name': 'Collector', 'iterationIndex': 6, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80e0ea21-56ca-11e7-bfab-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.369602'}]\n",
      "Collector4: progress: (200, 'OK', '{\"inserts\": [\"Collector4_stateful_orfeus-as-46133-80dbe145-56ca-11e7-bf84-f45c89acf865\", \"Collector4_stateful_orfeus-as-46133-80e0ecca-56ca-11e7-80b0-f45c89acf865\"], \"success\": true}')\n",
      "Collector4: BEFORE [{'iterationIndex': 6, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 6\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80e97e80-56ca-11e7-8a71-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 7, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80e97e80-56ca-11e7-8a71-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 7, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80e25b78-56ca-11e7-9917-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.378979', '_id': 'Collector4_stateful_orfeus-as-46133-80e97e80-56ca-11e7-8a71-f45c89acf865', 'name': 'Collector', 'iterationIndex': 7, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80e9791c-56ca-11e7-b95a-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.425719'}]\n",
      "Collector4: BEFORE [{'iterationIndex': 7, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 7\n",
      "Collector4: AFTER []\n",
      "Collector4: BUILDING INITIAL DERIVATION\n",
      "Collector4: NOOOT IGNOOOORING STTEEEE: Collector4_stateful_orfeus-as-46133-80f10451-56ca-11e7-8964-f45c89acf865\n",
      "Collector4: INSERT DERIV: [{'iterationIndex': 8, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: SENDING: Collector4_stateful_orfeus-as-46133-80f10451-56ca-11e7-8964-f45c89acf865\n",
      "Collector4: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 7, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80e25b78-56ca-11e7-9917-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.378979', '_id': 'Collector4_stateful_orfeus-as-46133-80e97e80-56ca-11e7-8a71-f45c89acf865', 'name': 'Collector', 'iterationIndex': 7, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80e9791c-56ca-11e7-b95a-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.425719'}, {'derivationIds': [{'iterationIndex': 8, 'DerivedFromDatasetID': None, 'prov_cluster': None, 'TriggeredByProcessIterationID': None, 'port': 'input'}], 'instanceId': 'Collector-Instance--orfeus-as-46133-80bedf5e-56ca-11e7-a2f0-f45c89acf865', 'pid': '46133', 'iterationId': 'Collector-orfeus-as-46133-80e9cd05-56ca-11e7-b5ce-f45c89acf865', 'prov_cluster': 'Collector4', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'Collector4', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.427786', '_id': 'Collector4_stateful_orfeus-as-46133-80f10451-56ca-11e7-8964-f45c89acf865', 'name': 'Collector', 'iterationIndex': 8, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newA.nc', 'id': 'orfeus-as-46133-80f0f759-56ca-11e7-b4e5-f45c89acf865', 'port': 'xarray', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.474912'}]\n",
      "Collector4: progress: (200, 'OK', '{\"inserts\": [\"Collector4_stateful_orfeus-as-46133-80e97e80-56ca-11e7-8a71-f45c89acf865\", \"Collector4_stateful_orfeus-as-46133-80f10451-56ca-11e7-8964-f45c89acf865\"], \"success\": true}')\n",
      "Collector4: BEFORE [{'iterationIndex': 8, 'DerivedFromDatasetID': None, 'TriggeredByProcessIterationID': None, 'port': 'input', 'prov_cluster': None}]\n",
      "Collector4: ITENDEX 8\n",
      "Collector4: AFTER []\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: PRINT AVG3\n",
      "ANALYSIS5: avg\n",
      "ANALYSIS5: Checking Skip-Rules\n",
      "ANALYSIS5: NOOOT IGNOOOORING STTEEEE: ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865\n",
      "ANALYSIS5: INSERT DERIV: [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}]\n",
      "ANALYSIS5:  Building SELF Derivation {'error': '', 'metadata': {'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'worker': 'orfeus-as', 'pid': '46133', 'mapping': '-f', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865', 'stateful': True, 'startTime': '2017-06-21 21:42:20.494206', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'name': 'ANALYSIS', 'parameters': [{'val': 10, 'key': 'filter'}], 'iterationIndex': 3, 'feedbackIteration': False, 'streams': [{'content': [{}], 'annotations': [], 'location': '', 'format': '', 'size': 0, 'port': '_d4p_state', 'id': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865'}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.494540', 'type': 'lineage', 'annotations': {}}}\n",
      "ANALYSIS5: SENDING: ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865\n",
      "ANALYSIS5: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'port': 'input'}, {'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'port': 'input'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'port': 'input'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.494206', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 3, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': '', 'id': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'port': '_d4p_state', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.494540'}]\n",
      "ANALYSIS5: BEFORE [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: ITENDEX 3\n",
      "ANALYSIS5: AFTER [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: Checking Skip-Rules\n",
      "ANALYSIS5: NOOOT IGNOOOORING STTEEEE: ANALYSIS5_stateful_orfeus-as-46133-80f42807-56ca-11e7-b14f-f45c89acf865\n",
      "ANALYSIS5: INSERT DERIV: [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: SENDING: ANALYSIS5_stateful_orfeus-as-46133-80f42807-56ca-11e7-b14f-f45c89acf865\n",
      "ANALYSIS5: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80c4a69e-56ca-11e7-b6ba-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80bef4e3-56ca-11e7-8890-f45c89acf865', 'port': 'input'}, {'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80c8b921-56ca-11e7-ae6b-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80c4dae3-56ca-11e7-b346-f45c89acf865', 'port': 'input'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80cf0ba3-56ca-11e7-839e-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80ca823d-56ca-11e7-a995-f45c89acf865', 'port': 'input'}, {'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.494206', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 3, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': '', 'id': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'port': '_d4p_state', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.494540'}, {'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.494206', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f42807-56ca-11e7-b14f-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 3, 'streams': [{'format': '', 'annotations': [], 'content': [{'count': 3}], 'location': '', 'id': 'orfeus-as-46133-80f422ae-56ca-11e7-8e5a-f45c89acf865', 'port': 'avg', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.495577'}]\n",
      "ANALYSIS5: progress: (200, 'OK', '{\"inserts\": [\"ANALYSIS5_stateful_orfeus-as-46133-80f3fed9-56ca-11e7-a5a7-f45c89acf865\", \"ANALYSIS5_stateful_orfeus-as-46133-80f42807-56ca-11e7-b14f-f45c89acf865\"], \"success\": true}')\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: PRINT thr5\n",
      "ANALYSIS5: threshold\n",
      "ANALYSIS5: Checking Skip-Rules\n",
      "ANALYSIS5: IGNOOOORING STTEEEE: ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865\n",
      "ANALYSIS5: DADADADAD :{'error': '', 'metadata': {'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'worker': 'orfeus-as', 'pid': '46133', 'mapping': '-f', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508416', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'name': 'ANALYSIS', 'parameters': [{'val': 10, 'key': 'filter'}], 'iterationIndex': 5, 'feedbackIteration': False, 'streams': [{'content': [{'count': 5}], 'annotations': [], 'location': '', 'format': '', 'size': 0, 'port': 'threshold', 'id': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865'}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.508557', 'type': 'lineage', 'annotations': {}}}\n",
      "ANALYSIS5: SENDING: ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865\n",
      "ANALYSIS5: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508416', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 5, 'streams': [{'format': '', 'annotations': [], 'content': [{'count': 5}], 'location': '', 'id': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865', 'port': 'threshold', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.508557'}]\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: PRINT AVG6\n",
      "ANALYSIS5: avg\n",
      "ANALYSIS5: Checking Skip-Rules\n",
      "ANALYSIS5: NOOOT IGNOOOORING STTEEEE: ANALYSIS5_stateful_orfeus-as-46133-80f6340f-56ca-11e7-a499-f45c89acf865\n",
      "ANALYSIS5: INSERT DERIV: [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}, {'iterationIndex': 4, 'DerivedFromDatasetID': 'orfeus-as-46133-80d4ee5c-56ca-11e7-b89a-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80cf3cdc-56ca-11e7-97fe-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80e0ea21-56ca-11e7-bfab-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80dbf935-56ca-11e7-9996-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}]\n",
      "ANALYSIS5:  Building SELF Derivation {'error': '', 'metadata': {'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}, {'iterationIndex': 4, 'DerivedFromDatasetID': 'orfeus-as-46133-80d4ee5c-56ca-11e7-b89a-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80cf3cdc-56ca-11e7-97fe-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80e0ea21-56ca-11e7-bfab-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80dbf935-56ca-11e7-9996-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'worker': 'orfeus-as', 'pid': '46133', 'mapping': '-f', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f6340f-56ca-11e7-a499-f45c89acf865', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508941', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'name': 'ANALYSIS', 'parameters': [{'val': 10, 'key': 'filter'}], 'iterationIndex': 6, 'feedbackIteration': False, 'streams': [{'content': [{}], 'annotations': [], 'location': '', 'format': '', 'size': 0, 'port': '_d4p_state', 'id': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865'}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.509055', 'type': 'lineage', 'annotations': {}}}\n",
      "ANALYSIS5: SENDING: ANALYSIS5_stateful_orfeus-as-46133-80f6340f-56ca-11e7-a499-f45c89acf865\n",
      "ANALYSIS5: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508416', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 5, 'streams': [{'format': '', 'annotations': [], 'content': [{'count': 5}], 'location': '', 'id': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865', 'port': 'threshold', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.508557'}, {'derivationIds': [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state'}, {'iterationIndex': 4, 'DerivedFromDatasetID': 'orfeus-as-46133-80d4ee5c-56ca-11e7-b89a-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80cf3cdc-56ca-11e7-97fe-f45c89acf865', 'port': 'input'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80e0ea21-56ca-11e7-bfab-f45c89acf865', 'prov_cluster': 'Collector4', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80dbf935-56ca-11e7-9996-f45c89acf865', 'port': 'input'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': '_d4p_state'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508941', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f6340f-56ca-11e7-a499-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 6, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': '', 'id': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'port': '_d4p_state', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.509055'}]\n",
      "ANALYSIS5: progress: (200, 'OK', '{\"inserts\": [\"ANALYSIS5_stateful_orfeus-as-46133-80f620eb-56ca-11e7-9e07-f45c89acf865\", \"ANALYSIS5_stateful_orfeus-as-46133-80f6340f-56ca-11e7-a499-f45c89acf865\"], \"success\": true}')\n",
      "ANALYSIS5: BEFORE [{'iterationIndex': 3, 'DerivedFromDatasetID': 'orfeus-as-46133-80f3f55c-56ca-11e7-a95d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}, {'iterationIndex': 4, 'DerivedFromDatasetID': 'orfeus-as-46133-80d4ee5c-56ca-11e7-b89a-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80cf3cdc-56ca-11e7-97fe-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 5, 'DerivedFromDatasetID': 'orfeus-as-46133-80dbdc4c-56ca-11e7-ab32-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80d6c9c0-56ca-11e7-986d-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80e0ea21-56ca-11e7-bfab-f45c89acf865', 'TriggeredByProcessIterationID': 'Collector-orfeus-as-46133-80dbf935-56ca-11e7-9996-f45c89acf865', 'port': 'input', 'prov_cluster': 'Collector4'}, {'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: ITENDEX 6\n",
      "ANALYSIS5: AFTER [{'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: Checking Skip-Rules\n",
      "ANALYSIS5: NOOOT IGNOOOORING STTEEEE: ANALYSIS5_stateful_orfeus-as-46133-80f7feb8-56ca-11e7-8925-f45c89acf865\n",
      "ANALYSIS5: INSERT DERIV: [{'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': '_d4p_state', 'prov_cluster': 'ANALYSIS5'}]\n",
      "ANALYSIS5: SENDING: ANALYSIS5_stateful_orfeus-as-46133-80f7feb8-56ca-11e7-8925-f45c89acf865\n",
      "ANALYSIS5: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 6, 'DerivedFromDatasetID': 'orfeus-as-46133-80f631f0-56ca-11e7-98c4-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': '_d4p_state'}], 'instanceId': 'ANALYSIS-Instance--orfeus-as-46133-80bee314-56ca-11e7-abce-f45c89acf865', 'pid': '46133', 'iterationId': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'errors': '', 'parameters': [{'key': 'filter', 'val': 10}], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'ANALYSIS5', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.508941', '_id': 'ANALYSIS5_stateful_orfeus-as-46133-80f7feb8-56ca-11e7-8925-f45c89acf865', 'name': 'ANALYSIS', 'iterationIndex': 6, 'streams': [{'format': '', 'annotations': [], 'content': [{'count': 6}], 'location': '', 'id': 'orfeus-as-46133-80f7fa80-56ca-11e7-b122-f45c89acf865', 'port': 'avg', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.520768'}]\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: None\n",
      "ANALYSIS5: None\n",
      "StoreFile6: Write_Function\n",
      "StoreFile6: ANDREJ.extractItemMetadata\n",
      "StoreFile6: ANDREJ.makeUniqueId\n",
      "StoreFile6: NOOOT IGNOOOORING STTEEEE: StoreFile6_stateful_orfeus-as-46133-80f88c4a-56ca-11e7-b7ed-f45c89acf865\n",
      "StoreFile6: INSERT DERIV: [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f422ae-56ca-11e7-8e5a-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreFile6: SENDING: StoreFile6_stateful_orfeus-as-46133-80f88c4a-56ca-11e7-b7ed-f45c89acf865\n",
      "StoreFile6: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f422ae-56ca-11e7-8e5a-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': 'input'}], 'instanceId': 'StoreFile-Instance--orfeus-as-46133-80bee538-56ca-11e7-8cd9-f45c89acf865', 'pid': '46133', 'iterationId': 'StoreFile-orfeus-as-46133-80f81da8-56ca-11e7-bbe3-f45c89acf865', 'prov_cluster': 'StoreFile6', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'StoreFile6', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.521600', '_id': 'StoreFile6_stateful_orfeus-as-46133-80f88c4a-56ca-11e7-b7ed-f45c89acf865', 'name': 'StoreFile', 'iterationIndex': 1, 'streams': [{'format': '', 'annotations': [], 'content': [OrderedDict([('Dimensions', \"{u'y': 721, u'x': 721, u'bnds': 2, u'time': 12}\"), ('Type', \"<class 'xarray.core.dataset.Dataset'>\"), ('clipc:source', 'SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data'), ('clipc:auxiliary_data', 'GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask'), ('clipc:product_version', '2.0'), ('clipc:summary', 'Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland'), ('clipc:id', '0953ef85-3a11-11e7-86f3-f45c89acf865'), ('clipc:naming_authority', 'fi.fmi'), ('clipc:keywords_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:cdm_data_type', 'grid'), ('clipc:project', 'ESA GlobSnow-2'), ('clipc:geospatial_vertical_min', '0.0'), ('clipc:geospatial_vertical_max', '0.0'), ('clipc:geospatial_lat_units', 'degrees north'), ('clipc:geospatial_lon_units', 'degrees east'), ('clipc:standard_name_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:license', 'These data may be redistributed and used without restriction.'), ('clipc:sensor', 'SMMR'), ('clipc:spatial_resolution', '25 km'), ('clipc:algorithm', 'FMI assimilation algorithm (Pulliainen 2006)'), ('clipc:tracking_id', '47092dd1-7a86-47b1-952c-3ae3163d3828'), ('clipc:Conventions', 'CF-1.6'), ('clipc:package_references', 'ophidia.cmcc.it'), ('clipc:date_published', '2016-07-19'), ('clipc:date_revised', '2016-07-19'), ('clipc:institution', 'CMCC'), ('clipc:institution_id', 'CMCC'), ('clipc:institution_url', 'www.cmcc.it'), ('clipc:contact_email', 'ophidia-info@lists.cmcc.it'), ('clipc:creator_name', 'CMCC'), ('clipc:creator_url', 'www.cmcc.it'), ('clipc:creator_email', 'ophidia-info@lists.cmcc.it'), ('clipc:contributor_name', ' '), ('clipc:contributor_role', ' '), ('clipc:platform', 'station'), ('clipc:platform_id', 'NIMBUS'), ('clipc:satellite_algorithm', ' '), ('clipc:satellite_sensor', 'SMMR'), ('clipc:indata_history', ' '), ('clipc:frequency', 'mon'), ('clipc:cdm_datatype', 'grid'), ('clipc:geospatial_bounds', 'POLYGON (35 -180, 85 -180, 85 180, 35 180)'), ('clipc:geospatial_lat_min', '35.0'), ('clipc:geospatial_lat_max', '85.0'), ('clipc:geospatial_lon_min', '-180.0'), ('clipc:geospatial_lon_max', '180.0'), ('clipc:geospatial_lat_resolution', '25 km'), ('clipc:geospatial_lon_resolution', '25 km'), ('clipc:project_id', 'CLIP-C'), ('clipc:activity', 'clipc'), ('clipc:title', 'Snow Water Equivalent, Oct monthly aggregate value'), ('clipc:time_coverage_start', '19791001'), ('clipc:product', 'obs_derived'), ('clipc:comment', ' '), ('clipc:references', ' '), ('clipc:package_name', 'ophidia-0-10-1'), ('clipc:date_created', '20160701'), ('clipc:date_modified', ' '), ('clipc:date_issued', '20160802'), ('clipc:source_data_id', 'GlobSnow-SWE-L3B'), ('clipc:source_data_id_comment', ' '), ('clipc:invar_platform', 'remote sensing'), ('clipc:invar_platform_id', 'ESA GlobSnow'), ('clipc:invar_satellite_algorithm', ' '), ('clipc:invar_satellite_sensor', 'SMMR'), ('clipc:invar_rcm_model_id', ' '), ('clipc:invar_rcm_model_realization_id', ' '), ('clipc:invar_rcm_model_driver', ' '), ('clipc:invar_reanalysis_id', ' '), ('clipc:invar_gcm_model_id', ' '), ('clipc:invar_experiment_name', ' '), ('clipc:invar_ensemble_member', ' '), ('clipc:invar_bc_method_id', ' '), ('clipc:invar_bc_observation_id', ' '), ('clipc:invar_bc_period', ' '), ('clipc:invar_variable_name', 'SWE_avg'), ('clipc:reference_period', '1979-2008'), ('clipc:output_frequency', 'monClim'), ('clipc:tile', ' '), ('clipc:keywords', 'SWE-avg,climate,index'), ('clipc:invar_tracking_id', ' '), ('clipc:contact', 'ophidia-info@lists.cmcc.it'), ('clipc:realisation_id', ' '), ('clipc:variable_name', 'SWE'), ('clipc:history', ' '), ('clipc:domain', '180E-180W-35N-85N'), ('clipc:time_coverage_end', '20080701'), ('clipc:DODS_strlen', '0'), ('clipc:DODS_EXTRA_Unlimited_Dimension', 'time'), (u'clipc:time_bnds_comment', 'Contains the start and end times for the time period the data represent'), (u'clipc:time_bnds_long_name', 'Time cell boundaries'), (u'clipc:time_bnds__ChunkSize', '[1 2]'), (u'clipc:lambert_azimuthal_equal_area_grid_mapping_name', 'lambert_azimuthal_equal_area'), (u'clipc:lambert_azimuthal_equal_area_false_easting', '0.0'), (u'clipc:lambert_azimuthal_equal_area_false_northing', '0.0'), (u'clipc:lambert_azimuthal_equal_area_latitude_of_projection_origin', '90.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_projection_origin', '0.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_prime_meridian', '0.0'), (u'clipc:lambert_azimuthal_equal_area_semi_major_axis', '6371228.0'), (u'clipc:lambert_azimuthal_equal_area_inverse_flattening', '0.0'), (u'clipc:lambert_azimuthal_equal_area_spatial_ref', 'PROJCS[\"NSIDC EASE-Grid North\",GEOGCS[\"Unspecified datum based upon the International 1924 Authalic Sphere\",DATUM[\"Not_specified_based_on_International_1924_Authalic_Sphere\",SPHEROID[\"International 1924 Authalic Sphere\",6371228,0,AUTHORITY[\"EPSG\",\"7057\"]],AUTHORITY[\"EPSG\",\"6053\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4053\"]],PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],PARAMETER[\"latitude_of_center\",90],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3408\"]]'), (u'clipc:lambert_azimuthal_equal_area_GeoTransform', '-9036842.762 25067.525 0 9036842.763000002 0 -25067.525 '), (u'clipc:SWE_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:SWE_units', 'mm'), (u'clipc:SWE_standard_name', 'lwe_thickness_of_surface_snow_amount'), (u'clipc:SWE_long_name', 'Snow Water Equivalent'), (u'clipc:SWE__ChunkSize', '[  1 721 721]'), (u'clipc:lat_long_name', 'WGS84 latitude coordinates, center of pixel'), (u'clipc:lat_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lat_units', 'degrees'), (u'clipc:lon_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lon_units', 'degrees'), (u'clipc:lon_long_name', 'WGS84 longitude coordinates, center of pixel')])], 'location': 'data/newB.nc', 'id': '80f886fa-56ca-11e7-9223-f45c89acf865', 'port': 'storedData', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.524377'}]\n",
      "StoreFile6: BEFORE [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f422ae-56ca-11e7-8e5a-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreFile6: ITENDEX 1\n",
      "StoreFile6: AFTER []\n",
      "StoreFile6: Write_Function\n",
      "StoreFile6: ANDREJ.extractItemMetadata\n",
      "StoreFile6: ANDREJ.makeUniqueId\n",
      "StoreFile6: NOOOT IGNOOOORING STTEEEE: StoreFile6_stateful_orfeus-as-46133-81234ba6-56ca-11e7-afbe-f45c89acf865\n",
      "StoreFile6: INSERT DERIV: [{'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80f7fa80-56ca-11e7-b122-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreFile6: SENDING: StoreFile6_stateful_orfeus-as-46133-81234ba6-56ca-11e7-afbe-f45c89acf865\n",
      "StoreFile6: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f422ae-56ca-11e7-8e5a-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f3ef78-56ca-11e7-88f0-f45c89acf865', 'port': 'input'}], 'instanceId': 'StoreFile-Instance--orfeus-as-46133-80bee538-56ca-11e7-8cd9-f45c89acf865', 'pid': '46133', 'iterationId': 'StoreFile-orfeus-as-46133-80f81da8-56ca-11e7-bbe3-f45c89acf865', 'prov_cluster': 'StoreFile6', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'StoreFile6', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.521600', '_id': 'StoreFile6_stateful_orfeus-as-46133-80f88c4a-56ca-11e7-b7ed-f45c89acf865', 'name': 'StoreFile', 'iterationIndex': 1, 'streams': [{'format': '', 'annotations': [], 'content': [OrderedDict([('Dimensions', \"{u'y': 721, u'x': 721, u'bnds': 2, u'time': 12}\"), ('Type', \"<class 'xarray.core.dataset.Dataset'>\"), ('clipc:source', 'SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data'), ('clipc:auxiliary_data', 'GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask'), ('clipc:product_version', '2.0'), ('clipc:summary', 'Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland'), ('clipc:id', '0953ef85-3a11-11e7-86f3-f45c89acf865'), ('clipc:naming_authority', 'fi.fmi'), ('clipc:keywords_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:cdm_data_type', 'grid'), ('clipc:project', 'ESA GlobSnow-2'), ('clipc:geospatial_vertical_min', '0.0'), ('clipc:geospatial_vertical_max', '0.0'), ('clipc:geospatial_lat_units', 'degrees north'), ('clipc:geospatial_lon_units', 'degrees east'), ('clipc:standard_name_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:license', 'These data may be redistributed and used without restriction.'), ('clipc:sensor', 'SMMR'), ('clipc:spatial_resolution', '25 km'), ('clipc:algorithm', 'FMI assimilation algorithm (Pulliainen 2006)'), ('clipc:tracking_id', '47092dd1-7a86-47b1-952c-3ae3163d3828'), ('clipc:Conventions', 'CF-1.6'), ('clipc:package_references', 'ophidia.cmcc.it'), ('clipc:date_published', '2016-07-19'), ('clipc:date_revised', '2016-07-19'), ('clipc:institution', 'CMCC'), ('clipc:institution_id', 'CMCC'), ('clipc:institution_url', 'www.cmcc.it'), ('clipc:contact_email', 'ophidia-info@lists.cmcc.it'), ('clipc:creator_name', 'CMCC'), ('clipc:creator_url', 'www.cmcc.it'), ('clipc:creator_email', 'ophidia-info@lists.cmcc.it'), ('clipc:contributor_name', ' '), ('clipc:contributor_role', ' '), ('clipc:platform', 'station'), ('clipc:platform_id', 'NIMBUS'), ('clipc:satellite_algorithm', ' '), ('clipc:satellite_sensor', 'SMMR'), ('clipc:indata_history', ' '), ('clipc:frequency', 'mon'), ('clipc:cdm_datatype', 'grid'), ('clipc:geospatial_bounds', 'POLYGON (35 -180, 85 -180, 85 180, 35 180)'), ('clipc:geospatial_lat_min', '35.0'), ('clipc:geospatial_lat_max', '85.0'), ('clipc:geospatial_lon_min', '-180.0'), ('clipc:geospatial_lon_max', '180.0'), ('clipc:geospatial_lat_resolution', '25 km'), ('clipc:geospatial_lon_resolution', '25 km'), ('clipc:project_id', 'CLIP-C'), ('clipc:activity', 'clipc'), ('clipc:title', 'Snow Water Equivalent, Oct monthly aggregate value'), ('clipc:time_coverage_start', '19791001'), ('clipc:product', 'obs_derived'), ('clipc:comment', ' '), ('clipc:references', ' '), ('clipc:package_name', 'ophidia-0-10-1'), ('clipc:date_created', '20160701'), ('clipc:date_modified', ' '), ('clipc:date_issued', '20160802'), ('clipc:source_data_id', 'GlobSnow-SWE-L3B'), ('clipc:source_data_id_comment', ' '), ('clipc:invar_platform', 'remote sensing'), ('clipc:invar_platform_id', 'ESA GlobSnow'), ('clipc:invar_satellite_algorithm', ' '), ('clipc:invar_satellite_sensor', 'SMMR'), ('clipc:invar_rcm_model_id', ' '), ('clipc:invar_rcm_model_realization_id', ' '), ('clipc:invar_rcm_model_driver', ' '), ('clipc:invar_reanalysis_id', ' '), ('clipc:invar_gcm_model_id', ' '), ('clipc:invar_experiment_name', ' '), ('clipc:invar_ensemble_member', ' '), ('clipc:invar_bc_method_id', ' '), ('clipc:invar_bc_observation_id', ' '), ('clipc:invar_bc_period', ' '), ('clipc:invar_variable_name', 'SWE_avg'), ('clipc:reference_period', '1979-2008'), ('clipc:output_frequency', 'monClim'), ('clipc:tile', ' '), ('clipc:keywords', 'SWE-avg,climate,index'), ('clipc:invar_tracking_id', ' '), ('clipc:contact', 'ophidia-info@lists.cmcc.it'), ('clipc:realisation_id', ' '), ('clipc:variable_name', 'SWE'), ('clipc:history', ' '), ('clipc:domain', '180E-180W-35N-85N'), ('clipc:time_coverage_end', '20080701'), ('clipc:DODS_strlen', '0'), ('clipc:DODS_EXTRA_Unlimited_Dimension', 'time'), (u'clipc:time_bnds_comment', 'Contains the start and end times for the time period the data represent'), (u'clipc:time_bnds_long_name', 'Time cell boundaries'), (u'clipc:time_bnds__ChunkSize', '[1 2]'), (u'clipc:lambert_azimuthal_equal_area_grid_mapping_name', 'lambert_azimuthal_equal_area'), (u'clipc:lambert_azimuthal_equal_area_false_easting', '0.0'), (u'clipc:lambert_azimuthal_equal_area_false_northing', '0.0'), (u'clipc:lambert_azimuthal_equal_area_latitude_of_projection_origin', '90.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_projection_origin', '0.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_prime_meridian', '0.0'), (u'clipc:lambert_azimuthal_equal_area_semi_major_axis', '6371228.0'), (u'clipc:lambert_azimuthal_equal_area_inverse_flattening', '0.0'), (u'clipc:lambert_azimuthal_equal_area_spatial_ref', 'PROJCS[\"NSIDC EASE-Grid North\",GEOGCS[\"Unspecified datum based upon the International 1924 Authalic Sphere\",DATUM[\"Not_specified_based_on_International_1924_Authalic_Sphere\",SPHEROID[\"International 1924 Authalic Sphere\",6371228,0,AUTHORITY[\"EPSG\",\"7057\"]],AUTHORITY[\"EPSG\",\"6053\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4053\"]],PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],PARAMETER[\"latitude_of_center\",90],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3408\"]]'), (u'clipc:lambert_azimuthal_equal_area_GeoTransform', '-9036842.762 25067.525 0 9036842.763000002 0 -25067.525 '), (u'clipc:SWE_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:SWE_units', 'mm'), (u'clipc:SWE_standard_name', 'lwe_thickness_of_surface_snow_amount'), (u'clipc:SWE_long_name', 'Snow Water Equivalent'), (u'clipc:SWE__ChunkSize', '[  1 721 721]'), (u'clipc:lat_long_name', 'WGS84 latitude coordinates, center of pixel'), (u'clipc:lat_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lat_units', 'degrees'), (u'clipc:lon_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lon_units', 'degrees'), (u'clipc:lon_long_name', 'WGS84 longitude coordinates, center of pixel')])], 'location': 'data/newB.nc', 'id': '80f886fa-56ca-11e7-9223-f45c89acf865', 'port': 'storedData', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.524377'}, {'derivationIds': [{'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80f7fa80-56ca-11e7-b122-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': 'input'}], 'instanceId': 'StoreFile-Instance--orfeus-as-46133-80bee538-56ca-11e7-8cd9-f45c89acf865', 'pid': '46133', 'iterationId': 'StoreFile-orfeus-as-46133-81230b4f-56ca-11e7-803d-f45c89acf865', 'prov_cluster': 'StoreFile6', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'StoreFile6', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:20.802874', '_id': 'StoreFile6_stateful_orfeus-as-46133-81234ba6-56ca-11e7-afbe-f45c89acf865', 'name': 'StoreFile', 'iterationIndex': 2, 'streams': [{'format': '', 'annotations': [], 'content': [OrderedDict([('Dimensions', \"{u'y': 721, u'x': 721, u'bnds': 2, u'time': 12}\"), ('Type', \"<class 'xarray.core.dataset.Dataset'>\"), ('clipc:source', 'SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data'), ('clipc:auxiliary_data', 'GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask'), ('clipc:product_version', '2.0'), ('clipc:summary', 'Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland'), ('clipc:id', '0953ef85-3a11-11e7-86f3-f45c89acf865'), ('clipc:naming_authority', 'fi.fmi'), ('clipc:keywords_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:cdm_data_type', 'grid'), ('clipc:project', 'ESA GlobSnow-2'), ('clipc:geospatial_vertical_min', '0.0'), ('clipc:geospatial_vertical_max', '0.0'), ('clipc:geospatial_lat_units', 'degrees north'), ('clipc:geospatial_lon_units', 'degrees east'), ('clipc:standard_name_vocabulary', 'NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)'), ('clipc:license', 'These data may be redistributed and used without restriction.'), ('clipc:sensor', 'SMMR'), ('clipc:spatial_resolution', '25 km'), ('clipc:algorithm', 'FMI assimilation algorithm (Pulliainen 2006)'), ('clipc:tracking_id', '47092dd1-7a86-47b1-952c-3ae3163d3828'), ('clipc:Conventions', 'CF-1.6'), ('clipc:package_references', 'ophidia.cmcc.it'), ('clipc:date_published', '2016-07-19'), ('clipc:date_revised', '2016-07-19'), ('clipc:institution', 'CMCC'), ('clipc:institution_id', 'CMCC'), ('clipc:institution_url', 'www.cmcc.it'), ('clipc:contact_email', 'ophidia-info@lists.cmcc.it'), ('clipc:creator_name', 'CMCC'), ('clipc:creator_url', 'www.cmcc.it'), ('clipc:creator_email', 'ophidia-info@lists.cmcc.it'), ('clipc:contributor_name', ' '), ('clipc:contributor_role', ' '), ('clipc:platform', 'station'), ('clipc:platform_id', 'NIMBUS'), ('clipc:satellite_algorithm', ' '), ('clipc:satellite_sensor', 'SMMR'), ('clipc:indata_history', ' '), ('clipc:frequency', 'mon'), ('clipc:cdm_datatype', 'grid'), ('clipc:geospatial_bounds', 'POLYGON (35 -180, 85 -180, 85 180, 35 180)'), ('clipc:geospatial_lat_min', '35.0'), ('clipc:geospatial_lat_max', '85.0'), ('clipc:geospatial_lon_min', '-180.0'), ('clipc:geospatial_lon_max', '180.0'), ('clipc:geospatial_lat_resolution', '25 km'), ('clipc:geospatial_lon_resolution', '25 km'), ('clipc:project_id', 'CLIP-C'), ('clipc:activity', 'clipc'), ('clipc:title', 'Snow Water Equivalent, Oct monthly aggregate value'), ('clipc:time_coverage_start', '19791001'), ('clipc:product', 'obs_derived'), ('clipc:comment', ' '), ('clipc:references', ' '), ('clipc:package_name', 'ophidia-0-10-1'), ('clipc:date_created', '20160701'), ('clipc:date_modified', ' '), ('clipc:date_issued', '20160802'), ('clipc:source_data_id', 'GlobSnow-SWE-L3B'), ('clipc:source_data_id_comment', ' '), ('clipc:invar_platform', 'remote sensing'), ('clipc:invar_platform_id', 'ESA GlobSnow'), ('clipc:invar_satellite_algorithm', ' '), ('clipc:invar_satellite_sensor', 'SMMR'), ('clipc:invar_rcm_model_id', ' '), ('clipc:invar_rcm_model_realization_id', ' '), ('clipc:invar_rcm_model_driver', ' '), ('clipc:invar_reanalysis_id', ' '), ('clipc:invar_gcm_model_id', ' '), ('clipc:invar_experiment_name', ' '), ('clipc:invar_ensemble_member', ' '), ('clipc:invar_bc_method_id', ' '), ('clipc:invar_bc_observation_id', ' '), ('clipc:invar_bc_period', ' '), ('clipc:invar_variable_name', 'SWE_avg'), ('clipc:reference_period', '1979-2008'), ('clipc:output_frequency', 'monClim'), ('clipc:tile', ' '), ('clipc:keywords', 'SWE-avg,climate,index'), ('clipc:invar_tracking_id', ' '), ('clipc:contact', 'ophidia-info@lists.cmcc.it'), ('clipc:realisation_id', ' '), ('clipc:variable_name', 'SWE'), ('clipc:history', ' '), ('clipc:domain', '180E-180W-35N-85N'), ('clipc:time_coverage_end', '20080701'), ('clipc:DODS_strlen', '0'), ('clipc:DODS_EXTRA_Unlimited_Dimension', 'time'), (u'clipc:time_bnds_comment', 'Contains the start and end times for the time period the data represent'), (u'clipc:time_bnds_long_name', 'Time cell boundaries'), (u'clipc:time_bnds__ChunkSize', '[1 2]'), (u'clipc:lambert_azimuthal_equal_area_grid_mapping_name', 'lambert_azimuthal_equal_area'), (u'clipc:lambert_azimuthal_equal_area_false_easting', '0.0'), (u'clipc:lambert_azimuthal_equal_area_false_northing', '0.0'), (u'clipc:lambert_azimuthal_equal_area_latitude_of_projection_origin', '90.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_projection_origin', '0.0'), (u'clipc:lambert_azimuthal_equal_area_longitude_of_prime_meridian', '0.0'), (u'clipc:lambert_azimuthal_equal_area_semi_major_axis', '6371228.0'), (u'clipc:lambert_azimuthal_equal_area_inverse_flattening', '0.0'), (u'clipc:lambert_azimuthal_equal_area_spatial_ref', 'PROJCS[\"NSIDC EASE-Grid North\",GEOGCS[\"Unspecified datum based upon the International 1924 Authalic Sphere\",DATUM[\"Not_specified_based_on_International_1924_Authalic_Sphere\",SPHEROID[\"International 1924 Authalic Sphere\",6371228,0,AUTHORITY[\"EPSG\",\"7057\"]],AUTHORITY[\"EPSG\",\"6053\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4053\"]],PROJECTION[\"Lambert_Azimuthal_Equal_Area\"],PARAMETER[\"latitude_of_center\",90],PARAMETER[\"longitude_of_center\",0],PARAMETER[\"false_easting\",0],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"X\",EAST],AXIS[\"Y\",NORTH],AUTHORITY[\"EPSG\",\"3408\"]]'), (u'clipc:lambert_azimuthal_equal_area_GeoTransform', '-9036842.762 25067.525 0 9036842.763000002 0 -25067.525 '), (u'clipc:SWE_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:SWE_units', 'mm'), (u'clipc:SWE_standard_name', 'lwe_thickness_of_surface_snow_amount'), (u'clipc:SWE_long_name', 'Snow Water Equivalent'), (u'clipc:SWE__ChunkSize', '[  1 721 721]'), (u'clipc:lat_long_name', 'WGS84 latitude coordinates, center of pixel'), (u'clipc:lat_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lat_units', 'degrees'), (u'clipc:lon_grid_mapping', 'lambert_azimuthal_equal_area'), (u'clipc:lon_units', 'degrees'), (u'clipc:lon_long_name', 'WGS84 longitude coordinates, center of pixel')])], 'location': 'data/newB.nc', 'id': '8123462e-56ca-11e7-8aa5-f45c89acf865', 'port': 'storedData', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:20.804519'}]\n",
      "StoreFile6: progress: (200, 'OK', '{\"inserts\": [\"StoreFile6_stateful_orfeus-as-46133-80f88c4a-56ca-11e7-b7ed-f45c89acf865\", \"StoreFile6_stateful_orfeus-as-46133-81234ba6-56ca-11e7-afbe-f45c89acf865\"], \"success\": true}')\n",
      "StoreFile6: BEFORE [{'iterationIndex': 2, 'DerivedFromDatasetID': 'orfeus-as-46133-80f7fa80-56ca-11e7-b122-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f62eee-56ca-11e7-b5c2-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreFile6: ITENDEX 2\n",
      "StoreFile6: AFTER []\n",
      "StoreThreshold7: Write_Function\n",
      "StoreThreshold7: NOOOT IGNOOOORING STTEEEE: StoreThreshold7_stateful_orfeus-as-46133-814c3f0c-56ca-11e7-a75d-f45c89acf865\n",
      "StoreThreshold7: INSERT DERIV: [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreThreshold7: SENDING: StoreThreshold7_stateful_orfeus-as-46133-814c3f0c-56ca-11e7-a75d-f45c89acf865\n",
      "StoreThreshold7: TO SERVICE ________________ID: [{'derivationIds': [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865', 'prov_cluster': 'ANALYSIS5', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'port': 'input'}], 'instanceId': 'StoreThreshold-Instance--orfeus-as-46133-80bee882-56ca-11e7-b374-f45c89acf865', 'pid': '46133', 'iterationId': 'StoreThreshold-orfeus-as-46133-814c2eeb-56ca-11e7-b4d4-f45c89acf865', 'prov_cluster': 'StoreThreshold7', 'errors': '', 'parameters': [], 'feedbackIteration': False, 'type': 'lineage', 'annotations': {}, 'username': 'aspinuso', 'actedOnBehalfOf': 'StoreThreshold7', 'worker': 'orfeus-as', 'mapping': '-f', 'stateful': True, 'startTime': '2017-06-21 21:42:21.072533', '_id': 'StoreThreshold7_stateful_orfeus-as-46133-814c3f0c-56ca-11e7-a75d-f45c89acf865', 'name': 'StoreThreshold', 'iterationIndex': 1, 'streams': [{'format': '', 'annotations': [], 'content': [{}], 'location': 'data/newB.nc', 'id': 'orfeus-as-46133-814c33b8-56ca-11e7-b663-f45c89acf865', 'port': 'storedData', 'size': 0}], 'runId': 'JUP_SIMPLE_orfeus-as-46133-8090baa1-56ca-11e7-8e45-f45c89acf865', 'endTime': '2017-06-21 21:42:21.072916'}]\n",
      "StoreThreshold7: BEFORE [{'iterationIndex': 1, 'DerivedFromDatasetID': 'orfeus-as-46133-80f61e5e-56ca-11e7-8f3d-f45c89acf865', 'TriggeredByProcessIterationID': 'ANALYSIS-orfeus-as-46133-80f61a94-56ca-11e7-990f-f45c89acf865', 'port': 'input', 'prov_cluster': 'ANALYSIS5'}]\n",
      "StoreThreshold7: ITENDEX 1\n",
      "StoreThreshold7: AFTER []\n",
      "ANALYSIS5: Postprocess: (200, 'OK', '{\"inserts\": [\"ANALYSIS5_stateful_orfeus-as-46133-80f7feb8-56ca-11e7-8925-f45c89acf865\"], \"success\": true}')\n",
      "StoreThreshold7: Postprocess: (200, 'OK', '{\"inserts\": [\"StoreThreshold7_stateful_orfeus-as-46133-814c3f0c-56ca-11e7-a75d-f45c89acf865\"], \"success\": true}')\n",
      "SimplePE: Processed 1 iteration.\n",
      "\n",
      " RESULT: {'StoreFile6': {'storedData': [{'port': 'storedData', '_d4p': (<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 80f886fa-56ca-11e7-9223-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc'), 'TriggeredByProcessIterationID': 'StoreFile-orfeus-as-46133-80f81da8-56ca-11e7-bbe3-f45c89acf865', 'id': '80f886fa-56ca-11e7-9223-f45c89acf865', 'prov_cluster': 'StoreFile6'}, {'port': 'storedData', '_d4p': (<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 8123462e-56ca-11e7-8aa5-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc'), 'TriggeredByProcessIterationID': 'StoreFile-orfeus-as-46133-81230b4f-56ca-11e7-803d-f45c89acf865', 'id': '8123462e-56ca-11e7-8aa5-f45c89acf865', 'prov_cluster': 'StoreFile6'}]}, 'StoreThreshold7': {'storedData': [{'port': 'storedData', '_d4p': (<xarray.Dataset>\n",
      "Dimensions:                       (bnds: 2, time: 12, x: 721, y: 721)\n",
      "Coordinates:\n",
      "  * y                             (y) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * x                             (x) float64 -9.024e+06 -8.999e+06 ...\n",
      "  * time                          (time) datetime64[ns] 1994-10-16T12:00:00 ...\n",
      "  * bnds                          (bnds) int64 0 1\n",
      "Data variables:\n",
      "    time_bnds                     (time, bnds) datetime64[ns] 1979-10-01 ...\n",
      "    lambert_azimuthal_equal_area  |S64 ''\n",
      "    SWE                           (time, y, x) float64 nan nan nan nan nan ...\n",
      "    lat                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "    lon                           (y, x) float64 nan nan nan nan nan nan nan ...\n",
      "Attributes:\n",
      "    source: SMMR L3 brightness temperatures in EASE grid, ECMWF weather station data\n",
      "    auxiliary_data: GLC-2000 derived land classification mask v2.0, ETOPO-5 derived mountain mask v2.0, GLC-2000 derived forest mask\n",
      "    product_version: 2.0\n",
      "    summary: Snow water equivalent values on 25 km by 25 km Equal Area Scalable Earth (EASE)-grid, produced by assimilating passive radiometer data with snow depth information from synoptic weather station network. SWE information is provided for terrestrial non-mountainous regions of Northern Hemisphere, excluding glaciers and Greenland\n",
      "    id: 0953ef85-3a11-11e7-86f3-f45c89acf865\n",
      "    naming_authority: fi.fmi\n",
      "    keywords_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    cdm_data_type: grid\n",
      "    project: ESA GlobSnow-2\n",
      "    geospatial_vertical_min: 0.0\n",
      "    geospatial_vertical_max: 0.0\n",
      "    geospatial_lat_units: degrees north\n",
      "    geospatial_lon_units: degrees east\n",
      "    standard_name_vocabulary: NetCDF Climate and Forecast (CF) Metadata Convention Standard Name Table Version 28 (07 January 2015)\n",
      "    license: These data may be redistributed and used without restriction.\n",
      "    sensor: SMMR\n",
      "    spatial_resolution: 25 km\n",
      "    algorithm: FMI assimilation algorithm (Pulliainen 2006)\n",
      "    tracking_id: 47092dd1-7a86-47b1-952c-3ae3163d3828\n",
      "    Conventions: CF-1.6\n",
      "    package_references: ophidia.cmcc.it\n",
      "    date_published: 2016-07-19\n",
      "    date_revised: 2016-07-19\n",
      "    institution: CMCC\n",
      "    institution_id: CMCC\n",
      "    institution_url: www.cmcc.it\n",
      "    contact_email: ophidia-info@lists.cmcc.it\n",
      "    creator_name: CMCC\n",
      "    creator_url: www.cmcc.it\n",
      "    creator_email: ophidia-info@lists.cmcc.it\n",
      "    contributor_name:  \n",
      "    contributor_role:  \n",
      "    platform: station\n",
      "    platform_id: NIMBUS\n",
      "    satellite_algorithm:  \n",
      "    satellite_sensor: SMMR\n",
      "    indata_history:  \n",
      "    frequency: mon\n",
      "    cdm_datatype: grid\n",
      "    geospatial_bounds: POLYGON (35 -180, 85 -180, 85 180, 35 180)\n",
      "    geospatial_lat_min: 35.0\n",
      "    geospatial_lat_max: 85.0\n",
      "    geospatial_lon_min: -180.0\n",
      "    geospatial_lon_max: 180.0\n",
      "    geospatial_lat_resolution: 25 km\n",
      "    geospatial_lon_resolution: 25 km\n",
      "    project_id: CLIP-C\n",
      "    activity: clipc\n",
      "    title: Snow Water Equivalent, Oct monthly aggregate value\n",
      "    time_coverage_start: 19791001\n",
      "    product: obs_derived\n",
      "    comment:  \n",
      "    references:  \n",
      "    package_name: ophidia-0-10-1\n",
      "    date_created: 20160701\n",
      "    date_modified:  \n",
      "    date_issued: 20160802\n",
      "    source_data_id: GlobSnow-SWE-L3B\n",
      "    source_data_id_comment:  \n",
      "    invar_platform: remote sensing\n",
      "    invar_platform_id: ESA GlobSnow\n",
      "    invar_satellite_algorithm:  \n",
      "    invar_satellite_sensor: SMMR\n",
      "    invar_rcm_model_id:  \n",
      "    invar_rcm_model_realization_id:  \n",
      "    invar_rcm_model_driver:  \n",
      "    invar_reanalysis_id:  \n",
      "    invar_gcm_model_id:  \n",
      "    invar_experiment_name:  \n",
      "    invar_ensemble_member:  \n",
      "    invar_bc_method_id:  \n",
      "    invar_bc_observation_id:  \n",
      "    invar_bc_period:  \n",
      "    invar_variable_name: SWE_avg\n",
      "    reference_period: 1979-2008\n",
      "    output_frequency: monClim\n",
      "    tile:  \n",
      "    keywords: SWE-avg,climate,index\n",
      "    invar_tracking_id:  \n",
      "    contact: ophidia-info@lists.cmcc.it\n",
      "    realisation_id:  \n",
      "    variable_name: SWE\n",
      "    history:  \n",
      "    domain: 180E-180W-35N-85N\n",
      "    time_coverage_end: 20080701\n",
      "    DODS.strlen: 0\n",
      "    DODS_EXTRA.Unlimited_Dimension: time, 'data/newB.nc'), 'TriggeredByProcessIterationID': 'StoreThreshold-orfeus-as-46133-814c2eeb-56ca-11e7-b4d4-f45c89acf865', 'id': 'orfeus-as-46133-814c33b8-56ca-11e7-b663-f45c89acf865', 'prov_cluster': 'StoreThreshold7'}]}}\n"
     ]
    }
   ],
   "source": [
    "runExampleWorkflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Export and embed provenance within NetCDF results\n",
    "\n",
    "Provenance is extracted from the repository for the ouput result in PROV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/newB.nc\n",
      "Extract Trace for dataid: 0953ef85-3a11-11e7-86f3-f45c89acf865\n",
      "127.0.0.1:8082/workflow/export/data/0953ef85-3a11-11e7-86f3-f45c89acf865?all=true\n",
      "progress: (500, 'Internal Server Error')\n",
      "PROV TO EMBED:\n"
     ]
    }
   ],
   "source": [
    "# output location.\n",
    "finalFile = input_data['Collector'][2]['input'][1]\n",
    "print finalFile\n",
    "\n",
    "''' read id of output to locate prov '''\n",
    "ds = xarray.open_dataset( finalFile )\n",
    "dataid = ds.attrs['id']     \n",
    "\n",
    "print(\"Extract Trace for dataid: \"+dataid)\n",
    "expurl = urlparse(ProvenancePE.PROV_EXPORT_URL)\n",
    "connection = httplib.HTTPConnection(expurl.netloc)\n",
    "print(expurl.netloc+expurl.path+dataid+\"?all=true\")\n",
    "connection.request(\n",
    "                \"GET\", expurl.path+dataid+\"?all=true\")\n",
    "response = connection.getresponse()\n",
    "print(\"progress: \" + str((response.status, response.reason)))\n",
    "prov1 = response.read()\n",
    "print('PROV TO EMBED:')\n",
    "#print str(prov1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And embedded into a new file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ds. create variable save to file\n",
    "\n",
    "ds.load()\n",
    "ds['provenance'] = xarray.DataArray(\"\")\n",
    "ds['provenance'].attrs['prov_xml']=str(prov1)\n",
    "ds.to_netcdf(str(finalFile+\"_PROV\"))\n",
    "ds = xarray.open_dataset(str(finalFile+\"_PROV\"))\n",
    "#print ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Explore the resulting provenance with static and interactive visualsations\n",
    "\n",
    "The W3C-PROV provenance trace for a target data element is visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ProvXMLException",
     "evalue": "Non PROV element discovered in document or bundle.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProvXMLException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-87c946d1099c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#print prov1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0msvg_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprovToSvg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprov1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PROV.png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtext_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-87c946d1099c>\u001b[0m in \u001b[0;36mprovToSvg\u001b[0;34m(xml, output_f)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mxml_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print xml_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mProvDocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_doc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprov_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aspinuso2/github/wps_workflow/prov/model.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(source, content, format, **args)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1684\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aspinuso2/github/wps_workflow/prov/serializers/provxml.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(self, stream, **kwargs)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mdocument\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProvDocument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeserialize_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aspinuso2/github/wps_workflow/prov/serializers/provxml.pyc\u001b[0m in \u001b[0;36mdeserialize_subtree\u001b[0;34m(self, xml_doc, bundle)\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0mqname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mqname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDEFAULT_NAMESPACES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prov\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m                 raise ProvXMLException(\"Non PROV element discovered in \"\n\u001b[0m\u001b[1;32m    247\u001b[0m                                        \"document or bundle.\")\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# Ignore the <prov:other> element storing non-PROV information.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProvXMLException\u001b[0m: Non PROV element discovered in document or bundle."
     ]
    }
   ],
   "source": [
    "import prov\n",
    "import io\n",
    "import StringIO\n",
    "from prov.model import ProvDocument, ProvBundle, ProvException, first, Literal\n",
    "from prov.dot import prov_to_dot\n",
    "\n",
    "def provToSvg(xml,output_f):\n",
    "     \n",
    "    xml_doc = StringIO.StringIO()\n",
    "    xml_doc.write(str(xml))\n",
    "    xml_doc.seek(0, 0)\n",
    "    #print xml_doc\n",
    "    doc=ProvDocument.deserialize(xml_doc,format=\"xml\")\n",
    "    dot = prov_to_dot(doc)\n",
    "    return dot.create(format=output_f)\n",
    "    \n",
    "\n",
    "#prov_doc=open(prov).read()\n",
    "\n",
    "#print prov1\n",
    "\n",
    "svg_content=provToSvg(prov1,\"png\")\n",
    "\n",
    "with open(\"PROV.png\",\"w+\") as text_file:\n",
    "    text_file.write(str(svg_content))\n",
    "\n",
    "from IPython.display import Image\n",
    "#Image(\"PROV.png\")\n",
    "\n",
    "    \n",
    "# visualse NetCDF provenance in PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage into generic archives\n",
    "\n",
    "The PROV Document can be store within generic archives:\n",
    "\n",
    "https://provenance.ecs.soton.ac.uk/store/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive tools - S-ProvFlow GUI\n",
    "\n",
    "The model and the repository can be explored through the S-ProvFlow GUI\n",
    "\n",
    "Access the following link and introduce your usename when asked (It has to be the same used for the workflow profiling and execution)\n",
    "\n",
    "http://climate4impact.eu/provenance-explorer/html/view.jsp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Data-reuse traceability.\n",
    "\n",
    "Change the <i>1.3 Specify the Input</i> section with the commented lines alternatively. Run the notebook to see updated results, both inline and on the remote repository."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
