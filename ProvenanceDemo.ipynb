{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Provenance integration in netcdf/xarray Data-Intensive workflows.\n",
    "\n",
    "\n",
    "#### Authors: Alessandro Spinuso and Andrej Mihajlovski, \n",
    "\n",
    "####  Royal Netherlands Meteorological Institure (KNMI)\n",
    "\n",
    "\n",
    "The following \"Live\" notebook demonstrates a simple workflow implemented with a data-intensive processing library (dispel4py), that has been extended with a configurable and programmable provenance tracking framework , S-PROV.\n",
    "\n",
    "## Management Highligts, S-PROV Towards reproduciblity as a service\n",
    "<ul>\n",
    "<li>\n",
    "The provenance information produced can be tuned and adapted to computational, precision and contextualisation requirements</li>\n",
    "<li>\n",
    "The freamework allows for the traceability of data-reuse across different executions, methods and users</li>\n",
    "<li>The provenance can be stored as files or sent at run-time to a custom external repository</li>\n",
    "<li>The repository can be searched and explored via interactive tools</li> \n",
    "<li>The provenance model is designed around an hybrid data-flow model, which takes into account data-streams and concrente data resourcese. eg. file location, webservices etc.</li>\n",
    "<li>The lineage can be exported from the repository in W3C PROV format. This facilitates the production of interoperabile reports and data-curation tasks. For instance, The provenance related to specific data can be stored in W3C-PROV XML format into strucutred file formats (NetCDF) as well as istitutional and general-purpose citable data-repositories.</li>\n",
    "</ul>\n",
    "\n",
    "## Demonstration outline\n",
    "\n",
    "### 1 - Workflow specification and execution\n",
    "\n",
    "<ol>\n",
    "  <li>Define the <i><b>Classes</b></i> of the <i><b>Workflow Components</b></i></li>\n",
    "  <li>Construct the <i><b>Workflow</b></i> application</li>\n",
    "  <li>Prepare the Input</li>\n",
    "  <li>Visualise and run the workflow without provenance</li>\n",
    "</ol>\n",
    "\n",
    "### 2 - Provenance Types, Profiling and contextualisation\n",
    "\n",
    "<ol>\n",
    "  <li>Define the <i><b>Provenance Type</b></i> to be used within the workflow</li>\n",
    "  <li><i><b>Profile</b></i> the workfow for provenance tracking</li>\n",
    "  <li>Run the workflow with provenance activatied</li>\n",
    "  <li>Export and embed provenance within NetCDF results</li>\n",
    "  <li>Explore the resulting provenance with interactive and static visualsations</li>\n",
    "</ol>\n",
    "\n",
    "### 3 - Data-reuse traceability. \n",
    "<ol>\n",
    "  <li>Change the input and demostrate consistency of provenance for data-ruse across multiple workflow executions</li>\n",
    "  <li>Discuss more complex use cases and configuration options</li>\n",
    "</ol>\n",
    "\n",
    "### 4 - Informal Evaluation\n",
    "\n",
    "SWOT form:\n",
    "\n",
    "https://docs.google.com/presentation/d/10xlRYytR7NB9iC19T29BD-rW77ZAtnjtlukMJDP_MIs/edit?usp=sharing\n",
    "\n",
    "\n",
    "## 1 - Workflow specification and execution\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>The dispel4py framework is utilised for the workflows</li>\n",
    "<li>Xarray for inmemory management of netcdf/opendap data.</li>\n",
    "<li>Matplotlib for visualisation.</li>\n",
    "<li>W3C for provenance representation.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xarray\n",
    "#import netCDF4\n",
    "import json\n",
    "\n",
    "from dispel4py.workflow_graph import WorkflowGraph \n",
    "from dispel4py.provenance import *\n",
    "\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "\n",
    "from dispel4py.base import create_iterative_chain, ConsumerPE, IterativePE, SimpleFunctionPE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Simple Workflow, xarray in xarray out. \n",
    "The generic processing elements are defined below. the <i>GenericPE</i> bellongs to the dispel4py framework. It allows data-objects to be passed as inputs and outputs. The <i>Components</i> are linked and visualised via the workflow_graph module.\n",
    "\n",
    "### 1.1 The three Workflow Components:\n",
    "\n",
    "<ol>\n",
    "<li>- Read, xarray is read into memory.</li>\n",
    "<li>- ANALYSIS, xarray is processed/passed to output (dummy, no real changes in the example)</li>\n",
    "<li>- Write, xarray is visualised.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Read(GenericPE):\n",
    "    \n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('xarray')\n",
    "\n",
    "    def _process(self,inputs):\n",
    "        \n",
    "        inputLocation = inputs['input'][0]\n",
    "\n",
    "        ds = xarray.open_dataset( inputLocation )\n",
    "    \n",
    "        self.write( 'xarray' , (ds , inputs['input'][1]) , location=inputLocation )\n",
    "\n",
    "        \n",
    "#The IterativePE automatically assigns input and output ports to the component\n",
    "class Write(IterativePE):\n",
    "    \n",
    "    def __init__(self):\n",
    "        IterativePE.__init__(self)\n",
    "         \n",
    "            \n",
    "    def _process(self,inputs):\n",
    "        self.log('Write_Function')\n",
    "        \n",
    "        outputLocation = inputs[1]\n",
    "        \n",
    "        inputs[0].to_netcdf( outputLocation )\n",
    "                \n",
    "        self.write('location', outputLocation,location=outputLocation )\n",
    "        \n",
    "        \n",
    "class Analysis(GenericPE):\n",
    "        \n",
    "    def __init__(self):\n",
    "        GenericPE.__init__(self)\n",
    "        self._add_input('input')\n",
    "        self._add_output('output')\n",
    "        \n",
    "    def _process(self,inputs):\n",
    "        self.log('Workflow_process')\n",
    "        \n",
    "       \n",
    "        nc = inputs['input'][0]\n",
    "       \n",
    "        #Additional metadata can be added to the output for provenance contextualisation\n",
    "        self.write('output', (nc , inputs['input'][1] ), metadata={'mycustom_term':10})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Construct the Workflow application\n",
    "\n",
    "Instantiates the Components and combines them in a workflow graph which gets eventually visualised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Initialise the graph\n",
    "def createWorkflowGraph():\n",
    "    readX  = Read()\n",
    "    readX.name = 'Collector'\n",
    "\n",
    "    analyse   = Analysis()\n",
    "    analyse.name    = 'ANALYSIS'\n",
    "    analyse.parameters = { 'filter': 10 }\n",
    "\n",
    "    writeX = Write()\n",
    "    writeX.name = 'StoreFile'\n",
    "    \n",
    "    \n",
    "    graph = WorkflowGraph()    \n",
    "    graph.connect(readX ,'xarray'   , analyse     ,'input')\n",
    "    graph.connect(analyse    ,'output'   , writeX , 'input')\n",
    "\n",
    "    return graph\n",
    "\n",
    "\n",
    "\n",
    "graph = createWorkflowGraph()\n",
    "\n",
    "\n",
    "from dispel4py.visualisation import display\n",
    "display(graph)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Specify the Input\n",
    "\n",
    "A simple json representation is used to define initial input data for each named Component of the workflow.\n",
    "Every component can recieve a list of inputs. These will be streamed serially or in parallel, depending from the execution mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = { \n",
    "                \n",
    "                #'Collector': [ { 'input' : [ 'http://opendap.knmi.nl/knmi/thredds/dodsC/CLIPC/cmcc/SWE/SWE_ophidia-0-10-1_CMCC_GlobSnow-SWE-L3B_monClim_19791001-20080701_1979-2008.nc',\n",
    "                #               'data/newA.nc']}]\n",
    "    \n",
    "                'Collector': [ { 'input': [ 'data/newA.nc', 'data/newB.nc']} ]     \n",
    "                #'Collector': [ { 'input': [ 'data/newB.nc', 'data/newC.nc']}]\n",
    "            }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Run the Workflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global result\n",
    "\n",
    "def runExampleWorkflow():\n",
    "                                                     \n",
    "    print input_data                   \n",
    "\n",
    "    #Launch in simple process\n",
    "    result = simple_process.process_and_return(graph, input_data)\n",
    "    print \"\\n RESULT: \"+str(result)\n",
    "\n",
    "runExampleWorkflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Provenance Types, Profiling and contextualisation\n",
    "\n",
    "### 2.1 Define a Provenance Type\n",
    "\n",
    "The <i>Provenance Type</i> defined below will be used to extend specific workflow components, enabling special provenance tracking properties for <i>NetCDF/xarray</i> formats.\n",
    "\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "<b><i>makeUniqueId:</i></b> \n",
    "Generates and returns a <i>uuid</i>. This can be implemented to adhere to the hosting infrastructure best-practices.</li>\n",
    "<li>\n",
    "<i><b>extractExternalInputDataId:</b></i>\n",
    "This method is used by the provenance type to extract the id of the incoming data. Its use is handy especially when a workflow component ingests files that have been produced by other workflows and that are represented by self-contained and structured data formats.  For instance, in NetCDF where data and metadata can be packaged together according to community standards, this method extracts and returns the id of the external resource, allowing the framework to use it in the current run to represent new dependencies. A customised implementation of this method for a provenance type that deals with domain-specific data formats, ensures the linkage and therefore the consistent continuation of provenance traces across workflow executions. </li>\n",
    "<li><b><i>extractItemMetadata:</i></b>\n",
    "This methods enables the configuration of the provenance for a particular domain, user or infrastructure requirement. It extracts metadata from the data written on a output channel and includes it as a detailed description of the <i>Data</i> entity within the provenance model.</li>\n",
    "<li><b><i>applyFlowResetPolicy (Advanced):</i></b>\n",
    "This method is invoked by each iteration when a decision has to be made on the required lineage pattern. The framework automatically passes information whether the invocation has produced any output or not (<i>on-void-iterations</i>). The method, according to predefined rules, provides indications on either discarding the current input data or to include it into the <i>StateCollection</i> automatically, capturing its contribution to the next invocation through a <i>stateful</i>operations. \n",
    "In our implementation, basic provenance types such as <i>StatefulType</i> and <i>StatelessType</i> are made available and can be used accordingly the specific needs.\n",
    "</li>\n",
    "\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class netcdfProvType(ProvenancePE):\n",
    "    def __init__(self):\n",
    "        ProvenancePE.__init__(self)\n",
    "    \n",
    "    def extractExternalInputDataId(self,data, input_port):\n",
    "        #Extract here the id from the data (type specific):\n",
    "\n",
    "        self.log('ANDREJ.extractExternalInputDataId')\n",
    "        #self.log(data)\n",
    "        \n",
    "        try:\n",
    "            #ds = xarray.open_dataset(data['input'][0])\n",
    "            ds = xarray.open_dataset(data[0])\n",
    "            id = ds.attrs['id']\n",
    "            \n",
    "        except Exception, err:\n",
    "            id = str(uuid.uuid1())\n",
    "            self.log(str(err))\n",
    "        #Return\n",
    "        return id\n",
    "    \n",
    "    \n",
    "    def makeUniqueId(self, data, output_port):      \n",
    "        \n",
    "        self.log('ANDREJ.makeUniqueId')\n",
    "        #self.log(kwargs)\n",
    "        \n",
    "        #produce the id\n",
    "        id=str(uuid.uuid1())\n",
    "            \n",
    "        ''' nc data '''\n",
    "        xa = data[0]\n",
    "        \n",
    "        ''' unique as defined by the community standard '''\n",
    "        xa.attrs['id'] = id\n",
    "        \n",
    "        #Return\n",
    "        return id \n",
    "    \n",
    "\n",
    "    \n",
    "    ''' extracts xarray metadata '''\n",
    "    def extractItemMetadata(self,data, output_port):\n",
    "        \n",
    "        self.log('ANDREJ.extractItemMetadata')\n",
    "        #self.log(data)\n",
    "        \n",
    "        try:            \n",
    "            nc_meta = OrderedDict()\n",
    "            \n",
    "            ''' cycle throug all attributes, dimensions and variables '''\n",
    "            xa = data[0]\n",
    "                        \n",
    "            # dataset meta\n",
    "            nc_meta['Dimensions'] = str( dict(xa.dims)) \n",
    "            nc_meta['Type'] = str(type(xa))\n",
    "            \n",
    "            # global attr\n",
    "            for k , v in xa.attrs.items():\n",
    "                nc_meta[str(k).replace(\".\",\"_\")] = str(v)\n",
    "            # vars attr   \n",
    "            for n , i in xa.data_vars.items():\n",
    "                for k , v in i.attrs.items():\n",
    "                    nc_meta[n+\"_\"+str(k).replace(\".\",\"_\")] = str(v)\n",
    "            \n",
    "            #pprint(nc_meta)\n",
    "        \n",
    "            metadata = [nc_meta]\n",
    "            \n",
    "            return metadata\n",
    "                             \n",
    "        except Exception, err:\n",
    "            self.log(\"Applying default metadata extraction:\"+str(traceback.format_exc()))\n",
    "            self.error=self.error+\"Extract Metadata error: \"+str(traceback.format_exc())\n",
    "            return super(netcdfProvType, self).extractItemMetadata(data);\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Profile the workfow for provenance tracking\n",
    "\n",
    "Once the Provenance types have been defined, these are used to configure, or profile, a workflow execution to comply with the desired provenance collection requirements.  Below we illustrate the framework method and the details of this approach.\n",
    "\n",
    "<ul>\n",
    "\n",
    "<li><b><i>profile_prov_run</i></b> With this method, the users of the workflow can profile their run for provenance by indicating which types to apply to each component. Users can also chose where to store the metadata, locally to the file system or to a remote service. These operations can be performed in bulks, with different impacts on the overall overhead and on the experienced rapidity of the access of the lineage information. Additional details on the proposed remote provenance storage and access service will be provided in Chapter V. Finally, also general information about the attribution of the run, such as <i>username, run_id, description, workflow_name, workflow_id</i> are captured and included within the provenance traces.\n",
    "</li>\n",
    "<li><b><i>Skip-Rules (Advanced)</i></b>\n",
    "Users can tune the scale of the records produced by indicating in the above method a set of <i>skip-rules</i> for every component.This functionality allows users to specify rules to control the data-driven production of the provenance declaratively. The approach takes advantage of the contextualisation applied by the provenance types, which extract domain and experimental metadata, and evaluates their value against simple <i>skip-rule</i> of this kind:\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skip_rules={\"ANALYSIS\":{\"mycustom_term\":{\"$gt\":0,\"$lt\":10}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining provenance profile\n",
    "\n",
    "A high JSON 'template' describing the provenance profile for a specific run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prov_profile =  {\n",
    "                    'username': \"aspinuso\", \n",
    "                    'description' : \"provdemo basic\",\n",
    "                    'workflowName': \"demo_ecmwf\"      ,\n",
    "                    'workflowId'  : \"workflow process\",\n",
    "                    'save_mode'   : 'service'         ,\n",
    "                    # Defines the use of the ProvenancePE with the Workflow Component\n",
    "                    'componentsType' : {'ANALYSIS':(netcdfProvType,) , 'Collector':(netcdfProvType,)},\n",
    "                    'skip_rules': skip_rules\n",
    "                } \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repository Endpoints \n",
    "\n",
    "The REPOS_URL is the target provenence repository. \n",
    "Used for VERCE (Seismo), CLIPC (C3S) and Climate4Impact (Climate IS-ENES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store via service\n",
    "#ProvenancePE.REPOS_URL='http://127.0.0.1:8082/workflow/insert'\n",
    "ProvenancePE.REPOS_URL='http://climate4impact.eu/prov/workflow/insert'\n",
    "\n",
    "#Export data lineage via service (REST GET Call on dataid resource)\n",
    "#ProvenancePE.PROV_EXPORT_URL='http://127.0.0.1:8082/workflow/export/data/'\n",
    "ProvenancePE.PROV_EXPORT_URL=\"http://climate4impact.eu/prov/workflow/export/data/\" \n",
    "\n",
    "\n",
    "#Store to local path\n",
    "ProvenancePE.PROV_PATH='./prov-files/'\n",
    "\n",
    "#Size of the provenance bulk of documents before sending to file, service or sensor\n",
    "ProvenancePE.BULK_SIZE=20\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Dynamic Profiling\n",
    "\n",
    "The application is then profiled with the desired provenance types and attribution parmeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createGraphWithProv():\n",
    "    \n",
    "    graph=createWorkflowGraph()\n",
    "    #Location of the remote repository for runtime updates of the lineage traces. Shared among ProvenanceRecorder subtypes\n",
    "\n",
    "    # Ranomdly generated unique identifier for the current run\n",
    "    rid='JUP_SIMPLE_'+getUniqueId()\n",
    "\n",
    "    \n",
    "    # Finally, provenance enhanced graph is prepared:\n",
    "    print prov_profile\n",
    "\n",
    "     \n",
    "    #Initialise provenance storage to service:\n",
    "    profile_prov_run(graph, \n",
    "                     provImpClass=(ProvenancePE,),\n",
    "                     username=prov_profile['username'],\n",
    "                     runId=rid,\n",
    "                     description=prov_profile['description'],\n",
    "                     workflowName=prov_profile['workflowName'],\n",
    "                     workflowId=prov_profile['workflowId'],\n",
    "                     save_mode=prov_profile['save_mode'],\n",
    "                     componentsType=prov_profile['componentsType'],\n",
    "                     skip_rules=prov_profile['skip_rules']\n",
    "                    )\n",
    "                   \n",
    "\n",
    "    #clustersRecorders={'record0':ProvenanceRecorderToFileBulk,'record1':ProvenanceRecorderToFileBulk,'record2':ProvenanceRecorderToFileBulk,'record6':ProvenanceRecorderToFileBulk,'record3':ProvenanceRecorderToFileBulk,'record4':ProvenanceRecorderToFileBulk,'record5':ProvenanceRecorderToFileBulk}\n",
    "    #Initialise provenance storage end associate a Provenance type with specific components:\n",
    "    #profile_prov_run(graph,provImpClass=ProvenancePE,componentsType={'Source':(ProvenanceStock,)},username='aspinuso',runId=rid,w3c_prov=False,description=\"provState\",workflowName=\"test_rdwd\",workflowId=\"xx\",save_mode='service')\n",
    "\n",
    "    #\n",
    "    return graph\n",
    "\n",
    "\n",
    "graph=createGraphWithProv()\n",
    "\n",
    "display(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Run the workflow with provenance activatied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "runExampleWorkflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Export and embed provenance within NetCDF results\n",
    "\n",
    "Provenance is extracted from the repository for the ouput result in PROV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output location.\n",
    "finalFile = input_data['Collector'][0]['input'][1]\n",
    "print finalFile\n",
    "\n",
    "''' read id of output to locate prov '''\n",
    "ds = xarray.open_dataset( finalFile )\n",
    "dataid = ds.attrs['id']     \n",
    "\n",
    "print(\"Extract Trace for dataid: \"+dataid)\n",
    "expurl = urlparse(ProvenancePE.PROV_EXPORT_URL)\n",
    "connection = httplib.HTTPConnection(expurl.netloc)\n",
    "print(expurl.netloc+expurl.path+dataid+\"?all=true\")\n",
    "connection.request(\n",
    "                \"GET\", expurl.path+dataid+\"?all=true\")\n",
    "response = connection.getresponse()\n",
    "print(\"progress: \" + str((response.status, response.reason)))\n",
    "prov1 = response.read()\n",
    "print('PROV TO EMBED:')\n",
    "print str(prov1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And embedded into a new file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ds. create variable save to file\n",
    "\n",
    "ds.load()\n",
    "ds['provenance'] = xarray.DataArray(\"\")\n",
    "ds['provenance'].attrs['prov_xml']=str(prov1)\n",
    "ds.to_netcdf(str(finalFile+\"_PROV\"))\n",
    "ds = xarray.open_dataset(str(finalFile+\"_PROV\"))\n",
    "print ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Explore the resulting provenance with static and interactive visualsations\n",
    "\n",
    "The W3C-PROV provenance trace for a target data element is visualised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import prov\n",
    "import io\n",
    "import StringIO\n",
    "from prov.model import ProvDocument, ProvBundle, ProvException, first, Literal\n",
    "from prov.dot import prov_to_dot\n",
    "\n",
    "def provToSvg(xml,output_f):\n",
    "     \n",
    "    xml_doc = StringIO.StringIO()\n",
    "    xml_doc.write(str(xml))\n",
    "    xml_doc.seek(0, 0)\n",
    "    #print xml_doc\n",
    "    doc=ProvDocument.deserialize(xml_doc,format=\"xml\")\n",
    "    dot = prov_to_dot(doc)\n",
    "    return dot.create(format=output_f)\n",
    "    \n",
    "\n",
    "#prov_doc=open(prov).read()\n",
    "\n",
    "#print prov1\n",
    "\n",
    "svg_content=provToSvg(prov1,\"png\")\n",
    "\n",
    "with open(\"PROV.png\",\"w+\") as text_file:\n",
    "    text_file.write(str(svg_content))\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(\"PROV.png\")\n",
    "\n",
    "    \n",
    "# visualse NetCDF provenance in PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storage into generic archives\n",
    "\n",
    "The PROV Document can be store within generic archives:\n",
    "\n",
    "https://provenance.ecs.soton.ac.uk/store/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactive tools - S-ProvFlow GUI\n",
    "\n",
    "The model and the repository can be explored through the S-ProvFlow GUI\n",
    "\n",
    "Access the following link and introduce your usename when asked (It has to be the same used for the workflow profiling and execution)\n",
    "\n",
    "http://climate4impact.eu/provenance-explorer/html/view.jsp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Data-reuse traceability.\n",
    "\n",
    "Change the <i>1.3 Specify the Input</i> section with the commented lines alternatively. Run the notebook to see updated results, both inline and on the remote repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
